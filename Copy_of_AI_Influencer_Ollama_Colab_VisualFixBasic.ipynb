{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbanzai88/Artificial_Influencers/blob/main/Copy_of_AI_Influencer_Ollama_Colab_VisualFixBasic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JthawIJSDMtK"
      },
      "source": [
        "# ü§ñ AI Influencer with Ollama (Colab Version)\n",
        "This notebook runs a local LLM (e.g., `deepseek-r1:1.5b`) using Ollama in Colab to simulate an influencer generating text content and imagery.\n",
        "\n",
        "**Modules:**\n",
        "- Ollama LLM for captioning and replies\n",
        "- Stable Diffusion for image generation\n",
        "- Automated comment reply generation"
      ],
      "id": "JthawIJSDMtK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYnzi0JEDMtU"
      },
      "outputs": [],
      "source": [
        "# üõ†Ô∏è Step 1: Install & launch Ollama locally in Colab\n",
        "!pip install --quiet langchain-ollama python-docx nest_asyncio tqdm\n",
        "\n",
        "import os, threading, subprocess, time, requests\n",
        "\n",
        "for v in [\"OPENAI_API_KEY\",\"LITELLM_PROVIDER\",\"LITELL M_MODEL\",\"LITELL M_BASE_URL\"]:\n",
        "    os.environ.pop(v, None)\n",
        "os.environ[\"OLLAMA_HOST\"] = \"127.0.0.1:11434\"\n",
        "os.environ[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "\n",
        "!curl -fsSL https://ollama.com/install.sh -o install.sh\n",
        "!bash install.sh && chmod +x /usr/local/bin/ollama\n",
        "\n",
        "def _serve_ollama():\n",
        "    subprocess.Popen([\"ollama\", \"serve\"], stderr=subprocess.DEVNULL)\n",
        "threading.Thread(target=_serve_ollama, daemon=True).start()\n",
        "time.sleep(8)\n",
        "\n",
        "print(\"‚úÖ Ollama status:\", requests.get(\"http://127.0.0.1:11434\").status_code)"
      ],
      "id": "KYnzi0JEDMtU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdZsoyjzDMtV"
      },
      "outputs": [],
      "source": [
        "# üì• Step 2: Pull the deepseek-r1:1.5b model\n",
        "!ollama pull deepseek-r1:1.5b"
      ],
      "id": "RdZsoyjzDMtV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUop-RouDMtV"
      },
      "source": [
        "## üß† Step 3: Define the AI Influencer Persona"
      ],
      "id": "UUop-RouDMtV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6OZ9M-ODMtW"
      },
      "outputs": [],
      "source": [
        "persona = {\n",
        "    'name': 'Ava Monroe',\n",
        "    'style': 'vintage fashion',\n",
        "    'tone': 'witty and confident'\n",
        "}\n",
        "\n",
        "prompt = (\n",
        "    f\"You are {persona['name']}, an AI fashion influencer known for {persona['style']} looks. \"\n",
        "    f\"Write a witty Instagram caption about wearing a vintage leather jacket on a crisp autumn day.\"\n",
        ")"
      ],
      "id": "e6OZ9M-ODMtW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDHsSbVqDMtW"
      },
      "source": [
        "## üí¨ Step 4: Generate Caption Using Ollama"
      ],
      "id": "kDHsSbVqDMtW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jC6DCapNDMtW"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "response = requests.post(\n",
        "    \"http://127.0.0.1:11434/api/generate\",\n",
        "    json={\n",
        "        \"model\": \"deepseek-r1:1.5b\",\n",
        "        \"prompt\": prompt,\n",
        "        \"stream\": False\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"üìù Caption:\", response.json()['response'])"
      ],
      "id": "jC6DCapNDMtW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15ZcS3kXDMtW"
      },
      "source": [
        "## üé® Step 5: Generate Image Using Stable Diffusion"
      ],
      "id": "15ZcS3kXDMtW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2P-E9WRDMtX"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet diffusers transformers accelerate safetensors\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "from IPython.display import display\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16\n",
        ").to(\"cuda\")\n",
        "\n",
        "image_prompt = \"Fashionable young woman wearing a vintage leather jacket, autumn city background, photorealistic\"\n",
        "image = pipe(image_prompt).images[0]\n",
        "image.save(\"ava_monroe_image.png\")\n",
        "display(image)"
      ],
      "id": "m2P-E9WRDMtX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXNhG9oaDMtX"
      },
      "source": [
        "## ü§ñ Step 6: Generate Automated Comment Replies"
      ],
      "id": "bXNhG9oaDMtX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVNhsiFEDMtX"
      },
      "outputs": [],
      "source": [
        "comments = [\n",
        "    \"Love your style! üòç\",\n",
        "    \"Where did you get that jacket?\",\n",
        "    \"You always know how to rock vintage looks!\"\n",
        "]\n",
        "\n",
        "for comment in comments:\n",
        "    reply_prompt = (\n",
        "        f\"As Ava Monroe, a witty and confident fashion influencer, reply briefly to this fan comment: \"\n",
        "        f\"'{comment}'\\n\"\n",
        "        f\"Your response should be no more than 25 words. Do NOT include any <think> or internal reasoning.\"\n",
        "    )\n",
        "\n",
        "    response = requests.post(\n",
        "        \"http://127.0.0.1:11434/api/generate\",\n",
        "        json={\n",
        "            \"model\": \"deepseek-r1:1.5b\",\n",
        "            \"prompt\": reply_prompt,\n",
        "            \"stream\": False\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(f\"üó®Ô∏è {comment}\\nüí¨ {response.json()['response'].strip()}\\n\")"
      ],
      "id": "pVNhsiFEDMtX"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}