{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbanzai88/Artificial_Influencers/blob/main/SynbioCrowV003.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10crctyo-3HH",
      "metadata": {
        "id": "10crctyo-3HH"
      },
      "source": [
        "This system is an automated end-to-end bio-retrosynthesis and design platform that integrates multiple computational tools into a unified LangGraph-based workflow. It identifies, evaluates, and simulates novel enzymatic pathways for the biosynthesis of target molecules, combining retrosynthetic search, enzyme selection, thermodynamic filtering, and metabolic simulation.\n",
        "\n",
        "Key Capabilities:\n",
        "\n",
        "*   Automated Retrosynthesis (RetroBioCat2)\n",
        "*   Generates de novo biochemical pathways from a target molecule’s SMILES.\n",
        "*   Performs Monte Carlo Tree Search (MCTS) over reaction rules to explore feasible routes.\n",
        "*   Pathway Extraction & Annotation\n",
        "*   Converts retrosynthesis outputs into structured reaction tables (substrates, products, scores).\n",
        "*   Integrates similarity metrics, prior precedents, and enzyme reaction type metadata.\n",
        "*   Thermodynamic & Ranking Modules\n",
        "*   Uses dGPredictor / eQuilibrator to estimate Gibbs free energies (ΔG′).\n",
        "*   Ranks pathways based on combined heuristic and thermodynamic feasibility scores.\n",
        "*   Enzyme Identification (Selenzyme)\n",
        "*   Predicts candidate enzymes for each step, optionally scraping Selenzyme for activity and organism data.\n",
        "*   Metabolic Simulation (COBRApy / novoStoic)\n",
        "*   Constructs toy stoichiometric models for top-ranked pathways.\n",
        "*   Runs flux balance analysis (FBA) to estimate steady-state feasibility and pathway yield.\n",
        "*   Sequence Ranking + Design of Experiments (DoE)\n",
        "*   Build / Approval / Export Workflow\n",
        "*   Produces pathway briefs, annotated CSVs/JSONs, simulation flux tables, and an export manifest for downstream integration or lab validation.\n",
        "*   List item\n",
        "\n",
        "Technical Architecture\n",
        "\n",
        "*   LangGraph orchestration: modular “nodes” for each stage (retrosynthesis, extract, thermo, rank, simulate, selenzyme, seqrank, doe, build, approve, export).\n",
        "*   Micromamba-based environment isolation ensures reproducible dependency management per run.\n",
        "*   Streaming execution & checkpointed state allow resuming or extending pipelines dynamically.\n",
        "*   Output artifacts (CSV, JSON, Markdown) capture every stage for transparency and reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uTr7HjkaMW-W",
      "metadata": {
        "id": "uTr7HjkaMW-W"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Optional, TypedDict\n",
        "\n",
        "from typing_extensions import TypedDict, Annotated\n",
        "from operator import add\n",
        "\n",
        "class DBTLState(TypedDict, total=False):\n",
        "    # constants (never “updated” again)\n",
        "    run_id: Annotated[str, \"const\"]\n",
        "    workdir: Annotated[str, \"const\"]\n",
        "    target_smiles: Annotated[str, \"const\"]\n",
        "    host: Annotated[str, \"const\"]\n",
        "\n",
        "    # normal fields (LastValue by default)\n",
        "    constraints: dict\n",
        "    status: str\n",
        "    last_node: str\n",
        "    approved: bool\n",
        "    signals: dict\n",
        "\n",
        "    # append-only logs\n",
        "    logs: Annotated[list[str], add]\n",
        "\n",
        "    # your artifacts…\n",
        "    retro_out_dir: str\n",
        "    pathways_all_csv: str\n",
        "    pathways_solved_csv: str\n",
        "    pathways_all_json: str\n",
        "    pathways_solved_json: str\n",
        "    pathway_json_map: dict\n",
        "    steps_plan_csv: str\n",
        "    ranked_csv: str\n",
        "    # etc…\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yAPHPs4m4AGS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAPHPs4m4AGS",
        "outputId": "9e301bf9-b542-4d1f-8fd0-0dc1724e4531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "↓ downloading micromamba… https://micro.mamba.pm/api/micromamba/linux-64/latest\n",
            "→ extracting micromamba (auto-detect compression)…\n",
            "✅ micromamba: /content/runs/run_001/bin/micromamba\n",
            "$ /content/runs/run_001/bin/micromamba create -y -p /content/runs/run_001/micromamba/envs/retrobiocat -c conda-forge python=3.10 pip\n",
            "$ /content/runs/run_001/bin/micromamba run -p /content/runs/run_001/micromamba/envs/retrobiocat python -m pip install -q --upgrade pip setuptools wheel numpy==1.26.4 pandas==2.2.2 pint==0.22\n",
            "$ /content/runs/run_001/bin/micromamba run -p /content/runs/run_001/micromamba/envs/retrobiocat python -m pip install -q equilibrator-api==0.6.0 equilibrator-cache==0.6.0\n",
            "$ /content/runs/run_001/bin/micromamba run -p /content/runs/run_001/micromamba/envs/retrobiocat python -m pip install -q cobra==0.29.0 optlang>=1.8.0 swiglpk>=5.0.10\n",
            "$ /content/runs/run_001/bin/micromamba install -y -p /content/runs/run_001/micromamba/envs/retrobiocat -c conda-forge rdkit=2022.09.5\n",
            "$ /content/runs/run_001/bin/micromamba run -p /content/runs/run_001/micromamba/envs/retrobiocat python -m pip install -q https://github.com/willfinnigan/RetroBioCat-2/archive/refs/heads/main.zip\n",
            "\n",
            "→ versions (light)\n",
            "$ /content/runs/run_001/bin/micromamba run -p /content/runs/run_001/micromamba/envs/retrobiocat python -\n",
            "✔ bootstrap done.\n"
          ]
        }
      ],
      "source": [
        "import io, os, stat, tarfile, urllib.request, subprocess, sys, pathlib, textwrap\n",
        "\n",
        "WORKDIR = pathlib.Path(\"/content/runs/run_001\")\n",
        "BIN_DIR = WORKDIR / \"bin\"\n",
        "MAMBA_ROOT = WORKDIR / \"micromamba\"\n",
        "ENV_PREFIX = MAMBA_ROOT / \"envs\" / \"retrobiocat\"\n",
        "MM_BIN = BIN_DIR / \"micromamba\"\n",
        "\n",
        "BIN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "MAMBA_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "os.environ[\"MAMBA_ROOT_PREFIX\"] = str(MAMBA_ROOT)\n",
        "\n",
        "def sh(cmd, **kw):\n",
        "    \"\"\"Run a command, print it, and return CompletedProcess (raises on error by default).\"\"\"\n",
        "    kw.setdefault(\"check\", True)\n",
        "    print(\"$\", \" \".join(cmd))\n",
        "    return subprocess.run(cmd, **kw)\n",
        "\n",
        "# 1) micromamba binary (download & extract once; auto-detect compression)\n",
        "if not MM_BIN.exists():\n",
        "    url = \"https://micro.mamba.pm/api/micromamba/linux-64/latest\"\n",
        "    print(\"↓ downloading micromamba…\", url)\n",
        "    with urllib.request.urlopen(url) as r:\n",
        "        data = r.read()\n",
        "    print(\"→ extracting micromamba (auto-detect compression)…\")\n",
        "    with tarfile.open(fileobj=io.BytesIO(data), mode=\"r:*\") as tf:\n",
        "        member = None\n",
        "        for m in tf.getmembers():\n",
        "            name = m.name.replace(\"\\\\\", \"/\")\n",
        "            if name.endswith(\"/micromamba\") and \"/bin/\" in name:\n",
        "                member = m\n",
        "                break\n",
        "        if member is None:\n",
        "            for m in tf.getmembers():\n",
        "                if m.name.split(\"/\")[-1] == \"micromamba\":\n",
        "                    member = m\n",
        "                    break\n",
        "        if member is None:\n",
        "            raise RuntimeError(\"micromamba binary not found in archive\")\n",
        "        with tf.extractfile(member) as src, open(MM_BIN, \"wb\") as dst:\n",
        "            dst.write(src.read())\n",
        "    MM_BIN.chmod(MM_BIN.stat().st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)\n",
        "print(\"✅ micromamba:\", MM_BIN)\n",
        "\n",
        "# 2) create env (idempotent)\n",
        "if not ENV_PREFIX.exists():\n",
        "    sh([str(MM_BIN), \"create\", \"-y\", \"-p\", str(ENV_PREFIX), \"-c\", \"conda-forge\", \"python=3.10\", \"pip\"])\n",
        "\n",
        "# 3) base pins (numpy/pandas/pint)\n",
        "sh([str(MM_BIN), \"run\", \"-p\", str(ENV_PREFIX), \"python\", \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\",\n",
        "    \"pip\", \"setuptools\", \"wheel\", \"numpy==1.26.4\", \"pandas==2.2.2\", \"pint==0.22\"])\n",
        "\n",
        "# 4) equilibrator\n",
        "sh([str(MM_BIN), \"run\", \"-p\", str(ENV_PREFIX), \"python\", \"-m\", \"pip\", \"install\", \"-q\",\n",
        "    \"equilibrator-api==0.6.0\", \"equilibrator-cache==0.6.0\"])\n",
        "\n",
        "# 5) cobra stack\n",
        "sh([str(MM_BIN), \"run\", \"-p\", str(ENV_PREFIX), \"python\", \"-m\", \"pip\", \"install\", \"-q\",\n",
        "    \"cobra==0.29.0\", \"optlang>=1.8.0\", \"swiglpk>=5.0.10\"])\n",
        "\n",
        "# 6) RDKit via conda-forge\n",
        "sh([str(MM_BIN), \"install\", \"-y\", \"-p\", str(ENV_PREFIX), \"-c\", \"conda-forge\", \"rdkit=2022.09.5\"])\n",
        "\n",
        "# 7) RetroBioCat-2 (zip first, fallback to git)\n",
        "try:\n",
        "    sh([str(MM_BIN), \"run\", \"-p\", str(ENV_PREFIX), \"python\", \"-m\", \"pip\", \"install\", \"-q\",\n",
        "        \"https://github.com/willfinnigan/RetroBioCat-2/archive/refs/heads/main.zip\"])\n",
        "except subprocess.CalledProcessError:\n",
        "    sh([str(MM_BIN), \"run\", \"-p\", str(ENV_PREFIX), \"python\", \"-m\", \"pip\", \"install\", \"-q\",\n",
        "        \"git+https://github.com/willfinnigan/RetroBioCat-2.git\"])\n",
        "\n",
        "# 8) light sanity (feed a tiny script via stdin)\n",
        "mini = textwrap.dedent(\"\"\"\n",
        "import sys, importlib\n",
        "print(\"python:\", sys.executable)\n",
        "mods = (\"numpy\",\"pandas\",\"equilibrator_api\",\"equilibrator_cache\",\"cobra\",\"rdkit\")\n",
        "for m in mods:\n",
        "    try:\n",
        "        mod = importlib.import_module(m)\n",
        "        print(f\"{m}: {getattr(mod,'__version__','?')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"{m}: NOT FOUND ({type(e).__name__}: {e})\")\n",
        "\"\"\").encode()\n",
        "\n",
        "print(\"\\n→ versions (light)\")\n",
        "sh([str(MM_BIN), \"run\", \"-p\", str(ENV_PREFIX), \"python\", \"-\"], input=mini)\n",
        "print(\"✔ bootstrap done.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YhbcJnD5LTQH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhbcJnD5LTQH",
        "outputId": "9dc2a203-e06e-40c7-fd36-86df807c3f88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import subprocess, pathlib, os\n",
        "ENV_PREFIX = pathlib.Path(\"/content/runs/run_001/micromamba/envs/retrobiocat\")\n",
        "MM_BIN = pathlib.Path(\"/content/runs/run_001/bin/micromamba\")\n",
        "print(subprocess.check_output([str(MM_BIN), \"run\", \"-p\", str(ENV_PREFIX), \"python\", \"-c\",\n",
        "                               \"from rdkit import Chem; print(bool(Chem.MolFromSmiles('CCO')))\"]).decode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SpOIlsUVxNW2",
      "metadata": {
        "id": "SpOIlsUVxNW2"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Micromamba bootstrap + nodes (clean, consolidated) -- 1\n",
        "# =========================\n",
        "\n",
        "import io, os, stat, tarfile, urllib.request, textwrap, subprocess, json, math, time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# ------------------------\n",
        "# Path helpers (per-state)\n",
        "# ------------------------\n",
        "def _paths(workdir: Path):\n",
        "    workdir = Path(workdir)\n",
        "    mm_root = workdir / \"micromamba\"\n",
        "    mm_bin  = mm_root / \"bin\" / \"micromamba\"\n",
        "    env_prefix = mm_root / \"envs\" / \"retrobiocat\"\n",
        "    return {\n",
        "        \"WORKDIR\": workdir,\n",
        "        \"MAMBA_ROOT\": mm_root,\n",
        "        \"MAMBA_BIN\": mm_bin,\n",
        "        \"ENV_PREFIX\": env_prefix,\n",
        "        \"BIN_DIR\": workdir / \"bin\",\n",
        "        \"RETRO_OUT\": workdir / \"retro_out\",\n",
        "        \"FINISH\": workdir / \"retro_finish_out\",\n",
        "    }\n",
        "\n",
        "# ---------------------------------\n",
        "# Micromamba download (safe, clean)\n",
        "# ---------------------------------\n",
        "\n",
        "\n",
        "# ---------------------------------\n",
        "# Run a command inside the env\n",
        "# ---------------------------------\n",
        "def _run_in_env(workdir: Path, argv, input_text=None, extra_env=None):\n",
        "    p = _paths(workdir)\n",
        "    mm = p[\"MAMBA_BIN\"]\n",
        "    envp = p[\"ENV_PREFIX\"]\n",
        "    cmd = [str(mm), \"run\", \"-p\", str(envp)] + list(argv)\n",
        "    env = os.environ.copy()\n",
        "    if extra_env:\n",
        "        env.update(extra_env)\n",
        "    proc = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdin=subprocess.PIPE if input_text is not None else None,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True,\n",
        "        env=env,\n",
        "    )\n",
        "    out, err = proc.communicate(input=input_text)\n",
        "    return proc.returncode, out, err\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Node: thermo_node\n",
        "#   - builds/repairs metabolite_map.csv using RDKit + matcher\n",
        "#   - tries eQuilibrator for dG′°\n",
        "# ----------------------------------------------------------\n",
        "# ---- helper: make sure RDKit is available in the *notebook kernel* (outer) ----\n",
        "def _ensure_rdkit_outer():\n",
        "    try:\n",
        "        import rdkit  # noqa: F401\n",
        "        return\n",
        "    except Exception:\n",
        "        import subprocess, sys\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rdkit-pypi\"])\n",
        "        import rdkit  # noqa: F401\n",
        "\n",
        "\n",
        "# ------------------------------- thermo_node --------------------------------\n",
        "# ---------- helpers (safe to paste multiple times) ----------\n",
        "\n",
        "def _run_in_env(env_prefix, argv, input_text=None, extra_env=None):\n",
        "    \"\"\"\n",
        "    Run a command inside the micromamba env at env_prefix.\n",
        "    Returns (rc, stdout, stderr).\n",
        "    \"\"\"\n",
        "    import os, subprocess\n",
        "    from pathlib import Path\n",
        "    mm = Path(env_prefix).parent.parent / \"bin\" / \"micromamba\"\n",
        "    cmd = [str(mm), \"run\", \"-p\", str(env_prefix)] + list(argv)\n",
        "    env = os.environ.copy()\n",
        "    if extra_env:\n",
        "        env.update(extra_env)\n",
        "    p = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdin=subprocess.PIPE if input_text is not None else None,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True,\n",
        "        env=env,\n",
        "    )\n",
        "    out, err = p.communicate(input=input_text)\n",
        "    return p.returncode, out, err\n",
        "\n",
        "\n",
        "def _ensure_equilibrator(env_prefix, state=None):\n",
        "    \"\"\"Best-effort install of equilibrator stack with safe pins.\"\"\"\n",
        "    pins = [\n",
        "        \"numpy==1.26.4\",\n",
        "        \"pandas==2.2.2\",\n",
        "        \"pint==0.22\",\n",
        "        \"equilibrator-api==0.6.0\",\n",
        "        \"equilibrator-cache==0.6.0\",\n",
        "    ]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pins)\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: pip install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "def _ensure_rdkit(env_prefix, state=None):\n",
        "    \"\"\"\n",
        "    Install RDKit quickly via wheels (rdkit-pypi).\n",
        "    This gives us Chem.MolFromSmiles and MolToInchiKey for the compound map.\n",
        "    \"\"\"\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-c\",\"import rdkit; print('rdkit_ok')\"])\n",
        "    if rc == 0 and \"rdkit_ok\" in (out or \"\"):\n",
        "        return\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"rdkit-pypi\"])\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: RDKit install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "# ------------------------------- thermo_node --------------------------------\n",
        "\n",
        "# ---------------- common helpers ----------------\n",
        "\n",
        "from pathlib import Path\n",
        "import subprocess, textwrap, os, io, tarfile, stat, time, math\n",
        "import pandas as pd\n",
        "\n",
        "WORKDIR      = Path(\"/content/runs/run_001\")\n",
        "MAMBA_ROOT   = WORKDIR / \"micromamba\"\n",
        "ENV_PREFIX   = MAMBA_ROOT / \"envs\" / \"retrobiocat\"\n",
        "MAMBA_BIN    = WORKDIR / \"bin\" / \"micromamba\"\n",
        "\n",
        "def _sh(cmd, input_text=None, check=True, env=None):\n",
        "    p = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdin=subprocess.PIPE if input_text is not None else None,\n",
        "        stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
        "        text=True, env=env\n",
        "    )\n",
        "    out, err = p.communicate(input=input_text)\n",
        "    if check and p.returncode != 0:\n",
        "        raise subprocess.CalledProcessError(p.returncode, cmd, out, err)\n",
        "    return p.returncode, out, err\n",
        "\n",
        "def _ensure_micromamba():\n",
        "    MAMBA_BIN.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if not MAMBA_BIN.exists():\n",
        "        # download micromamba tar (auto-detected by tarfile \"r:*\")\n",
        "        url = \"https://micro.mamba.pm/api/micromamba/linux-64/latest\"\n",
        "        import urllib.request\n",
        "        data = urllib.request.urlopen(url).read()\n",
        "        with tarfile.open(fileobj=io.BytesIO(data), mode=\"r:*\") as tf:\n",
        "            member = None\n",
        "            for m in tf.getmembers():\n",
        "                name = m.name.replace(\"\\\\\",\"/\")\n",
        "                if name.endswith(\"/micromamba\") and \"/bin/\" in name:\n",
        "                    member = m; break\n",
        "            if member is None:\n",
        "                for m in tf.getmembers():\n",
        "                    if m.name.split(\"/\")[-1] == \"micromamba\":\n",
        "                        member = m; break\n",
        "            if member is None:\n",
        "                raise RuntimeError(\"micromamba binary not found in archive\")\n",
        "            with tf.extractfile(member) as src, open(MAMBA_BIN, \"wb\") as dst:\n",
        "                dst.write(src.read())\n",
        "        MAMBA_BIN.chmod(MAMBA_BIN.stat().st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)\n",
        "    os.environ[\"MAMBA_ROOT_PREFIX\"] = str(MAMBA_ROOT)\n",
        "\n",
        "def _mm_run(argv, input_text=None):\n",
        "    return _sh([str(MAMBA_BIN), \"run\", \"-p\", str(ENV_PREFIX)] + list(argv), input_text=input_text, check=False)\n",
        "\n",
        "def _ensure_env_and_pins(state=None):\n",
        "    _ensure_micromamba()\n",
        "    # 1) create env if missing\n",
        "    if not ENV_PREFIX.exists():\n",
        "        _sh([str(MAMBA_BIN), \"create\", \"-y\", \"-p\", str(ENV_PREFIX), \"-c\", \"conda-forge\", \"python=3.10\", \"pip\"])\n",
        "    # 2) pins (fast wheels)\n",
        "    _mm_run([\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\",\n",
        "             \"pip\",\"setuptools\",\"wheel\",\n",
        "             \"numpy==1.26.4\",\"pandas==2.2.2\",\"pint==0.22\"])\n",
        "    # 3) equilibrator stack\n",
        "    _mm_run([\"python\",\"-m\",\"pip\",\"install\",\"-q\",\n",
        "             \"equilibrator-api==0.6.0\",\"equilibrator-cache==0.6.0\"])\n",
        "    # 4) RDKit (pip build is fine here)\n",
        "    _mm_run([\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"rdkit-pypi\"])\n",
        "    # 5) cobra stack (modern)\n",
        "    _mm_run([\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"cobra==0.29.0\",\"optlang>=1.8.0\",\"swiglpk>=5.0.10\"])\n",
        "    # quick sanity (optional)\n",
        "    rc, out, _ = _mm_run([\"python\",\"- <<'PY'\"], input_text=textwrap.dedent(\"\"\"\n",
        "        import importlib, sys\n",
        "        mods = (\"equilibrator_api\",\"equilibrator_cache\",\"rdkit\",\"cobra\",\"pandas\",\"numpy\")\n",
        "        for m in mods:\n",
        "            try:\n",
        "                mod=importlib.import_module(m)\n",
        "                print(m, \"OK\", getattr(mod,\"__version__\",\"?\"))\n",
        "            except Exception as e:\n",
        "                print(m, \"MISS\", type(e).__name__)\n",
        "    PY\n",
        "    \"\"\"))\n",
        "    if state is not None and out:\n",
        "        for ln in out.splitlines():\n",
        "            if ln.strip():\n",
        "                state.setdefault(\"logs\", []).append(\"env: \" + ln.strip())\n",
        "\n",
        "# ---------------- thermo_node ----------------\n",
        "def _run_in_env(env_prefix, argv, input_text=None, extra_env=None):\n",
        "    \"\"\"Run argv inside the micromamba env at env_prefix. Return (rc, out, err).\"\"\"\n",
        "    import os, subprocess\n",
        "    from pathlib import Path\n",
        "    mm = Path(env_prefix).parent.parent / \"bin\" / \"micromamba\"\n",
        "    cmd = [str(mm), \"run\", \"-p\", str(env_prefix)] + list(argv)\n",
        "    env = os.environ.copy()\n",
        "    if extra_env:\n",
        "        env.update(extra_env)\n",
        "    p = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdin=subprocess.PIPE if input_text is not None else None,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True,\n",
        "        env=env,\n",
        "    )\n",
        "    out, err = p.communicate(input=input_text)\n",
        "    return p.returncode, out, err\n",
        "\n",
        "\n",
        "def _ensure_eq_and_rdkit(env_prefix, state=None):\n",
        "    \"\"\"Idempotent install of equilibrator stack and RDKit wheels.\"\"\"\n",
        "    pins = [\n",
        "        \"pip\", \"setuptools\", \"wheel\",\n",
        "        \"numpy==1.26.4\", \"pandas==2.2.2\", \"pint==0.22\",\n",
        "        \"equilibrator-api==0.6.0\", \"equilibrator-cache==0.6.0\",\n",
        "        \"rdkit-pypi==2022.9.5\",\n",
        "    ]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pins)\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: pip install had warnings (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Node: simulate_gem_node -new\n",
        "#   - runs cobra FBA in env; writes CSV; tolerates missing cobra\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "def simulate_gem_node(state):\n",
        "    \"\"\"\n",
        "    Run a simple GEM simulation (FBA) inside the micromamba env.\n",
        "    - Tries to load the SBML model and run an FBA.\n",
        "    - Writes retro_finish_out/sim_fba_summary.csv  (always).\n",
        "    - Gracefully degrades if cobra isn't available or model fails to load.\n",
        "\n",
        "    Output CSV columns (best effort):\n",
        "      pathway_tag, status, objective_value, note\n",
        "    \"\"\"\n",
        "    from pathlib import Path\n",
        "    import time\n",
        "    import pandas as pd\n",
        "\n",
        "    def log(msg):\n",
        "        print(msg)\n",
        "        state.setdefault(\"logs\", []).append(msg)\n",
        "\n",
        "    t0 = time.time()\n",
        "    log(\"▶ start simulate_gem\")\n",
        "\n",
        "    workdir = Path(state[\"workdir\"])\n",
        "    finish  = workdir / \"retro_finish_out\"\n",
        "    finish.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    sbml_path = Path(state.get(\"sbml_model_path\", \"/content/models/iML1515.xml\"))\n",
        "    steps_csv = finish / \"steps_annotated.csv\"\n",
        "    if not steps_csv.exists():\n",
        "        # fall back to enzyme-plan if thermo didn’t run\n",
        "        alt = finish / \"steps_enzyme_plan.csv\"\n",
        "        if alt.exists():\n",
        "            steps_csv = alt\n",
        "\n",
        "    # ensure the env (no workdir arg!)\n",
        "    _ensure_env_and_pins(state=state)\n",
        "\n",
        "    # small helper to choose a pathway (purely cosmetic; not required for FBA)\n",
        "    pathway = \"P001\"\n",
        "    try:\n",
        "        dfp = pd.read_csv(steps_csv)\n",
        "        if \"pathway_tag\" in dfp.columns and len(dfp):\n",
        "            pathway = str(dfp[\"pathway_tag\"].iloc[0])\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Write a stub result quickly in case runner fails; we’ll overwrite on success.\n",
        "    summary_path = finish / \"sim_fba_summary.csv\"\n",
        "    pd.DataFrame([{\n",
        "        \"pathway_tag\": pathway,\n",
        "        \"status\": \"not_run\",\n",
        "        \"objective_value\": float(\"nan\"),\n",
        "        \"note\": \"pre-run stub\"\n",
        "    }]).to_csv(summary_path, index=False)\n",
        "\n",
        "    # COBRA runner (isolated)\n",
        "    runner = r\"\"\"\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "SBML   = Path(\"__SBML__\")\n",
        "OUT    = Path(\"__OUT__\")\n",
        "PATHWY = \"__PATHWAY__\"\n",
        "\n",
        "def write(rows):\n",
        "    pd.DataFrame(rows, columns=[\"pathway_tag\",\"status\",\"objective_value\",\"note\"]).to_csv(OUT, index=False)\n",
        "\n",
        "try:\n",
        "    import cobra\n",
        "    from cobra.io import read_sbml_model\n",
        "except Exception as e:\n",
        "    write([{\"pathway_tag\": PATHWY, \"status\": \"cobra_not_available\",\n",
        "            \"objective_value\": float(\"nan\"), \"note\": f\"{type(e).__name__}: {e}\"}])\n",
        "    raise SystemExit(0)\n",
        "\n",
        "# Try to load the model\n",
        "try:\n",
        "    model = read_sbml_model(str(SBML))\n",
        "except Exception as e:\n",
        "    write([{\"pathway_tag\": PATHWY, \"status\": \"model_load_failed\",\n",
        "            \"objective_value\": float(\"nan\"), \"note\": f\"{type(e).__name__}: {e}\"}])\n",
        "    raise SystemExit(0)\n",
        "\n",
        "# Choose an objective\n",
        "# Common biomass rxn for iML1515; fallback to existing objective or first reaction\n",
        "obj = None\n",
        "for cand in [\n",
        "    \"BIOMASS_Ec_iML1515_core_75p37M\",\n",
        "    \"BIOMASS_Ec_iML1515_WT_75p37M\",\n",
        "    \"BIOMASS_Ecoli_core_w_GAM\"\n",
        "]:\n",
        "    if cand in model.reactions:\n",
        "        obj = model.reactions.get_by_id(cand)\n",
        "        break\n",
        "if obj is None:\n",
        "    try:\n",
        "        obj = model.objective.expression.free_symbols.pop()._reaction  # best-effort\n",
        "    except Exception:\n",
        "        obj = next(iter(model.reactions)) if len(model.reactions) else None\n",
        "\n",
        "if obj is None:\n",
        "    write([{\"pathway_tag\": PATHWY, \"status\": \"no_objective\",\n",
        "            \"objective_value\": float(\"nan\"), \"note\": \"No reactions/objective in model\"}])\n",
        "    raise SystemExit(0)\n",
        "\n",
        "# Set objective and optimize\n",
        "try:\n",
        "    model.objective = obj\n",
        "    sol = model.optimize()  # default maximize\n",
        "    val = float(sol.objective_value) if sol and sol.status in (\"optimal\",\"time_limit\") else float(\"nan\")\n",
        "    status = getattr(sol, \"status\", \"unknown\") or \"unknown\"\n",
        "    note = f\"objective={obj.id}\"\n",
        "    write([{\"pathway_tag\": PATHWY, \"status\": status, \"objective_value\": val, \"note\": note}])\n",
        "except Exception as e:\n",
        "    write([{\"pathway_tag\": PATHWY, \"status\": \"opt_failed\",\n",
        "            \"objective_value\": float(\"nan\"), \"note\": f\"{type(e).__name__}: {e}\"}])\n",
        "\"\"\"\n",
        "\n",
        "    runner = runner.replace(\"__SBML__\", str(sbml_path).replace(\"\\\\\",\"\\\\\\\\\"))\n",
        "    runner = runner.replace(\"__OUT__\", str(summary_path).replace(\"\\\\\",\"\\\\\\\\\"))\n",
        "    runner = runner.replace(\"__PATHWAY__\", pathway)\n",
        "\n",
        "    rc, out, err = _mm_run([\"python\",\"-\"], input_text=runner)\n",
        "\n",
        "    if rc != 0 and err:\n",
        "        # keep the stub file but add an informative line\n",
        "        state.setdefault(\"logs\", []).append(\"simulate_gem: runner failed → stub preserved\")\n",
        "        state[\"logs\"].append((err or \"\").strip().splitlines()[-1])\n",
        "\n",
        "    # log a compact result summary\n",
        "    try:\n",
        "        dfres = pd.read_csv(summary_path)\n",
        "        if not dfres.empty:\n",
        "            msg = f\"simulate_gem: results={summary_path}\"\n",
        "            # if note is long, don’t flood the logs\n",
        "            state.setdefault(\"logs\", []).append(msg)\n",
        "            print(msg)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    print(f\"✔ done simulate_gem ({time.time()-t0:.1f}s)\")\n",
        "\n",
        "    # publish artifact\n",
        "    state.setdefault(\"artifacts\", []).append(str(summary_path))\n",
        "    return state\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h4S9kR7Dj70k",
      "metadata": {
        "id": "h4S9kR7Dj70k"
      },
      "outputs": [],
      "source": [
        "# ---------------------- helpers used by thermo_node ----------------------2\n",
        "\n",
        "def _run_in_env(env_prefix, argv, input_text=None, extra_env=None):\n",
        "    \"\"\"\n",
        "    Run a command inside the micromamba env at env_prefix.\n",
        "    Returns (rc, stdout, stderr).\n",
        "    \"\"\"\n",
        "    import os, subprocess\n",
        "    from pathlib import Path\n",
        "    mm = Path(env_prefix).parent.parent / \"bin\" / \"micromamba\"\n",
        "    cmd = [str(mm), \"run\", \"-p\", str(env_prefix)] + list(argv)\n",
        "    env = os.environ.copy()\n",
        "    if extra_env:\n",
        "        env.update(extra_env)\n",
        "    p = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdin=subprocess.PIPE if input_text is not None else None,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True,\n",
        "        env=env,\n",
        "    )\n",
        "    out, err = p.communicate(input=input_text)\n",
        "    return p.returncode, out, err\n",
        "\n",
        "\n",
        "def _ensure_equilibrator(env_prefix, state=None):\n",
        "    \"\"\"Best-effort, idempotent install of equilibrator stack with safe pins.\"\"\"\n",
        "    pins = [\n",
        "        \"pip\", \"setuptools\", \"wheel\",\n",
        "        \"numpy==1.26.4\",\n",
        "        \"pandas==2.2.2\",\n",
        "        \"pint==0.22\",\n",
        "        \"equilibrator-api==0.6.0\",\n",
        "        \"equilibrator-cache==0.6.0\",\n",
        "    ]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pins)\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: pip install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "def _ensure_rdkit(env_prefix, state=None):\n",
        "    \"\"\"\n",
        "    Install RDKit into the same micromamba env (conda-forge build).\n",
        "    \"\"\"\n",
        "    # Quick ping\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-c\",\"import rdkit; print('rdkit_ok')\"])\n",
        "    if rc == 0 and \"rdkit_ok\" in (out or \"\"):\n",
        "        return\n",
        "    # Install from conda-forge (works well in micromamba env)\n",
        "    rc, out, err = _run_in_env(\n",
        "        env_prefix,\n",
        "        [\"micromamba\",\"install\",\"-y\",\"-p\",str(env_prefix),\"-c\",\"conda-forge\",\"rdkit=2022.09.5\"]\n",
        "    )\n",
        "    if rc != 0:\n",
        "        # Fallback to rdkit-pypi if conda install is unavailable\n",
        "        rc2, out2, err2 = _run_in_env(\n",
        "            env_prefix,\n",
        "            [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"rdkit-pypi\"]\n",
        "        )\n",
        "        if state is not None and rc2 != 0:\n",
        "            state.setdefault(\"logs\", []).append(\"thermo: RDKit install warning (continuing)\")\n",
        "            if err2:\n",
        "                state[\"logs\"].append(err2.strip().splitlines()[-1])\n",
        "\n",
        "def _canon_smiles(smi):\n",
        "    \"\"\"Return a canonical isomeric SMILES for stable PubChem lookups.\"\"\"\n",
        "    try:\n",
        "        from rdkit import Chem\n",
        "        m = Chem.MolFromSmiles(smi)\n",
        "        if m is None:\n",
        "            return \"\"\n",
        "        return Chem.MolToSmiles(m, isomericSmiles=True, canonical=True)\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def _pubchem_cid_from_smiles(smi, session=None):\n",
        "    \"\"\"SMILES -> CID via PUG REST (tolerant).\"\"\"\n",
        "    smi = _canon_smiles(smi) or smi\n",
        "    if not smi:\n",
        "        return None\n",
        "    import urllib.parse\n",
        "    enc = urllib.parse.quote(smi, safe=\"\")\n",
        "    js = _pc_json(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/smiles/{enc}/cids/JSON\",\n",
        "                  session=session)\n",
        "    try:\n",
        "        cids = js.get(\"IdentifierList\", {}).get(\"CID\", []) if js else []\n",
        "        if cids:\n",
        "            return int(cids[0])\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "\n",
        "def thermo_node(state):\n",
        "    \"\"\"\n",
        "    Compute thermodynamics and write:\n",
        "      - retro_finish_out/steps_annotated.csv\n",
        "      - retro_finish_out/pathways_ranked_final.csv\n",
        "      - retro_finish_out/metabolite_map.csv\n",
        "      - retro_finish_out/_thermo_metabolite_map.json\n",
        "\n",
        "    Mapping strategy per token (first success wins):\n",
        "      1) explicit IDs in token (KEGG Cxxxxx or CHEBI:nnn) via CompoundMatcher\n",
        "      2) literal InChIKey inside token via CompoundMatcher\n",
        "      3) RDKit -> InChIKey, then CompoundMatcher\n",
        "      4) RDKit -> InChIKey only (record IK even if no CID)\n",
        "      5) PubChem: IK -> CID -> KEGG\n",
        "      6) PubChem: SMILES -> CID -> KEGG     <-- NEW\n",
        "      7) PubChem: CAS -> CID -> KEGG        <-- NEW\n",
        "      8) name match via CompoundMatcher\n",
        "      9) unmapped\n",
        "\n",
        "    Also:\n",
        "      - Prefer tokens from `substrates`/`products` columns; fallback to reaction_smiles.\n",
        "      - Drop tiny/query-like fragments (<=3 heavy atoms) before attempting resolution.\n",
        "    \"\"\"\n",
        "    import time, math, pandas as pd\n",
        "    from pathlib import Path\n",
        "\n",
        "    def _log(msg):\n",
        "        print(msg)\n",
        "        state.setdefault(\"logs\", []).append(msg)\n",
        "\n",
        "    t0 = time.time()\n",
        "    _log(\"▶ start thermo\")\n",
        "\n",
        "    workdir   = Path(state[\"workdir\"])\n",
        "    finish    = workdir / \"retro_finish_out\"\n",
        "    retro_out = workdir / \"retro_out\"\n",
        "    finish.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    env_prefix = workdir / \"micromamba\" / \"envs\" / \"retrobiocat\"\n",
        "\n",
        "    # Ensure deps in env (idempotent)\n",
        "    _run_in_env(env_prefix, [\n",
        "        \"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\",\n",
        "        \"pip\",\"setuptools\",\"wheel\",\n",
        "        \"equilibrator-api==0.6.0\",\"equilibrator-cache==0.6.0\",\n",
        "        \"numpy==1.26.4\",\"pandas==2.2.2\",\"pint==0.22\",\n",
        "        \"requests>=2.31.0\"\n",
        "    ])\n",
        "    # RDKit via conda if missing\n",
        "    _run_in_env(env_prefix, [\n",
        "        \"bash\",\"-lc\",\n",
        "        f'set -e; python -c \"import rdkit\" 2>/dev/null || micromamba install -y -p \"{env_prefix}\" -c conda-forge rdkit=2022.09.5 >/dev/null'\n",
        "    ])\n",
        "\n",
        "    # choose steps table (prefer extractor output that already has selenzyme_url)\n",
        "    steps_csv = finish / \"steps_enzyme_plan.csv\"\n",
        "    if not steps_csv.exists():\n",
        "        steps_csv = retro_out / \"steps.csv\"\n",
        "\n",
        "    if not steps_csv.exists():\n",
        "        _log(\"thermo: no steps table found; creating empty placeholders\")\n",
        "        (finish / \"steps_annotated.csv\").write_text(\"\")\n",
        "        (finish / \"pathways_ranked_final.csv\").write_text(\"\")\n",
        "        _log(f\"✔ done thermo ({time.time()-t0:.1f}s)\")\n",
        "        return state\n",
        "\n",
        "    # Embedded runner executed inside the env\n",
        "    runner = r\"\"\"\n",
        "import os, re, json, math, time\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "STEPS_CSV = Path(\"__STEPS__\")\n",
        "FINISH    = Path(\"__FINISH__\")\n",
        "\n",
        "OUT_STEPS    = FINISH / \"steps_annotated.csv\"\n",
        "OUT_RANK     = FINISH / \"pathways_ranked_final.csv\"\n",
        "OUT_MAP_CSV  = FINISH / \"metabolite_map.csv\"\n",
        "OUT_MAP_JSON = FINISH / \"_thermo_metabolite_map.json\"\n",
        "\n",
        "# Load steps\n",
        "df = pd.read_csv(STEPS_CSV)\n",
        "for col in [\"pathway_tag\",\"step_idx\",\"reaction_smiles\",\"substrates\",\"products\",\n",
        "            \"rbc2_score\",\"precedent_best_similarity\",\"selenzyme_url\"]:\n",
        "    if col not in df.columns:\n",
        "        if col in (\"rbc2_score\",\"precedent_best_similarity\"):\n",
        "            df[col] = 0.0\n",
        "        else:\n",
        "            df[col] = \"\"\n",
        "\n",
        "# --- Tokenization helpers ---\n",
        "def _split_rxn(r):\n",
        "    if not isinstance(r, str) or \">>\" not in r:\n",
        "        return [], []\n",
        "    L, R = r.split(\">>\", 1)\n",
        "    subs  = [s.strip() for s in L.split(\".\") if s.strip()]\n",
        "    prods = [p.strip() for p in R.split(\".\") if p.strip()]\n",
        "    return subs, prods\n",
        "\n",
        "def _split_field(val):\n",
        "    # supports dot '.' or semicolon ';' separation\n",
        "    if not isinstance(val, str) or not val.strip():\n",
        "        return []\n",
        "    parts = []\n",
        "    for sep in (\".\",\";\"):\n",
        "        if sep in val:\n",
        "            parts = [p.strip() for p in val.split(sep)]\n",
        "            break\n",
        "    if not parts:\n",
        "        parts = [val.strip()]\n",
        "    return [p for p in parts if p]\n",
        "\n",
        "# Prefer substrates/products columns if present and non-empty;\n",
        "# fallback to reaction_smiles tokenization.\n",
        "raw_tokens = []\n",
        "if (df[\"substrates\"].astype(str).str.strip().ne(\"\").any() or\n",
        "    df[\"products\"].astype(str).str.strip().ne(\"\").any()):\n",
        "    for a,b in zip(df.get(\"substrates\",\"\").astype(str), df.get(\"products\",\"\").astype(str)):\n",
        "        raw_tokens.extend(_split_field(a))\n",
        "        raw_tokens.extend(_split_field(b))\n",
        "else:\n",
        "    for rxn in df.get(\"reaction_smiles\", pd.Series([\"\"]*len(df))).astype(str).fillna(\"\"):\n",
        "        L, R = _split_rxn(rxn)\n",
        "        raw_tokens.extend(L); raw_tokens.extend(R)\n",
        "\n",
        "# --- RDKit helpers ---\n",
        "def _smiles_to_inchikey(smi):\n",
        "    try:\n",
        "        from rdkit import Chem\n",
        "        m = Chem.MolFromSmiles(smi)\n",
        "        if m is None:\n",
        "            return \"\"\n",
        "        return Chem.MolToInchiKey(m) or \"\"\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def _heavy_atoms(smi):\n",
        "    try:\n",
        "        from rdkit import Chem\n",
        "        m = Chem.MolFromSmiles(smi)\n",
        "        return int(m.GetNumHeavyAtoms()) if m is not None else 0\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "# Filter out tiny/query-like fragments (≤3 heavy atoms)\n",
        "tokens = sorted({t for t in raw_tokens if _heavy_atoms(t) > 3})\n",
        "\n",
        "# Try to import CompoundMatcher (optional)\n",
        "matcher = None\n",
        "try:\n",
        "    try:\n",
        "        from equilibrator_cache.match import CompoundMatcher\n",
        "    except Exception:\n",
        "        from equilibrator_cache.matching import CompoundMatcher\n",
        "    try:\n",
        "        matcher = CompoundMatcher()\n",
        "    except Exception:\n",
        "        matcher = None\n",
        "except Exception:\n",
        "    matcher = None\n",
        "\n",
        "# --- PubChem helpers (tolerant) ---\n",
        "def _pc_get_json(url, timeout=6.0, session=None):\n",
        "    try:\n",
        "        import requests\n",
        "        s = session or requests.Session()\n",
        "        s.headers.update({\"User-Agent\": \"dbtl-thermo/0.3\"})\n",
        "        r = s.get(url, timeout=timeout)\n",
        "        if r.status_code == 200:\n",
        "            return r.json()\n",
        "    except Exception:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "def _pubchem_kegg_from_cid(cid, timeout=6.0, session=None):\n",
        "    js = _pc_get_json(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/xrefs/KEGG/JSON\", timeout, session)\n",
        "    if js:\n",
        "        info = js.get(\"InformationList\", {}).get(\"Information\", [])\n",
        "        if info:\n",
        "            klist = info[0].get(\"KEGG\") or []\n",
        "            for k in klist:\n",
        "                if isinstance(k, str) and re.fullmatch(r\"C\\\\d{5}\", k):\n",
        "                    return k\n",
        "    js = _pc_get_json(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/synonyms/JSON\", timeout, session)\n",
        "    if js:\n",
        "        info = js.get(\"InformationList\", {}).get(\"Information\", [])\n",
        "        if info:\n",
        "            syns = info[0].get(\"Synonym\") or []\n",
        "            for s in syns:\n",
        "                if isinstance(s, str) and re.fullmatch(r\"C\\\\d{5}\", s):\n",
        "                    return s\n",
        "    return \"\"\n",
        "\n",
        "def _pubchem_kegg_from_inchikey(ik, timeout=6.0, session=None):\n",
        "    js = _pc_get_json(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/inchikey/{ik}/cids/JSON\", timeout, session)\n",
        "    cid = None\n",
        "    try:\n",
        "        cid_list = js.get(\"IdentifierList\", {}).get(\"CID\", []) if js else []\n",
        "        if cid_list:\n",
        "            cid = int(cid_list[0])\n",
        "    except Exception:\n",
        "        cid = None\n",
        "    if cid is None:\n",
        "        js = _pc_get_json(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/inchikey/{ik}/cids/JSON?match=exact\", timeout, session)\n",
        "        try:\n",
        "            cid_list = js.get(\"IdentifierList\", {}).get(\"CID\", []) if js else []\n",
        "            if cid_list:\n",
        "                cid = int(cid_list[0])\n",
        "        except Exception:\n",
        "            cid = None\n",
        "    if cid is None:\n",
        "        return \"\"\n",
        "    return _pubchem_kegg_from_cid(cid, timeout, session)\n",
        "\n",
        "def _pubchem_kegg_from_smiles(smi, timeout=6.0, session=None):\n",
        "    # SMILES → CID → KEGG  (identity search)\n",
        "    js = _pc_get_json(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/smiles/{smi}/cids/JSON?search=identity\",\n",
        "                      timeout, session)\n",
        "    cid = None\n",
        "    try:\n",
        "        cid_list = js.get(\"IdentifierList\", {}).get(\"CID\", []) if js else []\n",
        "        if cid_list:\n",
        "            cid = int(cid_list[0])\n",
        "    except Exception:\n",
        "        cid = None\n",
        "    if cid is None:\n",
        "        return \"\"\n",
        "    return _pubchem_kegg_from_cid(cid, timeout, session)\n",
        "\n",
        "def _pubchem_kegg_from_cas(cas_rn, timeout=6.0, session=None):\n",
        "    js = _pc_get_json(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/xref/RN/{cas_rn}/cids/JSON\", timeout, session)\n",
        "    cid = None\n",
        "    try:\n",
        "        cid_list = js.get(\"IdentifierList\", {}).get(\"CID\", []) if js else []\n",
        "        if cid_list:\n",
        "            cid = int(cid_list[0])\n",
        "    except Exception:\n",
        "        cid = None\n",
        "    if cid is None:\n",
        "        return \"\"\n",
        "    return _pubchem_kegg_from_cid(cid, timeout, session)\n",
        "\n",
        "_cas_re = re.compile(r\"\\\\b\\\\d{2,7}-\\\\d{2}-\\\\d\\\\b\")\n",
        "\n",
        "route_counts = {\n",
        "    \"via_explicit_id\": 0,\n",
        "    \"via_inchikey_literal\": 0,\n",
        "    \"via_rdkit_inchikey\": 0,\n",
        "    \"via_rdkit_inchikey_only\": 0,\n",
        "    \"via_pubchem_kegg\": 0,\n",
        "    \"via_pubchem_smiles\": 0,\n",
        "    \"via_pubchem_cas\": 0,\n",
        "    \"via_match_smiles\": 0,\n",
        "    \"via_name\": 0,\n",
        "    \"unmapped\": 0,\n",
        "}\n",
        "\n",
        "def _best_match(tok):\n",
        "    # Returns: dict(token, cid, name, inchikey)\n",
        "    # 1) explicit KEGG/CHEBI in token\n",
        "    try:\n",
        "        if matcher is not None:\n",
        "            m = re.search(r\"(CHEBI:\\\\d+|C\\\\d{5})\", tok, flags=re.I)\n",
        "            if m:\n",
        "                key = m.group(1)\n",
        "                try:\n",
        "                    if key.upper().startswith(\"CHEBI:\"):\n",
        "                        res = matcher.match_chebi_id(key.upper())\n",
        "                    else:\n",
        "                        res = matcher.match_kegg_id(key.upper())\n",
        "                    if res:\n",
        "                        route_counts[\"via_explicit_id\"] += 1\n",
        "                        return {\"token\": tok,\n",
        "                                \"cid\": getattr(res, \"cid\", \"\") or \"\",\n",
        "                                \"name\": getattr(res, \"name\", \"\") or \"\",\n",
        "                                \"inchikey\": getattr(res, \"inchi_key\", \"\") or \"\"}\n",
        "                except Exception:\n",
        "                    pass\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 2) literal IK in token\n",
        "    try:\n",
        "        if matcher is not None:\n",
        "            m2 = re.search(r\"[A-Z]{14}-[A-Z]{10}-[A-Z]\", tok)\n",
        "            if m2:\n",
        "                res = matcher.match_inchi_key(m2.group(0))\n",
        "                if res:\n",
        "                    route_counts[\"via_inchikey_literal\"] += 1\n",
        "                    return {\"token\": tok,\n",
        "                            \"cid\": getattr(res, \"cid\", \"\") or \"\",\n",
        "                            \"name\": getattr(res, \"name\", \"\") or \"\",\n",
        "                            \"inchikey\": getattr(res, \"inchi_key\", \"\") or \"\"}\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 3) RDKit IK then matcher\n",
        "    ik = \"\"\n",
        "    try:\n",
        "        ik = _smiles_to_inchikey(tok)\n",
        "        if ik and matcher is not None:\n",
        "            res = matcher.match_inchi_key(ik)\n",
        "            if res:\n",
        "                route_counts[\"via_rdkit_inchikey\"] += 1\n",
        "                return {\"token\": tok,\n",
        "                        \"cid\": getattr(res, \"cid\", \"\") or \"\",\n",
        "                        \"name\": getattr(res, \"name\", \"\") or \"\",\n",
        "                        \"inchikey\": getattr(res, \"inchi_key\", \"\") or ik}\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 4/5) RDKit IK only + PubChem IK->KEGG\n",
        "    if ik:\n",
        "        route_counts[\"via_rdkit_inchikey_only\"] += 1\n",
        "        kegg = _pubchem_kegg_from_inchikey(ik)\n",
        "        if kegg:\n",
        "            route_counts[\"via_pubchem_kegg\"] += 1\n",
        "            return {\"token\": tok, \"cid\": kegg, \"name\": \"\", \"inchikey\": ik}\n",
        "\n",
        "    # 6) PubChem SMILES → KEGG (identity)\n",
        "    try:\n",
        "        kegg = _pubchem_kegg_from_smiles(tok)\n",
        "        if kegg:\n",
        "            route_counts[\"via_pubchem_smiles\"] += 1\n",
        "            return {\"token\": tok, \"cid\": kegg, \"name\": \"\", \"inchikey\": ik or _smiles_to_inchikey(tok)}\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 7) CAS in token → KEGG\n",
        "    try:\n",
        "        m3 = _cas_re.search(tok)\n",
        "        if m3:\n",
        "            cas = m3.group(0)\n",
        "            kegg = _pubchem_kegg_from_cas(cas)\n",
        "            if kegg:\n",
        "                route_counts[\"via_pubchem_cas\"] += 1\n",
        "                return {\"token\": tok, \"cid\": kegg, \"name\": \"\", \"inchikey\": ik or \"\"}\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 8) name match (very last resort)\n",
        "    try:\n",
        "        if matcher is not None:\n",
        "            res = matcher.match_name(tok)\n",
        "            if res:\n",
        "                route_counts[\"via_name\"] += 1\n",
        "                return {\"token\": tok,\n",
        "                        \"cid\": getattr(res, \"cid\", \"\") or \"\",\n",
        "                        \"name\": getattr(res, \"name\", \"\") or \"\",\n",
        "                        \"inchikey\": getattr(res, \"inchi_key\", \"\") or \"\"}\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    route_counts[\"unmapped\"] += 1\n",
        "    return {\"token\": tok, \"cid\": \"\", \"name\": \"\", \"inchikey\": ik or \"\"}\n",
        "\n",
        "map_rows = [_best_match(t) for t in tokens]\n",
        "\n",
        "if map_rows:\n",
        "    map_df = pd.DataFrame(map_rows, columns=[\"token\",\"inchikey\",\"cid\",\"name\"])\n",
        "    map_df.to_csv(OUT_MAP_CSV, index=False)\n",
        "    with open(OUT_MAP_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"generated_from\": str(STEPS_CSV),\n",
        "                   \"routes\": route_counts,\n",
        "                   \"rows\": map_rows}, f, indent=2)\n",
        "\n",
        "# Equilibrator\n",
        "have_eq = False\n",
        "try:\n",
        "    from equilibrator_api import ComponentContribution, Reaction\n",
        "    cc = ComponentContribution()\n",
        "    have_eq = True\n",
        "except Exception:\n",
        "    cc = None\n",
        "\n",
        "cid_by_token = {r[\"token\"]: r.get(\"cid\",\"\") for r in map_rows}\n",
        "\n",
        "def _stoich_from_rxn(rxn):\n",
        "    if not isinstance(rxn, str) or \">>\" not in rxn:\n",
        "        return None\n",
        "    L, R = _split_rxn(rxn)\n",
        "    st = {}\n",
        "    for s in L:\n",
        "        cid = cid_by_token.get(s, \"\")\n",
        "        if not cid: return None\n",
        "        st[cid] = st.get(cid, 0) - 1\n",
        "    for p in R:\n",
        "        cid = cid_by_token.get(p, \"\")\n",
        "        if not cid: return None\n",
        "        st[cid] = st.get(cid, 0) + 1\n",
        "    return st\n",
        "\n",
        "pH, I, pMg, tempK, margin = 7.5, 0.25, 3.0, 298.15, 0.0\n",
        "dGs, dGsig, passf, form = [], [], [], []\n",
        "matched = 0\n",
        "\n",
        "for rxn in df.get(\"reaction_smiles\", pd.Series([\"\"]*len(df))).astype(str).fillna(\"\"):\n",
        "    st = _stoich_from_rxn(rxn)\n",
        "    if have_eq and st:\n",
        "        try:\n",
        "            r = Reaction(st)\n",
        "            dG0, dG0_unc = cc.standard_dg_prime(r, pH=pH, ionic_strength=I, pMg=pMg, temperature=tempK)\n",
        "            dGs.append(float(dG0)); dGsig.append(float(dG0_unc))\n",
        "            passf.append(bool((float(dG0) + margin) <= 0.0))\n",
        "            form.append(\"eq\")\n",
        "            matched += 1\n",
        "        except Exception:\n",
        "            dGs.append(math.nan); dGsig.append(math.nan); passf.append(False); form.append(\"\")\n",
        "    else:\n",
        "        dGs.append(math.nan); dGsig.append(math.nan); passf.append(False); form.append(\"\")\n",
        "\n",
        "df[\"dGprime_kJ_per_mol\"]   = dGs\n",
        "df[\"uncert_kJ_per_mol\"]    = dGsig\n",
        "df[\"thermo_pass\"]          = passf\n",
        "df[\"equilibrator_formula\"] = form\n",
        "df.to_csv(OUT_STEPS, index=False)\n",
        "\n",
        "# Rank (tolerant)\n",
        "tmp = df.copy()\n",
        "tmp[\"rbc2_score\"] = pd.to_numeric(tmp.get(\"rbc2_score\", 0.0), errors=\"coerce\").fillna(0.0)\n",
        "tmp[\"precedent_best_similarity\"] = pd.to_numeric(tmp.get(\"precedent_best_similarity\", 0.0), errors=\"coerce\").fillna(0.0)\n",
        "tmp[\"thermo_pass\"] = tmp.get(\"thermo_pass\", False)\n",
        "\n",
        "agg = tmp.groupby(\"pathway_tag\").agg(\n",
        "    steps_count=(\"step_idx\",\"max\"),\n",
        "    sum_rbc2=(\"rbc2_score\",\"sum\"),\n",
        "    sum_prec_sim=(\"precedent_best_similarity\",\"sum\"),\n",
        "    n_thermo_pass=(\"thermo_pass\",\"sum\"),\n",
        ").reset_index()\n",
        "\n",
        "agg[\"rank_score\"] = (\n",
        "    agg[\"sum_rbc2\"] + 0.2*agg[\"sum_prec_sim\"] + 0.5*agg[\"n_thermo_pass\"] - 0.1*agg[\"steps_count\"]\n",
        ")\n",
        "\n",
        "ranked = agg.sort_values(\n",
        "    [\"rank_score\",\"sum_rbc2\",\"sum_prec_sim\",\"n_thermo_pass\",\"steps_count\"],\n",
        "    ascending=[False, False, False, False, True]\n",
        ").reset_index(drop=True)\n",
        "ranked.to_csv(OUT_RANK, index=False)\n",
        "\n",
        "# Logging\n",
        "cid_avail = sum(1 for r in map_rows if (r.get(\"cid\",\"\") or \"\").startswith(\"C\"))\n",
        "ik_avail  = sum(1 for r in map_rows if r.get(\"inchikey\",\"\"))\n",
        "print(f\"thermo: token IDs available for {cid_avail} / {len(tokens)} tokens\")\n",
        "print(f\"thermo: id routes: {route_counts}\")\n",
        "\n",
        "# Show examples if IK only and no KEGG\n",
        "if route_counts.get(\"via_rdkit_inchikey_only\",0) > 0 and (\n",
        "    route_counts.get(\"via_pubchem_kegg\",0) + route_counts.get(\"via_pubchem_smiles\",0) + route_counts.get(\"via_pubchem_cas\",0)\n",
        ") == 0:\n",
        "    ex = [r[\"token\"] for r in map_rows if r.get(\"inchikey\",\"\") and not (r.get(\"cid\",\"\") or \"\").startswith(\"C\")][:5]\n",
        "    if ex:\n",
        "        print(\"thermo: NOTE – RDKit produced InChIKeys but none resolved to KEGG via PubChem.\")\n",
        "        print(f\"thermo: example tokens with IK but no KEGG (first 5): {ex}\")\n",
        "\n",
        "print(\"thermo: equilibrator ran in env\" if have_eq else \"thermo: equilibrator not available\")\n",
        "print(\"thermo: steps evaluable %d / %d\" % (matched, len(df)))\n",
        "\"\"\".lstrip(\"\\n\")\n",
        "\n",
        "    # inject paths\n",
        "    runner = runner.replace(\"__STEPS__\", str(steps_csv).replace(\"\\\\\", \"\\\\\\\\\"))\n",
        "    runner = runner.replace(\"__FINISH__\", str(finish).replace(\"\\\\\", \"\\\\\\\\\"))\n",
        "\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-\"], input_text=runner)\n",
        "\n",
        "    if rc != 0:\n",
        "        _log(\"thermo: runner failed, writing tolerant placeholders\")\n",
        "        try:\n",
        "            df = pd.read_csv(steps_csv)\n",
        "        except Exception:\n",
        "            df = pd.DataFrame(columns=[\n",
        "                \"pathway_tag\",\"step_idx\",\"reaction_smiles\",\"substrates\",\"products\",\n",
        "                \"rbc2_score\",\"precedent_best_similarity\"\n",
        "            ])\n",
        "        for col in [\"dGprime_kJ_per_mol\",\"uncert_kJ_per_mol\",\"thermo_pass\",\"equilibrator_formula\"]:\n",
        "            if col not in df.columns:\n",
        "                df[col] = (False if col==\"thermo_pass\" else (\"\" if col==\"equilibrator_formula\" else math.nan))\n",
        "        df.to_csv(finish / \"steps_annotated.csv\", index=False)\n",
        "\n",
        "        tmp = df.copy()\n",
        "        tmp[\"rbc2_score\"] = pd.to_numeric(tmp.get(\"rbc2_score\",0.0), errors=\"coerce\").fillna(0.0)\n",
        "        tmp[\"precedent_best_similarity\"] = pd.to_numeric(tmp.get(\"precedent_best_similarity\",0.0), errors=\"coerce\").fillna(0.0)\n",
        "        tmp[\"thermo_pass\"] = tmp.get(\"thermo_pass\", False)\n",
        "        agg = tmp.groupby(\"pathway_tag\").agg(\n",
        "            steps_count=(\"step_idx\",\"max\"),\n",
        "            sum_rbc2=(\"rbc2_score\",\"sum\"),\n",
        "            sum_prec_sim=(\"precedent_best_similarity\",\"sum\"),\n",
        "            n_thermo_pass=(\"thermo_pass\",\"sum\"),\n",
        "        ).reset_index()\n",
        "        agg[\"rank_score\"] = agg[\"sum_rbc2\"] + 0.2*agg[\"sum_prec_sim\"] + 0.5*agg[\"n_thermo_pass\"] - 0.1*agg[\"steps_count\"]\n",
        "        agg.sort_values(\n",
        "            [\"rank_score\",\"sum_rbc2\",\"sum_prec_sim\",\"n_thermo_pass\",\"steps_count\"],\n",
        "            ascending=[False,False,False,False,True]\n",
        "        ).reset_index(drop=True).to_csv(finish / \"pathways_ranked_final.csv\", index=False)\n",
        "\n",
        "        if err:\n",
        "            _log(err.strip().splitlines()[-1])\n",
        "        state[\"thermo_method\"] = \"matchonly\"\n",
        "    else:\n",
        "        for line in (out or \"\").splitlines():\n",
        "            if line.strip():\n",
        "                _log(line.strip())\n",
        "        state[\"thermo_method\"] = \"equilibrator\"\n",
        "\n",
        "    # advertise artifacts\n",
        "    state.setdefault(\"artifacts\", []).extend([\n",
        "        str(finish / \"steps_annotated.csv\"),\n",
        "        str(finish / \"pathways_ranked_final.csv\"),\n",
        "        str(finish / \"metabolite_map.csv\"),\n",
        "        str(finish / \"_thermo_metabolite_map.json\"),\n",
        "    ])\n",
        "\n",
        "    _log(f\"✔ done thermo ({time.time()-t0:.1f}s)\")\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "def smarts_smirks_node(state):\n",
        "    \"\"\"\n",
        "    Annotate tokens with SMARTS hits and check SMIRKS applicability.\n",
        "    Outputs:\n",
        "      - retro_finish_out/smarts_hits.csv\n",
        "      - retro_finish_out/smirks_applicability.csv\n",
        "    \"\"\"\n",
        "    import time, pandas as pd\n",
        "    from pathlib import Path\n",
        "\n",
        "    def _log(msg):\n",
        "        print(msg)\n",
        "        state.setdefault(\"logs\", []).append(msg)\n",
        "\n",
        "    t0 = time.time()\n",
        "    _log(\"▶ start smarts_smirks\")\n",
        "\n",
        "    workdir   = Path(state[\"workdir\"])\n",
        "    finish    = workdir / \"retro_finish_out\"\n",
        "    retro_out = workdir / \"retro_out\"\n",
        "    finish.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    env_prefix = workdir / \"micromamba\" / \"envs\" / \"retrobiocat\"\n",
        "\n",
        "    # Ensure RDKit\n",
        "    _run_in_env(env_prefix, [\n",
        "        \"bash\",\"-lc\",\n",
        "        f'set -e; python -c \"import rdkit\" 2>/dev/null || micromamba install -y -p \"{env_prefix}\" -c conda-forge rdkit=2022.09.5 >/dev/null'\n",
        "    ])\n",
        "\n",
        "    # Prefer steps_annotated (after thermo), else steps_enzyme_plan, else steps.csv\n",
        "    steps_csv = finish / \"steps_annotated.csv\"\n",
        "    if not steps_csv.exists():\n",
        "        steps_csv = finish / \"steps_enzyme_plan.csv\"\n",
        "    if not steps_csv.exists():\n",
        "        steps_csv = retro_out / \"steps.csv\"\n",
        "\n",
        "    # supply default libs if absent\n",
        "    smarts_lib = state.get(\"smarts_library\") or {\n",
        "        \"carbonyl\": \"[CX3]=[OX1]\",\n",
        "        \"primary_alcohol\": \"[CX4;H2][OX2H]\",\n",
        "        \"secondary_alcohol\": \"[CX4;H1][OX2H]\",\n",
        "        \"aromatic_phenol\": \"c[OH]\",\n",
        "        \"nitrile\": \"[CX2]#N\",\n",
        "    }\n",
        "    smirks_lib = state.get(\"smirks_library\") or {\n",
        "        # toy examples\n",
        "        \"reduce_carbonyl_to_alcohol\": \"[CX3:1]=[OX1:2]>>[CX3H1:1][OX2H1:2]\",\n",
        "        \"hydrolyze_nitrile\": \"[CX2:1]#N>>[CX3:1](=O)N\",\n",
        "    }\n",
        "\n",
        "    # Runner that does RDKit work inside env\n",
        "    runner = r\"\"\"\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "STEPS_CSV = Path(\"__STEPS__\")\n",
        "FINISH    = Path(\"__FINISH__\")\n",
        "\n",
        "OUT_SMARTS  = FINISH / \"smarts_hits.csv\"\n",
        "OUT_SMIRKS  = FINISH / \"smirks_applicability.csv\"\n",
        "\n",
        "SMARTS_LIB = __SMARTS_JSON__\n",
        "SMIRKS_LIB = __SMIRKS_JSON__\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdChemReactions as Reactions\n",
        "\n",
        "# Load steps\n",
        "df = pd.read_csv(STEPS_CSV)\n",
        "\n",
        "def _split_rxn(r):\n",
        "    if not isinstance(r, str) or \">>\" not in r:\n",
        "        return [], []\n",
        "    L, R = r.split(\">>\", 1)\n",
        "    subs  = [s.strip() for s in L.split(\".\") if s.strip()]\n",
        "    prods = [p.strip() for p in R.split(\".\") if p.strip()]\n",
        "    return subs, prods\n",
        "\n",
        "# Collect tokens (substrates + products) with step indices\n",
        "rows = []\n",
        "for i, rxn in enumerate(df.get(\"reaction_smiles\", pd.Series([\"\"]*len(df))).astype(str).fillna(\"\")):\n",
        "    subs, prods = _split_rxn(rxn)\n",
        "    for smi in subs + prods:\n",
        "        rows.append({\"step_idx\": int(df.get(\"step_idx\", pd.Series(range(1,len(df)+1))).iloc[i] if \"step_idx\" in df.columns else i+1),\n",
        "                     \"token\": smi})\n",
        "tokdf = pd.DataFrame(rows).drop_duplicates()\n",
        "\n",
        "# SMARTS matching (long format)\n",
        "smart_rows = []\n",
        "compiled = {}\n",
        "for name, patt in SMARTS_LIB.items():\n",
        "    try:\n",
        "        compiled[name] = Chem.MolFromSmarts(patt)\n",
        "    except Exception:\n",
        "        compiled[name] = None\n",
        "\n",
        "for _, r in tokdf.iterrows():\n",
        "    smi = r[\"token\"]\n",
        "    m = Chem.MolFromSmiles(smi)\n",
        "    if m is None:\n",
        "        continue\n",
        "    for name, q in compiled.items():\n",
        "        hit = False\n",
        "        if q is not None:\n",
        "            try:\n",
        "                hit = (m.HasSubstructMatch(q))\n",
        "            except Exception:\n",
        "                hit = False\n",
        "        smart_rows.append({\"token\": smi, \"smarts_name\": name, \"hit\": bool(hit)})\n",
        "\n",
        "pd.DataFrame(smart_rows).to_csv(OUT_SMARTS, index=False)\n",
        "\n",
        "# SMIRKS applicability (per step, per rule; count applicable substrates)\n",
        "app_rows = []\n",
        "compiled_rxn = {}\n",
        "for name, smks in SMIRKS_LIB.items():\n",
        "    try:\n",
        "        rxn = Reactions.ReactionFromSmarts(smks, useSmiles=True)\n",
        "        compiled_rxn[name] = rxn\n",
        "    except Exception:\n",
        "        compiled_rxn[name] = None\n",
        "\n",
        "for i, rxn in enumerate(df.get(\"reaction_smiles\", pd.Series([\"\"]*len(df))).astype(str).fillna(\"\")):\n",
        "    step_i = int(df.get(\"step_idx\", pd.Series(range(1,len(df)+1))).iloc[i] if \"step_idx\" in df.columns else i+1)\n",
        "    subs, prods = _split_rxn(rxn)\n",
        "    subs_mols = []\n",
        "    for smi in subs:\n",
        "        m = Chem.MolFromSmiles(smi)\n",
        "        if m is not None:\n",
        "            subs_mols.append(m)\n",
        "    for name, rxnobj in compiled_rxn.items():\n",
        "        applicable = 0\n",
        "        if rxnobj is not None and subs_mols:\n",
        "            try:\n",
        "                # try each substrate alone as a reactant tuple of length 1\n",
        "                # (multi-substrate SMIRKS will need a library-specific adapter)\n",
        "                for m in subs_mols:\n",
        "                    out = rxnobj.RunReactants((m,))\n",
        "                    if out and len(out) > 0:\n",
        "                        applicable += 1\n",
        "            except Exception:\n",
        "                applicable = 0\n",
        "        app_rows.append({\"step_idx\": step_i, \"smirks_name\": name, \"n_applicable_substrates\": int(applicable)})\n",
        "\n",
        "pd.DataFrame(app_rows).to_csv(OUT_SMIRKS, index=False)\n",
        "\n",
        "print(\"smarts_smirks: tokens\", len(tokdf))\n",
        "print(\"smarts_smirks: smarts rules\", len(SMARTS_LIB))\n",
        "print(\"smarts_smirks: smirks rules\", len(SMIRKS_LIB))\n",
        "\"\"\".lstrip(\"\\n\")\n",
        "\n",
        "    import json\n",
        "    runner = runner.replace(\"__STEPS__\", str(steps_csv).replace(\"\\\\\", \"\\\\\\\\\"))\n",
        "    runner = runner.replace(\"__FINISH__\", str(finish).replace(\"\\\\\", \"\\\\\\\\\"))\n",
        "    runner = runner.replace(\"__SMARTS_JSON__\", json.dumps(smarts_lib))\n",
        "    runner = runner.replace(\"__SMIRKS_JSON__\", json.dumps(smirks_lib))\n",
        "\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-\"], input_text=runner)\n",
        "    if rc != 0:\n",
        "        _log(\"smarts_smirks: runner failed\")\n",
        "        if err:\n",
        "            _log(err.strip().splitlines()[-1])\n",
        "    else:\n",
        "        for line in (out or \"\").splitlines():\n",
        "            if line.strip():\n",
        "                _log(line.strip())\n",
        "\n",
        "    state.setdefault(\"artifacts\", []).extend([\n",
        "        str(finish / \"smarts_hits.csv\"),\n",
        "        str(finish / \"smirks_applicability.csv\"),\n",
        "    ])\n",
        "    _log(f\"✔ done smarts_smirks ({time.time()-t0:.1f}s)\")\n",
        "    return state\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h3JEbBpttH32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3JEbBpttH32",
        "outputId": "813ec952-de38-4ed5-9857-cb87fb014331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/runs/run_001/micromamba/envs/retrobiocat/bin/python: No module named equilibrator_cache.cli\n"
          ]
        }
      ],
      "source": [
        "! /content/runs/run_001/bin/micromamba run -p /content/runs/run_001/micromamba/envs/retrobiocat \\\n",
        "  python -m equilibrator_cache.cli download --to /content/runs/run_001/equilibrator_cache\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sequuence matching\n",
        "# --- sequence matching ---\n",
        "def sequence_fetch_node(state, per_step=10, reviewed_first=False, timeout=12.0):\n",
        "    \"\"\"\n",
        "    Fetches sequence candidates from UniProt based on Selenzyme links, EC numbers,\n",
        "    and keywords. Writes retro_finish_out/steps_sequence_candidates.csv and\n",
        "    sequence_fetch_debug.json.\n",
        "    \"\"\"\n",
        "    # --- GUARDS ---\n",
        "    if state is None:\n",
        "        state = {}\n",
        "\n",
        "    import json, re, requests, pandas as pd, time\n",
        "    from pathlib import Path\n",
        "\n",
        "    def _log(msg):\n",
        "        print(msg)\n",
        "        state.setdefault(\"logs\", []).append(msg)\n",
        "\n",
        "    t0 = time.time()\n",
        "    _log(\"▶ start sequence_fetch\")\n",
        "\n",
        "    workdir = Path(state.get(\"workdir\") or state.get(\"run_dir\") or \".\")\n",
        "    state[\"workdir\"] = str(workdir)  # ensure for downstream\n",
        "    finish = workdir / \"retro_finish_out\"\n",
        "    finish.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    save_debug = True\n",
        "\n",
        "    # ----- load steps (choice > plan) -----\n",
        "    steps_csv = finish / \"steps_enzyme_choice.csv\"\n",
        "    if not steps_csv.exists():\n",
        "        steps_csv = finish / \"steps_enzyme_plan.csv\"\n",
        "\n",
        "    if not steps_csv.exists():\n",
        "        _log(\"sequence_fetch: no steps file found; wrote empty candidates\")\n",
        "        (finish / \"steps_sequence_candidates.csv\").write_text(\"\")\n",
        "        if save_debug:\n",
        "            (finish / \"sequence_fetch_debug.json\").write_text(\"[]\")\n",
        "        _log(f\"✔ done sequence_fetch ({time.time()-t0:.1f}s)\")\n",
        "        return state\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(steps_csv).fillna(\"\")\n",
        "    except Exception as e:\n",
        "        _log(f\"sequence_fetch: ERROR loading steps CSV: {type(e).__name__}: {e}\")\n",
        "        (finish / \"steps_sequence_candidates.csv\").write_text(\"\")\n",
        "        if save_debug:\n",
        "            (finish / \"sequence_fetch_debug.json\").write_text(\"[]\")\n",
        "        _log(f\"✔ done sequence_fetch ({time.time()-t0:.1f}s)\")\n",
        "        return state\n",
        "\n",
        "    # Normalize columns we rely on\n",
        "    for col in [\"pathway_tag\",\"step_idx\",\"rxn_type\",\"name\",\"selenzyme_url\",\"seed_uniprots\",\"reaction_smiles\"]:\n",
        "        if col not in df.columns:\n",
        "            df[col] = \"\"\n",
        "    df[\"step_idx\"] = pd.to_numeric(df[\"step_idx\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "    # ----- UniProt helpers -----\n",
        "    U = requests.Session()\n",
        "    U.headers.update({\"User-Agent\": \"dbtl-seq/0.4\"})\n",
        "    uniprot_base = \"https://rest.uniprot.org/uniprotkb/search\"\n",
        "    fasta_base   = \"https://rest.uniprot.org/uniprotkb/\"  # {ACC}.fasta\n",
        "\n",
        "    def _uniprot_search(query, size):\n",
        "        fields = \",\".join([\n",
        "            \"accession\",\"id\",\"organism_name\",\"reviewed\",\"length\",\"protein_name\",\n",
        "            \"genes\",\"ec\",\"cc_function\",\"sequence\"\n",
        "        ])\n",
        "        params = dict(query=query, fields=fields, format=\"json\", size=int(max(1,size)))\n",
        "        meta = {\"status\": None, \"url\": None, \"query\": query}\n",
        "        try:\n",
        "            r = U.get(uniprot_base, params=params, timeout=timeout)\n",
        "            meta[\"status\"] = r.status_code; meta[\"url\"] = str(r.url)\n",
        "            if r.status_code != 200:\n",
        "                return [], meta\n",
        "            js = r.json()\n",
        "            return (js.get(\"results\", []) or []), meta\n",
        "        except Exception as e:\n",
        "            meta[\"status\"] = f\"ERR:{type(e).__name__}\"\n",
        "            return [], meta\n",
        "\n",
        "    def _fetch_fasta(acc):\n",
        "        try:\n",
        "            r = U.get(f\"{fasta_base}{acc}.fasta\", timeout=timeout)\n",
        "            if r.status_code != 200 or not r.text or not r.text.startswith(\">\"):\n",
        "                return \"\"\n",
        "            lines = [ln.strip() for ln in r.text.splitlines() if ln.strip()]\n",
        "            return \"\".join(ln for ln in lines if not ln.startswith(\">\"))\n",
        "        except Exception:\n",
        "            return \"\"\n",
        "\n",
        "    # Selenzyme page scraper for UniProt IDs\n",
        "    def _scrape_uniprot_from_selenzyme(url, session=None, timeout=8.0):\n",
        "        if not url or not isinstance(url, str):\n",
        "            return set()\n",
        "        s = session or requests.Session()\n",
        "        s.headers.update({\"User-Agent\": \"dbtl-scraper/0.1\"})\n",
        "        try:\n",
        "            r = s.get(url, timeout=timeout)\n",
        "            if r.status_code != 200:\n",
        "                return set()\n",
        "            html = r.text\n",
        "        except Exception:\n",
        "            return set()\n",
        "        hits = set()\n",
        "        # plain accessions\n",
        "        for m in re.finditer(r\"\\b([OPQ][0-9][A-Z0-9]{3}[0-9]|[A-NR-Z][0-9]{5})\\b\", html):\n",
        "            hits.add(m.group(1))\n",
        "        # uniprot links\n",
        "        for m in re.finditer(r'uniprot(?:kb)?/(?:entry/)?([A-Z0-9]{6,10})', html, re.I):\n",
        "            hits.add(m.group(1))\n",
        "        return hits\n",
        "\n",
        "    def _ec_from_row(row):\n",
        "        # full or dashed EC patterns\n",
        "        m = re.search(r\"(?:EC\\s*)?(\\d+\\.\\d+\\.\\d+\\.\\d+|\\d+\\.\\d+\\.\\d+\\.-|\\d+\\.\\d+\\.-\\.-|\\d+\\.-\\.-\\.-)\",\n",
        "                      str(row.get(\"rxn_type\",\"\")) + \" \" + str(row.get(\"name\",\"\")))\n",
        "        return m.group(1) if m else \"\"\n",
        "\n",
        "    def _guess_keywords(row):\n",
        "        kws = []\n",
        "        for src in (row.get(\"retrobiocat_reaction\",\"\"), row.get(\"name\",\"\")):\n",
        "            if isinstance(src, str) and src.strip():\n",
        "                kws.extend(re.split(r\"\\W+\", src.strip()))\n",
        "        return [k.lower() for k in kws if len(k) > 2]\n",
        "\n",
        "    RE_EC = re.compile(r'\\d+\\.\\d+\\.\\d+\\.(?:\\d+|-)')\n",
        "\n",
        "    def _rows_from_hits(step_row, hits, source=\"uniprot_rest\"):\n",
        "        out = []\n",
        "        for h in hits:\n",
        "            acc   = h.get(\"primaryAccession\",\"\")\n",
        "            org   = (h.get(\"organism\",{}) or {}).get(\"scientificName\",\"\")\n",
        "            rev   = bool(h.get(\"entryType\",\"\") == \"Swiss-Prot\" or h.get(\"reviewed\", False))\n",
        "            plen  = int((h.get(\"sequence\",{}) or {}).get(\"length\") or h.get(\"length\") or 0)\n",
        "            seq   = (h.get(\"sequence\",{}) or {}).get(\"value\",\"\")\n",
        "            pdsc  = h.get(\"proteinDescription\",{}) or {}\n",
        "            pname = (\n",
        "                ((pdsc.get(\"recommendedName\",{}) or {}).get(\"fullName\",{}) or {}).get(\"value\",\"\")\n",
        "                or (pdsc.get(\"submissionNames\",[{}]) or [{}])[0].get(\"fullName\",{}).get(\"value\",\"\")\n",
        "                or h.get(\"proteinName\",\"\") or h.get(\"uniProtkbId\",\"\")\n",
        "            )\n",
        "            ec_text = json.dumps(h, ensure_ascii=False)\n",
        "            ecs = sorted(set(RE_EC.findall(ec_text)))\n",
        "            out.append({\n",
        "                \"pathway_tag\": step_row[\"pathway_tag\"],\n",
        "                \"step_idx\":    int(step_row[\"step_idx\"]),\n",
        "                \"reaction_smiles\": step_row.get(\"reaction_smiles\",\"\"),\n",
        "                \"rxn_type\":    step_row.get(\"rxn_type\",\"\"),\n",
        "                \"name\":        step_row.get(\"name\",\"\") or step_row.get(\"enzyme\",\"\"),\n",
        "                \"selenzyme_url\": step_row.get(\"selenzyme_url\",\"\"),\n",
        "                \"uniprot_acc\": acc,\n",
        "                \"protein_name\": pname,\n",
        "                \"organism\":     org,\n",
        "                \"reviewed\":     rev,\n",
        "                \"sequence_len\": plen,\n",
        "                \"ec_numbers\":   \";\".join(ecs),\n",
        "                \"aa_sequence\":  seq,\n",
        "                \"source\":       source\n",
        "            })\n",
        "        return out\n",
        "\n",
        "    debug_log, out_rows = [], []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        tag  = row.get(\"pathway_tag\",\"\")\n",
        "        i    = int(row.get(\"step_idx\",0) or 0)\n",
        "        per_this = 0\n",
        "        step_dbg = {\"pathway_tag\": tag, \"step_idx\": i, \"tried\": []}\n",
        "\n",
        "        # A) seeds (selenzyme + prefilled)\n",
        "        seed = set()\n",
        "        if row.get(\"seed_uniprots\",\"\"):\n",
        "            # accept both ; and , just in case\n",
        "            for a in re.split(r\"[;,]+\", str(row[\"seed_uniprots\"])):\n",
        "                a = a.strip()\n",
        "                if a:\n",
        "                    seed.add(a)\n",
        "        seed |= _scrape_uniprot_from_selenzyme(row.get(\"selenzyme_url\",\"\"))\n",
        "\n",
        "        if seed:\n",
        "            acc_q = \" OR \".join(f\"accession:{a}\" for a in list(seed)[:per_step])\n",
        "            hits, meta = _uniprot_search(acc_q, size=per_step)\n",
        "            step_dbg[\"tried\"].append({\"mode\":\"acc_batch\", **meta, \"n_hits\":len(hits)})\n",
        "            rows = _rows_from_hits(row, hits, source=\"uniprot_by_acc\")\n",
        "            out_rows.extend(rows); per_this += len(rows)\n",
        "\n",
        "            if per_this < per_step:\n",
        "                for a in list(seed)[:per_step]:\n",
        "                    if per_this >= per_step:\n",
        "                        break\n",
        "                    if any(r[\"uniprot_acc\"] == a and r[\"step_idx\"]==i and r[\"pathway_tag\"]==tag for r in out_rows):\n",
        "                        continue\n",
        "                    seq = _fetch_fasta(a)\n",
        "                    step_dbg[\"tried\"].append({\"mode\":\"acc_fasta\", \"acc\":a, \"status\":\"ok\" if seq else \"miss\"})\n",
        "                    if seq:\n",
        "                        out_rows.append({\n",
        "                            \"pathway_tag\": tag, \"step_idx\": i,\n",
        "                            \"reaction_smiles\": row.get(\"reaction_smiles\",\"\"),\n",
        "                            \"rxn_type\": row.get(\"rxn_type\",\"\"),\n",
        "                            \"name\": row.get(\"name\",\"\") or row.get(\"enzyme\",\"\"),\n",
        "                            \"selenzyme_url\": row.get(\"selenzyme_url\",\"\"),\n",
        "                            \"uniprot_acc\": a,\n",
        "                            \"protein_name\": \"\",\n",
        "                            \"organism\":     \"\",\n",
        "                            \"reviewed\":     False,\n",
        "                            \"sequence_len\": len(seq),\n",
        "                            \"ec_numbers\":   \"\",\n",
        "                            \"aa_sequence\":  seq,\n",
        "                            \"source\":       \"uniprot_fasta_fallback\"\n",
        "                        })\n",
        "                        per_this += 1\n",
        "\n",
        "        # B) EC-driven search\n",
        "        if per_this < per_step:\n",
        "            ec = _ec_from_row(row)\n",
        "            if ec:\n",
        "                q = f\"ec:{ec}\"\n",
        "                if reviewed_first:\n",
        "                    q += \" AND reviewed:true\"\n",
        "                hits, meta = _uniprot_search(q, size=per_step-per_this)\n",
        "                step_dbg[\"tried\"].append({\"mode\":\"ec\", **meta, \"n_hits\":len(hits)})\n",
        "                rows = _rows_from_hits(row, hits)\n",
        "                out_rows.extend(rows); per_this += len(rows)\n",
        "\n",
        "        # C) keywords (looser)\n",
        "        if per_this < per_step:\n",
        "            kws = _guess_keywords(row)\n",
        "            if kws:\n",
        "                q = \" AND \".join(f'(\"{k}\")' for k in kws)\n",
        "                q += \" AND annotation_score:[2 TO 5]\"\n",
        "                host = (state.get(\"host\") or \"\").strip()\n",
        "                if host:\n",
        "                    q += f' AND (organism_name:\"{host}\" OR taxonomy_id:562)'\n",
        "                hits, meta = _uniprot_search(q, size=per_step-per_this)\n",
        "                step_dbg[\"tried\"].append({\"mode\":\"keywords\", **meta, \"n_hits\":len(hits)})\n",
        "                rows = _rows_from_hits(row, hits)\n",
        "                out_rows.extend(rows); per_this += len(rows)\n",
        "\n",
        "        debug_log.append(step_dbg)\n",
        "\n",
        "    import pandas as pd\n",
        "    cand = pd.DataFrame(out_rows)\n",
        "    out = finish / \"steps_sequence_candidates.csv\"\n",
        "    cand.to_csv(out, index=False)\n",
        "\n",
        "    if save_debug:\n",
        "        with open(finish / \"sequence_fetch_debug.json\",\"w\") as f:\n",
        "            json.dump(debug_log, f, indent=2)\n",
        "\n",
        "    _log(f\"sequence_fetch: wrote {len(cand)} candidates → {out}\")\n",
        "    _log(f\"✔ done sequence_fetch ({time.time()-t0:.1f}s)\")\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "CnTGTf9YunqN"
      },
      "id": "CnTGTf9YunqN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sequence ranking\n",
        "\n",
        "# --- shared tiny helper\n",
        "def _get_workdir(st):\n",
        "    try:\n",
        "        return Path(st.get(\"workdir\") or st.get(\"run_dir\") or \"/content/runs/run_001\")\n",
        "    except Exception:\n",
        "        return Path(\"/content/runs/run_001\")\n",
        "\n",
        "# ========= sequence_fetch_node (ensure state, workdir, always returns) =========\n",
        "def sequence_fetch_node(state, per_step=10, reviewed_first=False, timeout=12.0):\n",
        "    # --- GUARDS ---\n",
        "    if state is None:\n",
        "        state = {}\n",
        "    from pathlib import Path\n",
        "    import time, json, re, requests, pandas as pd\n",
        "\n",
        "    def log(msg):\n",
        "        print(msg)\n",
        "        state.setdefault(\"logs\", []).append(msg)\n",
        "\n",
        "    t0 = time.time()\n",
        "    log(\"▶ start sequence_fetch (v4)\")\n",
        "    workdir = _get_workdir(state)\n",
        "    state[\"workdir\"] = str(workdir)  # ensure it exists for downstream nodes\n",
        "    finish  = workdir / \"retro_finish_out\"\n",
        "    finish.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        steps = finish / \"steps_enzyme_choice.csv\"\n",
        "        if not steps.exists():\n",
        "            # fallback to the plan (should have seed_uniprots after selenzyme_rank_node)\n",
        "            steps = finish / \"steps_enzyme_plan.csv\"\n",
        "        if not steps.exists():\n",
        "            log(\"sequence_fetch: no steps file found; wrote empty candidates\")\n",
        "            (finish / \"steps_sequence_candidates.csv\").write_text(\"\")\n",
        "            log(f\"✔ done sequence_fetch ({time.time()-t0:.1f}s)\")\n",
        "            return state\n",
        "\n",
        "        df = pd.read_csv(steps).fillna(\"\")\n",
        "        # robust seed cleaner (accepts semicolons & commas)\n",
        "        def _clean_seed_list(val):\n",
        "            if not isinstance(val, str) or not val.strip():\n",
        "                return []\n",
        "            toks = re.split(r\"[,\\s;|]+\", val.strip())\n",
        "            return [t.upper() for t in toks if re.fullmatch(r\"[A-Z0-9]{6,10}\", t)]\n",
        "\n",
        "        # Pull seeds if present\n",
        "        seeds_col = \"seed_uniprots\" if \"seed_uniprots\" in df.columns else None\n",
        "        df[\"seed_uniprots\"] = df[seeds_col].astype(str) if seeds_col else \"\"\n",
        "\n",
        "        # UniProt fetcher (with EC wildcard fix)\n",
        "        S = requests.Session()\n",
        "        S.headers.update({\"User-Agent\":\"dbtl-seq/0.4\"})\n",
        "        base = \"https://rest.uniprot.org/uniprotkb/search\"\n",
        "\n",
        "        def _ec_to_uniprot_pattern(ec_raw: str) -> str:\n",
        "            if not isinstance(ec_raw, str) or not ec_raw.strip():\n",
        "                return \"\"\n",
        "            parts = ec_raw.strip().split(\".\")\n",
        "            # trim trailing '-' and replace with wildcard\n",
        "            while parts and parts[-1] == \"-\":\n",
        "                parts.pop()\n",
        "            if not parts:\n",
        "                return \"\"\n",
        "            return \".\".join(parts) + \".*\" if len(parts) < 4 else \".\".join(parts)\n",
        "\n",
        "        rows = []\n",
        "        for _, r in df.iterrows():\n",
        "            tag = str(r.get(\"pathway_tag\",\"\"))\n",
        "            idx = int(pd.to_numeric(r.get(\"step_idx\",0), errors=\"coerce\") or 0)\n",
        "            rxn = str(r.get(\"reaction_smiles\",\"\"))\n",
        "            name= str(r.get(\"name\",\"\"))\n",
        "            rxnt= str(r.get(\"rxn_type\",\"\"))\n",
        "            seeds = _clean_seed_list(r.get(\"seed_uniprots\",\"\"))\n",
        "\n",
        "            # (A) seed accessions path\n",
        "            seed_hits = []\n",
        "            if seeds:\n",
        "                for acc in seeds:\n",
        "                    params = dict(query=f\"accession:{acc}\", fields=\"accession,id,organism_name,reviewed,length,sequence,ec\", format=\"json\", size=1)\n",
        "                    try:\n",
        "                        resp = S.get(base, params=params, timeout=timeout)\n",
        "                        if resp.status_code == 200:\n",
        "                            js = resp.json()\n",
        "                            for h in js.get(\"results\", []):\n",
        "                                seed_hits.append(h)\n",
        "                    except Exception:\n",
        "                        pass\n",
        "\n",
        "            # (B) EC-based search (fallback)\n",
        "            # try to derive EC from rxn_type/name\n",
        "            ec = \"\"\n",
        "            for src in (rxnt, name):\n",
        "                m = re.search(r\"(?:EC\\s*)?(\\d+\\.\\d+\\.\\d+\\.\\d+|\\d+\\.\\d+\\.\\d+\\.-|\\d+\\.\\d+\\.-\\.-|\\d+\\.-\\.-\\.-)\", str(src))\n",
        "                if m:\n",
        "                    ec = m.group(1); break\n",
        "            ec_pat = _ec_to_uniprot_pattern(ec)\n",
        "\n",
        "            hits = []\n",
        "            if not seed_hits:\n",
        "                qparts = []\n",
        "                if ec_pat:\n",
        "                    qparts.append(f\"ec:{ec_pat}\")\n",
        "                elif name:\n",
        "                    qparts.append(f'({name})')\n",
        "                if reviewed_first:\n",
        "                    qparts.append(\"reviewed:true\")\n",
        "                params = dict(query=\" AND \".join(qparts) if qparts else \"reviewed:true\",\n",
        "                              fields=\"accession,id,organism_name,reviewed,length,sequence,ec\",\n",
        "                              format=\"json\", size=per_step)\n",
        "                try:\n",
        "                    resp = S.get(base, params=params, timeout=timeout)\n",
        "                    if resp.status_code == 200:\n",
        "                        hits = resp.json().get(\"results\", [])\n",
        "                except Exception:\n",
        "                    hits = []\n",
        "            else:\n",
        "                hits = seed_hits\n",
        "\n",
        "            for h in hits:\n",
        "                rows.append({\n",
        "                    \"pathway_tag\": tag,\n",
        "                    \"step_idx\": idx,\n",
        "                    \"reaction_smiles\": rxn,\n",
        "                    \"uniprot_acc\": h.get(\"primaryAccession\",\"\"),\n",
        "                    \"organism\": (h.get(\"organism\",{}) or {}).get(\"scientificName\",\"\"),\n",
        "                    \"reviewed\": bool(h.get(\"entryType\",\"\") == \"Swiss-Prot\" or h.get(\"reviewed\", False)),\n",
        "                    \"sequence_len\": int(h.get(\"sequence\",{}).get(\"length\",0) or h.get(\"length\",0) or 0),\n",
        "                    \"aa_sequence\": (h.get(\"sequence\",{}) or {}).get(\"value\",\"\"),\n",
        "                    \"ec_numbers\": \";\".join(h.get(\"ec\",[]) or []),\n",
        "                    \"source\": \"seed\" if seed_hits else \"search\",\n",
        "                })\n",
        "\n",
        "        out = finish / \"steps_sequence_candidates.csv\"\n",
        "        pd.DataFrame(rows).to_csv(out, index=False)\n",
        "        log(f\"sequence_fetch: wrote {len(rows)} candidates → {out}\")\n",
        "        log(f\"✔ done sequence_fetch ({time.time()-t0:.1f}s)\")\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        # never return None; log and continue\n",
        "        log(f\"sequence_fetch: ERROR {type(e).__name__}: {e}\")\n",
        "        out = finish / \"steps_sequence_candidates.csv\"\n",
        "        if not out.exists():\n",
        "            out.write_text(\"\")  # ensure file exists so next node tolerates it\n",
        "        log(f\"✔ done sequence_fetch ({time.time()-t0:.1f}s)\")\n",
        "        return state\n",
        "\n",
        "\n",
        "# ========= sequence_rank_node (guard state/workdir, always returns) =========\n",
        "def sequence_rank_node(state):\n",
        "    import time\n",
        "    from pathlib import Path\n",
        "    import pandas as pd\n",
        "\n",
        "    t0 = time.time()\n",
        "    workdir = Path(state.get(\"workdir\") or state.get(\"run_dir\") or \".\")\n",
        "    finish  = workdir / \"retro_finish_out\"\n",
        "    finish.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    in_csv  = finish / \"steps_sequence_candidates.csv\"\n",
        "    out_csv = finish / \"steps_sequence_plan.csv\"\n",
        "    cols = [\"pathway_tag\",\"step_idx\",\"enzyme\",\"uniprot_acc\",\"score\",\"source\",\n",
        "            \"organism\",\"sequence_len\",\"reviewed\",\"aa_sequence\",\"protein_name\"]\n",
        "\n",
        "    def log(m): print(m); state.setdefault(\"logs\", []).append(m)\n",
        "    log(\"▶ start sequence_rank\")\n",
        "\n",
        "    if (not in_csv.exists()) or in_csv.stat().st_size == 0:\n",
        "        pd.DataFrame(columns=cols).to_csv(out_csv, index=False)\n",
        "        log(\"sequence_rank: no or empty candidates → wrote empty plan (headers only)\")\n",
        "        log(f\"✔ done sequence_rank ({time.time()-t0:.1f}s)\")\n",
        "        return state\n",
        "\n",
        "    try:\n",
        "        cand = pd.read_csv(in_csv)\n",
        "    except Exception:\n",
        "        pd.DataFrame(columns=cols).to_csv(out_csv, index=False)\n",
        "        log(\"sequence_rank: read error → wrote empty plan (headers only)\")\n",
        "        log(f\"✔ done sequence_rank ({time.time()-t0:.1f}s)\")\n",
        "        return state\n",
        "\n",
        "    if cand.empty:\n",
        "        pd.DataFrame(columns=cols).to_csv(out_csv, index=False)\n",
        "        log(\"sequence_rank: 0 rows → wrote empty plan (headers only)\")\n",
        "        log(f\"✔ done sequence_rank ({time.time()-t0:.1f}s)\")\n",
        "        return state\n",
        "\n",
        "    # simple scoring\n",
        "    cand[\"reviewed\"] = cand.get(\"reviewed\", False).astype(str).str.lower().isin([\"true\",\"1\",\"yes\",\"reviewed\"]).astype(int)\n",
        "    cand[\"sequence_len\"] = pd.to_numeric(cand.get(\"sequence_len\", 0), errors=\"coerce\").fillna(0).astype(int)\n",
        "    cand[\"len_pen\"] = ((cand[\"sequence_len\"] < 100) | (cand[\"sequence_len\"] > 1000)).astype(int)\n",
        "    cand[\"score\"] = 1.0*cand[\"reviewed\"] - 0.2*cand[\"len_pen\"]\n",
        "\n",
        "    # pick 1 per step\n",
        "    cand[\"step_idx\"] = pd.to_numeric(cand.get(\"step_idx\",0), errors=\"coerce\").fillna(0).astype(int)\n",
        "    plan = (cand.sort_values([\"pathway_tag\",\"step_idx\",\"score\"], ascending=[True,True,False])\n",
        "                 .groupby([\"pathway_tag\",\"step_idx\"], as_index=False)\n",
        "                 .head(1)\n",
        "                 .reset_index(drop=True))\n",
        "\n",
        "    keep_cols = [\"pathway_tag\",\"step_idx\",\"uniprot_acc\",\"score\",\"source\",\n",
        "                 \"organism\",\"sequence_len\",\"reviewed\",\"aa_sequence\"]\n",
        "    plan = plan.reindex(columns=[c for c in keep_cols if c in plan.columns])\n",
        "    plan.to_csv(out_csv, index=False)\n",
        "    log(f\"sequence_rank: wrote {len(plan)} picks → {out_csv}\")\n",
        "    log(f\"✔ done sequence_rank ({time.time()-t0:.1f}s)\")\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BYHuDWaHu2iZ"
      },
      "id": "BYHuDWaHu2iZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _ec_to_uniprot_pattern(ec_raw: str) -> str:\n",
        "    # '1.1.1.-' → '1.1.1.*', '1.1.-.-' → '1.1.*', '1.-.-.-' → '1.*'\n",
        "    import re\n",
        "    if not isinstance(ec_raw, str):\n",
        "        return \"\"\n",
        "    parts = ec_raw.strip().split(\".\")\n",
        "    # replace trailing '-' segments with '*', keep leading defined parts\n",
        "    while parts and parts[-1] == \"-\":\n",
        "        parts.pop()\n",
        "    if not parts:\n",
        "        return \"\"\n",
        "    return \".\".join(parts) + \".*\" if len(parts) < 4 else \".\".join(parts)  # already full EC\n"
      ],
      "metadata": {
        "id": "-3Ph6M3iJ35s"
      },
      "id": "-3Ph6M3iJ35s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build node\n",
        "\n",
        "def build_node(state, overhang5=\"AATG\", overhang3=\"GCTT\", enzyme=\"BsaI\"):\n",
        "    \"\"\"\n",
        "    Turn steps_sequence_plan.csv into codon-optimized FASTA + simple Golden Gate plan.\n",
        "    Writes:\n",
        "      - retro_finish_out/sequences_codon_opt.fasta\n",
        "      - retro_finish_out/cloning_plan.csv\n",
        "    \"\"\"\n",
        "    import re, time, pandas as pd\n",
        "    from pandas.errors import EmptyDataError\n",
        "    from pathlib import Path\n",
        "\n",
        "    def _log(m):\n",
        "        print(m); state.setdefault(\"logs\", []).append(m)\n",
        "\n",
        "    _log(\"▶ start build (codon-opt + Golden Gate plan)\")\n",
        "    t0 = time.time()\n",
        "    workdir = Path(state.get(\"workdir\") or state.get(\"run_dir\") or \".\")\n",
        "    finish  = workdir / \"retro_finish_out\"\n",
        "    finish.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    plan_csv = finish / \"steps_sequence_plan.csv\"\n",
        "\n",
        "    def _emit_empty_and_exit(note: str):\n",
        "        # always create empty artifacts so downstream never crashes\n",
        "        (finish / \"sequences_codon_opt.fasta\").write_text(\"\")\n",
        "        import pandas as pd\n",
        "        pd.DataFrame(columns=[\n",
        "            \"pathway_tag\",\"step_idx\",\"uniprot_acc\",\"protein_name\",\"organism\",\n",
        "            \"aa_len\",\"cds_len\",\"enzyme\",\"site_forward\",\"site_reverse\",\"overhang_5\",\"overhang_3\",\"fasta_id\"\n",
        "        ]).to_csv(finish / \"cloning_plan.csv\", index=False)\n",
        "        _log(f\"build: {note}; wrote empty FASTA and cloning_plan.csv; skipping\")\n",
        "        _log(f\"✔ done build ({time.time()-t0:.1f}s)\")\n",
        "        return state\n",
        "\n",
        "    # Guard: file missing or zero-bytes\n",
        "    if (not plan_csv.exists()) or plan_csv.stat().st_size == 0:\n",
        "        return _emit_empty_and_exit(\"plan missing or empty\")\n",
        "\n",
        "    # Read plan safely\n",
        "    try:\n",
        "        df = pd.read_csv(plan_csv).fillna(\"\")\n",
        "    except EmptyDataError:\n",
        "        return _emit_empty_and_exit(\"plan CSV had no columns (EmptyDataError)\")\n",
        "\n",
        "    if df.empty:\n",
        "        return _emit_empty_and_exit(\"plan has 0 rows\")\n",
        "\n",
        "    # ---------- keep your existing codon optimization + Golden Gate code below ----------\n",
        "    # Preferred E. coli codons (… your table …)\n",
        "    pref = {\n",
        "        'A':'GCT','R':'CGT','N':'AAT','D':'GAT','C':'TGT','Q':'CAA','E':'GAA','G':'GGT',\n",
        "        'H':'CAT','I':'ATT','L':'CTG','K':'AAA','M':'ATG','F':'TTT','P':'CCT','S':'TCT',\n",
        "        'T':'ACT','W':'TGG','Y':'TAT','V':'GTG','*':'TAA'\n",
        "    }\n",
        "    alt = {\n",
        "        'A':['GCT','GCC','GCA','GCG'], 'R':['CGT','CGC','CGA','CGG','AGA','AGG'],\n",
        "        'N':['AAT','AAC'], 'D':['GAT','GAC'], 'C':['TGT','TGC'], 'Q':['CAA','CAG'],\n",
        "        'E':['GAA','GAG'], 'G':['GGT','GGC','GGA','GGG'], 'H':['CAT','CAC'],\n",
        "        'I':['ATT','ATC','ATA'], 'L':['CTG','CTC','CTA','CTT','TTA','TTG'], 'K':['AAA','AAG'],\n",
        "        'M':['ATG'], 'F':['TTT','TTC'], 'P':['CCT','CCC','CCA','CCG'],\n",
        "        'S':['TCT','TCC','TCA','TCG','AGC','AGT'], 'T':['ACT','ACC','ACA','ACG'],\n",
        "        'W':['TGG'], 'Y':['TAT','TAC'], 'V':['GTG','GTC','GTA','GTT'], '*':['TAA','TAG','TGA']\n",
        "    }\n",
        "\n",
        "    enzyme = enzyme.upper()\n",
        "    if enzyme == \"BSAI\":\n",
        "        site_f, site_r = \"GGTCTC\", \"GAGACC\"\n",
        "    elif enzyme == \"BSMBI\":\n",
        "        site_f, site_r = \"CGTCTC\", \"GAGACG\"\n",
        "    else:\n",
        "        site_f, site_r = \"GGTCTC\", \"GAGACC\"\n",
        "\n",
        "    forbid = [site_f, site_r]\n",
        "\n",
        "    def _remove_sites(dna, aa):\n",
        "        def has_site(s):\n",
        "            S = s.upper()\n",
        "            if any(f in S for f in forbid): return True\n",
        "            comp = str.maketrans(\"ACGT\",\"TGCA\")\n",
        "            rc = S.translate(comp)[::-1]\n",
        "            return any(f in rc for f in forbid)\n",
        "        if not has_site(dna): return dna\n",
        "        codons = [dna[i:i+3] for i in range(0, len(dna), 3)]\n",
        "        AAs    = list(aa)\n",
        "        for i in range(len(codons)):\n",
        "            aa_i = AAs[i] if i < len(AAs) else None\n",
        "            if aa_i not in alt: continue\n",
        "            for c in alt[aa_i]:\n",
        "                if c == codons[i]: continue\n",
        "                trial = \"\".join(codons[:i] + [c] + codons[i+1:])\n",
        "                if not has_site(trial): return trial\n",
        "        return dna\n",
        "\n",
        "    def aa_to_dna(aa):\n",
        "        aa = aa.strip().upper().replace(\"U\",\"C\")\n",
        "        return \"\".join(pref.get(a, \"NNN\") for a in aa)\n",
        "\n",
        "    def decorate(dna):\n",
        "        return f\"{site_f}{overhang5}{dna}{overhang3}{site_r}\"\n",
        "\n",
        "    fasta_lines, build_rows = [], []\n",
        "    keep = (df.sort_values([\"pathway_tag\",\"step_idx\",\"score\"], ascending=[True,True,False])\n",
        "              .groupby([\"pathway_tag\",\"step_idx\"], as_index=False).head(1))\n",
        "\n",
        "    for _, r in keep.iterrows():\n",
        "        tag  = str(r.get(\"pathway_tag\",\"\"))\n",
        "        idx  = int(r.get(\"step_idx\",0) or 0)\n",
        "        acc  = str(r.get(\"uniprot_acc\",\"\") or r.get(\"uniprot_id\",\"\"))\n",
        "        org  = str(r.get(\"organism\",\"\"))\n",
        "        pname= str(r.get(\"protein_name\",\"\"))\n",
        "        aa   = str(r.get(\"aa_sequence\",\"\")).strip().upper()\n",
        "        if not aa: continue\n",
        "\n",
        "        cds  = aa_to_dna(aa)\n",
        "        cds2 = _remove_sites(cds, aa)\n",
        "        full = decorate(cds2)\n",
        "\n",
        "        name = f\"{tag}_step{idx}_{acc}\".replace(\" \",\"_\")\n",
        "        fasta_lines.append(f\">{name} | {pname} | {org}\\n{full}\")\n",
        "\n",
        "        build_rows.append({\n",
        "            \"pathway_tag\": tag, \"step_idx\": idx, \"uniprot_acc\": acc,\n",
        "            \"protein_name\": pname, \"organism\": org,\n",
        "            \"aa_len\": len(aa), \"cds_len\": len(cds2), \"enzyme\": enzyme,\n",
        "            \"site_forward\": site_f, \"site_reverse\": site_r,\n",
        "            \"overhang_5\": overhang5, \"overhang_3\": overhang3, \"fasta_id\": name\n",
        "        })\n",
        "\n",
        "    (finish / \"sequences_codon_opt.fasta\").write_text(\"\\n\".join(fasta_lines) + (\"\\n\" if fasta_lines else \"\"))\n",
        "    import pandas as pd\n",
        "    pd.DataFrame(build_rows).to_csv(finish / \"cloning_plan.csv\", index=False)\n",
        "    _log(f\"build: wrote {len(build_rows)} constructs -> sequences_codon_opt.fasta, cloning_plan.csv\")\n",
        "    _log(f\"✔ done build ({time.time()-t0:.1f}s)\")\n",
        "    return state\n",
        "\n"
      ],
      "metadata": {
        "id": "fK3DfsATvFAM"
      },
      "id": "fK3DfsATvFAM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re, time\n",
        "from typing import List, Optional\n",
        "\n",
        "_UNIPROT_RE = re.compile(\n",
        "    r\"\\b(?:[OPQ][0-9][A-Z0-9]{3}[0-9]|[A-NR-Z][0-9][A-Z0-9]{3}[0-9])\\b\"  # swissprot/trembl patterns\n",
        ")\n",
        "\n",
        "def _uniprot_hints_from_selenzyme(url: str, session=None, timeout: float = 8.0, max_ids: int = 6) -> List[str]:\n",
        "    \"\"\"\n",
        "    Fetch a Selenzyme result page and extract UniProt accessions if present.\n",
        "    - Looks for explicit links to uniprot.org and also scans the page text.\n",
        "    - Returns a de-duplicated (uppercased) list, up to max_ids.\n",
        "    \"\"\"\n",
        "    if not url or not isinstance(url, str):\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        import requests\n",
        "        from bs4 import BeautifulSoup  # optional but preferred\n",
        "    except Exception:\n",
        "        requests = None\n",
        "        BeautifulSoup = None\n",
        "\n",
        "    if requests is None:\n",
        "        return []\n",
        "\n",
        "    s = session or requests.Session()\n",
        "    s.headers.update({\"User-Agent\": \"dbtl-selenzyme-scraper/0.1\"})\n",
        "\n",
        "    try:\n",
        "        r = s.get(url, timeout=timeout, allow_redirects=True)\n",
        "        if r.status_code != 200 or \"text/html\" not in (r.headers.get(\"Content-Type\",\"\")):\n",
        "            return []\n",
        "        html = r.text or \"\"\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "    ids = set()\n",
        "\n",
        "    # 1) Parse anchors to uniprot\n",
        "    if BeautifulSoup is not None:\n",
        "        try:\n",
        "            soup = BeautifulSoup(html, \"html.parser\")\n",
        "            for a in soup.find_all(\"a\", href=True):\n",
        "                href = a[\"href\"]\n",
        "                if \"uniprot.org\" in href.lower():\n",
        "                    # common patterns: /uniprotkb/<ACC>, /uniprot/<ACC>, query params, etc.\n",
        "                    m = re.search(r\"/uniprot(?:kb)?/([A-Z0-9]{6,10})\", href, flags=re.I)\n",
        "                    if m:\n",
        "                        ids.add(m.group(1).upper())\n",
        "                # also check the anchor text\n",
        "                txt = (a.get_text() or \"\").strip()\n",
        "                for m in _UNIPROT_RE.findall(txt.upper()):\n",
        "                    ids.add(m)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # 2) Regex scan of the whole page fallback\n",
        "    for m in _UNIPROT_RE.findall(html.upper()):\n",
        "        ids.add(m)\n",
        "\n",
        "    # Light politeness if this is called in a loop\n",
        "    if session is None:\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    # Defensive filter: accessions are 6–10 chars, keep the common 6-char ones first\n",
        "    ordered = sorted(ids, key=lambda x: (len(x) != 6, x))  # prefer 6-char, then lexicographic\n",
        "    return ordered[:max_ids]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MlvFnja6nkIy"
      },
      "id": "MlvFnja6nkIy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _scrape_uniprot_from_selenzyme(url, session=None, timeout=8.0):\n",
        "    \"\"\"Return a set of UniProt accessions found on a Selenzyme result page.\"\"\"\n",
        "    import re, requests\n",
        "    s = session or requests.Session()\n",
        "    s.headers.update({\"User-Agent\":\"dbtl-scraper/0.1\"})\n",
        "    try:\n",
        "        r = s.get(url, timeout=timeout)\n",
        "        if r.status_code != 200:\n",
        "            return set()\n",
        "        html = r.text\n",
        "    except Exception:\n",
        "        return set()\n",
        "    hits = set()\n",
        "    # plain accession tokens\n",
        "    for m in re.finditer(r\"\\b([OPQ][0-9][A-Z0-9]{3}[0-9]|[A-NR-Z][0-9]{5})\\b\", html):\n",
        "        hits.add(m.group(1))\n",
        "    # UniProt links\n",
        "    for m in re.finditer(r'uniprot(?:kb)?/(?:entry/)?([A-Z0-9]{6,10})', html, re.I):\n",
        "        hits.add(m.group(1))\n",
        "    return hits\n"
      ],
      "metadata": {
        "id": "lENpA1ho0wdm"
      },
      "id": "lENpA1ho0wdm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Test Node (evaluate predicted constructs) ---\n",
        "def test_node(state):\n",
        "    \"\"\"\n",
        "    Simulates or imports wet-lab results for built constructs.\n",
        "    \"\"\"\n",
        "    import pandas as pd, numpy as np\n",
        "    from pathlib import Path\n",
        "\n",
        "    finish = Path(state.get(\"workdir\") or \".\") / \"retro_finish_out\"\n",
        "    builds = pd.read_csv(finish / \"cloning_plan.csv\")\n",
        "    # fake activity measurements\n",
        "    builds[\"measured_activity\"] = np.random.rand(len(builds)) * 100\n",
        "    builds[\"status\"] = np.where(builds[\"measured_activity\"] > 50, \"active\", \"inactive\")\n",
        "\n",
        "    out = finish / \"test_results.csv\"\n",
        "    builds.to_csv(out, index=False)\n",
        "    print(f\"✔ done test_node ({len(builds)} constructs tested) → {out}\")\n",
        "    state[\"test_results\"] = str(out)\n",
        "    return state\n",
        "\n",
        "\n",
        "# --- Learn Node (update scoring models) ---\n",
        "def learn_node(state):\n",
        "    \"\"\"\n",
        "    Updates sequence ranking model using test data (simple reweighting stub).\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    from pathlib import Path\n",
        "\n",
        "    finish = Path(state.get(\"workdir\") or \".\") / \"retro_finish_out\"\n",
        "    tests = pd.read_csv(state.get(\"test_results\"))\n",
        "    avg = tests.groupby(\"status\")[\"measured_activity\"].mean().to_dict()\n",
        "    print(f\"learn_node: mean activities by status = {avg}\")\n",
        "\n",
        "    # write placeholder updated model params\n",
        "    (finish / \"learn_update.json\").write_text(json.dumps(avg, indent=2))\n",
        "    print(f\"✔ done learn_node → learn_update.json\")\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "09Uh8_D55X5R"
      },
      "id": "09Uh8_D55X5R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2Io9R2Q4iWoj",
      "metadata": {
        "id": "2Io9R2Q4iWoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da7e654-2a34-4853-ba98-f3cdc52fa18a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7eacc0e0a9c0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# If needed in a fresh notebook:\n",
        "!pip -q install langgraph langchain_core\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import os, sys, re, json, time, math, glob, shutil, textwrap, datetime, subprocess\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "from typing_extensions import Annotated, TypedDict\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "from langgraph.graph import END, StateGraph\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "from pathlib import Path\n",
        "Path(\"/content/runs/run_001/micromamba/bin\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/runs/run_001/micromamba/envs/retrobiocat\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# State schema (fixes LastValue error by marking \"run_id\" static)\n",
        "# =========================\n",
        "class DBTLState(TypedDict, total=False):\n",
        "    # Static keys (won’t change across steps; avoids InvalidUpdateError)\n",
        "    run_id: Annotated[str, \"static\"]\n",
        "    workdir: Annotated[str, \"static\"]\n",
        "\n",
        "    # Inputs\n",
        "    target_smiles: str\n",
        "    host: str\n",
        "    constraints: Dict[str, Any]\n",
        "\n",
        "    # Bookkeeping\n",
        "    status: str\n",
        "    last_node: str\n",
        "    logs: List[str]\n",
        "    error: str\n",
        "    signals: Dict[str, Any]\n",
        "    approved: bool\n",
        "\n",
        "    # Retro out\n",
        "    retro_out_dir: str\n",
        "    pathways_all_csv: Optional[str]\n",
        "    pathways_solved_csv: Optional[str]\n",
        "    pathways_all_json: Optional[str]\n",
        "    pathways_solved_json: Optional[str]\n",
        "    pathway_json_map: Dict[str, str]\n",
        "\n",
        "    # Extractor / Thermo / Rank\n",
        "    steps_plan_csv: Optional[str]\n",
        "    steps_annotated_csv: Optional[str]\n",
        "    ranked_csv: Optional[str]\n",
        "    ranked_final_csv: Optional[str]\n",
        "    ranking_method: Optional[str]\n",
        "    thermo_method: Optional[str]\n",
        "\n",
        "    # Selenzyme + sequences\n",
        "    selenzyme_rows: int\n",
        "    scraped_sequences_csv: Optional[str]\n",
        "    sequences_ranked_csv: Optional[str]\n",
        "    sequences_shortlist_csv: Optional[str]\n",
        "    sequence_rank_method: Optional[str]\n",
        "    sequence_rank_counts: Dict[str, int]\n",
        "\n",
        "    # DoE\n",
        "    screening_sheet_csv: Optional[str]\n",
        "    pathway_brief_md: Optional[str]\n",
        "    doe_pathway_tag: Optional[str]\n",
        "    doe_steps: Optional[int]\n",
        "    doe_sequences_merged: Optional[int]\n",
        "\n",
        "    # Build\n",
        "    build_out_dir: Optional[str]\n",
        "    sequence_csv: Optional[str]\n",
        "\n",
        "    # Export\n",
        "    export_manifest: Optional[str]\n",
        "    export_dir: Optional[str]\n",
        "    human_gate_md: Optional[str]\n",
        "\n",
        "\n",
        "def log(state: DBTLState, msg: str) -> Dict[str, List[str]]:\n",
        "    return {\"logs\": (state.get(\"logs\", []) + [msg])}\n",
        "\n",
        "\n",
        "# ============== Helpers ==============\n",
        "\n",
        "def wrap_node(name: str, fn):\n",
        "    \"\"\"Add start/finish logs + timing to any node.\"\"\"\n",
        "    def _wrapped(state: DBTLState) -> DBTLState:\n",
        "        t0 = time.time()\n",
        "        pre = {**state,\n",
        "               \"status\": f\"running:{name}\",\n",
        "               \"last_node\": name,\n",
        "               \"logs\": [*state.get(\"logs\", []), f\"▶ start {name}\"]}\n",
        "        out = fn(pre)\n",
        "        dt = time.time() - t0\n",
        "        out_logs = [*out.get(\"logs\", []), f\"✔ done {name} ({dt:.1f}s)\"]\n",
        "        return {**out, \"status\": f\"idle:{name}\", \"logs\": out_logs, \"last_node\": name}\n",
        "    return RunnableLambda(_wrapped)\n",
        "\n",
        "\n",
        "# ============== Nodes ==============\n",
        "\n",
        "import json, time, subprocess, shlex, os, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def _log(state, msg):\n",
        "    state.setdefault(\"logs\", []).append(msg)\n",
        "\n",
        "def retrosynthesis_node(state):\n",
        "    t0 = time.time()\n",
        "    _log(state, \"▶ start retrosynthesis\")\n",
        "    _log(state, \"retrosynthesis_node: starting\")\n",
        "\n",
        "    workdir = Path(state[\"workdir\"])\n",
        "    retro_out = workdir / \"retro_out\"\n",
        "    retro_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    target_smi = state[\"target_smiles\"]\n",
        "    expanders = state.get(\"constraints\", {}).get(\"expanders\",\n",
        "                    [\"RetroBioCat\",\"EnzymeMap\",\"BKMS\",\"RetroRules\"])\n",
        "\n",
        "    # --- Try native RBC2 first ---\n",
        "    try:\n",
        "        from rbc2 import MCTS, get_expanders\n",
        "        _log(state, \"[rbc2] native import ok; running inside current env\")\n",
        "\n",
        "        ex = get_expanders([e.lower() for e in expanders])\n",
        "        mcts = MCTS(target_smi, ex)\n",
        "        mcts.config.max_search_time = int(state.get(\"constraints\", {}).get(\"max_search_time_s\", 15))\n",
        "        mcts.run()\n",
        "\n",
        "        all_paths    = mcts.get_all_pathways()\n",
        "        solved_paths = mcts.get_solved_pathways()\n",
        "\n",
        "        def _rows(pwy, tag):\n",
        "            rows = []\n",
        "            for i, rxn in enumerate(pwy.reactions, start=1):\n",
        "                rows.append({\n",
        "                    \"pathway_tag\": tag, \"step_idx\": i,\n",
        "                    \"reaction_smiles\": rxn.reaction_smiles(),\n",
        "                    \"substrates\": \" . \".join(rxn.substrates),\n",
        "                    \"products\": rxn.product,\n",
        "                    \"rxn_type\": rxn.rxn_type, \"name\": rxn.name,\n",
        "                    \"rbc2_score\": rxn.score\n",
        "                })\n",
        "            return rows\n",
        "\n",
        "        all_rows = []\n",
        "        for k, pwy in enumerate(all_paths, start=1):\n",
        "            tag = f\"P{k:03d}\"\n",
        "            with open(retro_out / f\"{tag}.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(pwy.save(), f, indent=2)\n",
        "            all_rows.extend(_rows(pwy, tag))\n",
        "\n",
        "        if all_rows:\n",
        "            df = pd.DataFrame(all_rows)\n",
        "            df.to_csv(retro_out / \"steps.csv\", index=False)\n",
        "\n",
        "        # Minimal stubs for downstream (mirror your file names)\n",
        "        df_steps = pd.read_csv(retro_out / \"steps.csv\")\n",
        "        df_steps.to_csv(retro_out / \"pathways.csv\", index=False)\n",
        "        df_steps.to_csv(retro_out / \"pathways_solved.csv\", index=False)\n",
        "\n",
        "        _log(state, f\"[rbc2] Total pathways: {len(all_paths)} | Solved: {len(solved_paths)}\")\n",
        "\n",
        "    except Exception as native_err:\n",
        "        # --- Fallback: spawn micromamba env run (the recipe you posted) ---\n",
        "        _log(state, \"[rbc2] native import failed or missing; attempting in-place install & run\")\n",
        "        mm_bin   = workdir / \"bin\" / \"micromamba\"\n",
        "        env_path = workdir / \"micromamba\" / \"envs\" / \"retrobiocat\"\n",
        "        retro_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        try:\n",
        "            # 1) micromamba bootstrap (idempotent)\n",
        "            if not mm_bin.exists():\n",
        "                cmd = f\"curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest -o {workdir}/mm.tar.bz2\"\n",
        "                subprocess.run(shlex.split(cmd), check=True)\n",
        "                subprocess.run(shlex.split(f\"tar -xvjf {workdir}/mm.tar.bz2 -C {workdir} bin/micromamba\"), check=True)\n",
        "\n",
        "            # 2) env create\n",
        "            if not env_path.exists():\n",
        "                subprocess.run([str(mm_bin), \"create\", \"-y\", \"-p\", str(env_path), \"-c\", \"conda-forge\", \"python=3.10\", \"pip\"], check=True)\n",
        "\n",
        "            # 3) install RBC2 and pins (your exact combo)\n",
        "            def mm(cmd):\n",
        "                return [str(mm_bin), \"run\", \"-p\", str(env_path)] + cmd\n",
        "\n",
        "            subprocess.run(mm([\"python\",\"-m\",\"pip\",\"install\",\"--upgrade\",\"pip\",\"setuptools\",\"wheel\"]), check=True)\n",
        "            # Prefer zipball, fallback to git (as in your log)\n",
        "            rc = subprocess.run(mm([\"python\",\"-m\",\"pip\",\"install\",\"https://github.com/willfinnigan/RetroBioCat-2/archive/refs/heads/main.zip\"]))\n",
        "            if rc.returncode != 0:\n",
        "                subprocess.run(mm([\"python\",\"-m\",\"pip\",\"install\",\"git+https://github.com/willfinnigan/RetroBioCat-2.git\"]), check=True)\n",
        "\n",
        "            # Pins needed by your earlier runs\n",
        "            subprocess.run(mm([\"python\",\"-m\",\"pip\",\"install\",\"pydantic<2\",\"networkx<3\",\"tqdm\",\"requests\"]), check=True)\n",
        "\n",
        "            # 4) run MCTS inside that env (writes into retro_out)\n",
        "            pycode = f\"\"\"\n",
        "import json, pandas as pd\n",
        "from pathlib import Path\n",
        "from rbc2 import MCTS, get_expanders\n",
        "\n",
        "retro_out = Path(r\"{retro_out}\")\n",
        "retro_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "target_smi = r\"{target_smi}\"\n",
        "expanders  = get_expanders({[e.lower() for e in expanders]})\n",
        "\n",
        "mcts = MCTS(target_smi, expanders)\n",
        "mcts.config.max_search_time = int({int(state.get(\"constraints\", {}).get(\"max_search_time_s\", 15))})\n",
        "mcts.run()\n",
        "\n",
        "def rows(pwy, tag):\n",
        "    out = []\n",
        "    for i, rxn in enumerate(pwy.reactions, start=1):\n",
        "        out.append({{\n",
        "            \"pathway_tag\": tag, \"step_idx\": i,\n",
        "            \"reaction_smiles\": rxn.reaction_smiles(),\n",
        "            \"substrates\": \" . \".join(rxn.substrates),\n",
        "            \"products\": rxn.product,\n",
        "            \"rxn_type\": rxn.rxn_type, \"name\": rxn.name,\n",
        "            \"rbc2_score\": rxn.score\n",
        "        }})\n",
        "    return out\n",
        "\n",
        "all_rows = []\n",
        "for k, pwy in enumerate(mcts.get_all_pathways(), start=1):\n",
        "    tag = f\"P{{k:03d}}\"\n",
        "    with open(retro_out / f\"{{tag}}.json\",\"w\",encoding=\"utf-8\") as f:\n",
        "        json.dump(pwy.save(), f, indent=2)\n",
        "    all_rows.extend(rows(pwy, tag))\n",
        "\n",
        "if all_rows:\n",
        "    df = pd.DataFrame(all_rows)\n",
        "    df.to_csv(retro_out / \"steps.csv\", index=False)\n",
        "    df.to_csv(retro_out / \"pathways.csv\", index=False)\n",
        "    df.to_csv(retro_out / \"pathways_solved.csv\", index=False)\n",
        "\n",
        "print(\"[rbc2] write:\", retro_out)\n",
        "\"\"\"\n",
        "            subprocess.run(mm([\"python\",\"-c\", pycode]), check=True)\n",
        "            _log(state, \"[rbc2] run ok\")\n",
        "\n",
        "        except subprocess.CalledProcessError as e2:\n",
        "            _log(state, \"[rbc2] run_failed\")\n",
        "            # Emit empty stub so downstream nodes don’t die\n",
        "            (retro_out / \"steps.csv\").write_text(\"\")\n",
        "            (retro_out / \"pathways.csv\").write_text(\"\")\n",
        "            (retro_out / \"pathways_solved.csv\").write_text(\"\")\n",
        "\n",
        "    # Hand off common outputs into state\n",
        "    state[\"retro_out\"] = str(retro_out)\n",
        "    state.setdefault(\"artifacts\", []).extend([\n",
        "        str(retro_out / \"steps.csv\"),\n",
        "        str(retro_out / \"pathways.csv\"),\n",
        "        str(retro_out / \"pathways_solved.csv\"),\n",
        "    ])\n",
        "    _log(state, f\"✔ done retrosynthesis ({time.time()-t0:.1f}s)\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def extract_pathways_node(state: DBTLState) -> DBTLState:\n",
        "    \"\"\"\n",
        "    Build enzyme-planning artifacts from RetroBioCat-2 outputs:\n",
        "      - steps_enzyme_plan.csv (per-step details incl. enzyme classes, precedents, Selenzyme links)\n",
        "      - pathways_ranked_no_thermo.csv (RBC2 + precedent-based ranking; no thermodynamics)\n",
        "    \"\"\"\n",
        "    workdir = Path(state[\"workdir\"])\n",
        "    retro_out = workdir / \"retro_out\"\n",
        "    finish_out = workdir / \"retro_finish_out\"\n",
        "    finish_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # pick CSV (solved preferred, else all)\n",
        "    csv_solved = retro_out / \"pathways_solved_steps.csv\"\n",
        "    csv_all    = retro_out / \"pathways_all_steps.csv\"\n",
        "    csv_in = csv_solved if csv_solved.exists() else csv_all\n",
        "    if not csv_in.exists():\n",
        "        raise FileNotFoundError(f\"No pathways CSV found under {retro_out}\")\n",
        "\n",
        "    steps_df = pd.read_csv(csv_in)\n",
        "\n",
        "    # pathway -> json map\n",
        "    json_map: Dict[str,str] = dict(state.get(\"pathway_json_map\") or {})\n",
        "    if not json_map:\n",
        "        for p in glob.glob(str(retro_out / \"P*.json\")):\n",
        "            tag = Path(p).stem  # P001\n",
        "            json_map[tag] = p\n",
        "\n",
        "    from urllib.parse import quote_plus\n",
        "\n",
        "    def selenzyme_url_from_rxn(rxn_smiles: str, org: str) -> str:\n",
        "        return (\n",
        "            \"https://selenzyme.synbiochem.co.uk/selenzy/selenzy?reaction_smiles=\"\n",
        "            + quote_plus(rxn_smiles)\n",
        "            + \"&organism=\"\n",
        "            + quote_plus(org)\n",
        "        )\n",
        "\n",
        "    host_org = state.get(\"host\") or \"Escherichia coli\"\n",
        "\n",
        "    # expand per-step details from Pxxx.json\n",
        "    records = []\n",
        "    for _, r in steps_df.iterrows():\n",
        "        tag   = str(r.get(\"pathway_tag\"))\n",
        "        idx   = int(r.get(\"step_idx\"))\n",
        "        rxn   = str(r.get(\"reaction_smiles\",\"\"))\n",
        "        prod  = str(r.get(\"products\", r.get(\"product\",\"\")))\n",
        "        subs  = str(r.get(\"substrates\",\"\"))\n",
        "\n",
        "        rxn_type = r.get(\"rxn_type\",\"\")\n",
        "        name     = r.get(\"name\",\"\")\n",
        "        rbc2_score = r.get(\"score\", float(\"nan\"))\n",
        "\n",
        "        possible_enzymes = []\n",
        "        enzyme_choices = []\n",
        "        selected_enzyme = \"\"\n",
        "        precedents = []\n",
        "\n",
        "        pj = json_map.get(tag)\n",
        "        if pj and os.path.exists(pj):\n",
        "            try:\n",
        "                data = json.load(open(pj, \"r\"))\n",
        "                if isinstance(data, list) and 1 <= idx <= len(data):\n",
        "                    d = data[idx - 1]\n",
        "                    rxn_type = d.get(\"rxn_type\", rxn_type)\n",
        "                    name     = d.get(\"name\", name)\n",
        "                    tm = d.get(\"template_metadata\", {}) or {}\n",
        "                    if tm:\n",
        "                        tkey = next(iter(tm.keys()))\n",
        "                        tmeta = tm.get(tkey, {}) or {}\n",
        "                        possible_enzymes = (tmeta.get(\"possible_enzymes\") or [])\n",
        "                        choices = (tmeta.get(\"enzyme_choices\") or [])\n",
        "                        enzyme_choices = [\n",
        "                            \" / \".join(x) if isinstance(x, (list, tuple)) else str(x)\n",
        "                            for x in choices\n",
        "                        ]\n",
        "                        selected_enzyme = tmeta.get(\"selected_enzyme\") or \"\"\n",
        "                    precedents = d.get(\"precedents\") or []\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        prec_sorted = sorted(precedents, key=lambda x: x.get(\"similarity\", 0), reverse=True)[:3]\n",
        "        prec_summ, best_sim = [], float(\"nan\")\n",
        "        for p in prec_sorted:\n",
        "            sim = p.get(\"similarity\", float(\"nan\"))\n",
        "            dat = p.get(\"data\", {}) or {}\n",
        "            doi = dat.get(\"html_doi\", \"\") or dat.get(\"doi\", \"\")\n",
        "            enz = dat.get(\"enzyme_name\", \"\") or p.get(\"name\", \"\")\n",
        "            cite = dat.get(\"short_citation\", \"\")\n",
        "            try:\n",
        "                prec_summ.append(f\"{enz} | sim={float(sim):.3f} | {cite} | {doi}\")\n",
        "            except Exception:\n",
        "                prec_summ.append(f\"{enz} | sim={sim} | {cite} | {doi}\")\n",
        "        if prec_sorted:\n",
        "            best_sim = prec_sorted[0].get(\"similarity\", float(\"nan\"))\n",
        "\n",
        "        records.append({\n",
        "            \"pathway_tag\": tag,\n",
        "            \"step_idx\": idx,\n",
        "            \"rxn_type\": rxn_type,\n",
        "            \"retrobiocat_reaction\": name,\n",
        "            \"reaction_smiles\": rxn,\n",
        "            \"substrates\": subs,\n",
        "            \"products\": prod,\n",
        "            \"rbc2_score\": rbc2_score,\n",
        "            \"selected_enzyme\": selected_enzyme,\n",
        "            \"possible_enzymes\": \" ; \".join(possible_enzymes),\n",
        "            \"enzyme_choices\": \" ; \".join(enzyme_choices),\n",
        "            \"precedent_top3\": \" || \".join(prec_summ),\n",
        "            \"precedent_best_similarity\": best_sim,\n",
        "            \"selenzyme_url\": selenzyme_url_from_rxn(rxn, host_org),\n",
        "        })\n",
        "\n",
        "    plan = pd.DataFrame(records).sort_values([\"pathway_tag\",\"step_idx\"]).reset_index(drop=True)\n",
        "\n",
        "    # pathway ranking (no thermo)\n",
        "    tmp = plan.copy()\n",
        "    tmp[\"rbc2_score\"] = pd.to_numeric(tmp[\"rbc2_score\"], errors=\"coerce\").fillna(0.0)\n",
        "    tmp[\"precedent_best_similarity\"] = pd.to_numeric(tmp[\"precedent_best_similarity\"], errors=\"coerce\").fillna(0.0)\n",
        "\n",
        "    agg = tmp.groupby(\"pathway_tag\").agg(\n",
        "        steps_count=(\"step_idx\",\"max\"),\n",
        "        sum_rbc2=(\"rbc2_score\",\"sum\"),\n",
        "        sum_prec_sim=(\"precedent_best_similarity\",\"sum\"),\n",
        "    ).reset_index()\n",
        "    agg[\"rank_score\"] = agg[\"sum_rbc2\"] + 0.2*agg[\"sum_prec_sim\"] - 0.1*agg[\"steps_count\"]\n",
        "    ranked = agg.sort_values(\n",
        "        [\"rank_score\",\"sum_rbc2\",\"sum_prec_sim\",\"steps_count\"],\n",
        "        ascending=[False, False, False, True]\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    steps_plan_csv = str(finish_out / \"steps_enzyme_plan.csv\")\n",
        "    ranked_csv     = str(finish_out / \"pathways_ranked_no_thermo.csv\")\n",
        "    plan.to_csv(steps_plan_csv, index=False)\n",
        "    ranked.to_csv(ranked_csv, index=False)\n",
        "\n",
        "    new_state = {\n",
        "        **state,\n",
        "        \"steps_plan_csv\": steps_plan_csv,\n",
        "        \"ranked_csv\": ranked_csv,\n",
        "        \"thermo_method\": \"none\",\n",
        "    }\n",
        "    new_state[\"logs\"] = state.get(\"logs\", []) + [\n",
        "        f\"extracted pathways ({len(plan)} step rows, {len(ranked)} pathways)\",\n",
        "        f\"steps_plan={steps_plan_csv}\",\n",
        "        f\"ranked_no_thermo={ranked_csv}\",\n",
        "    ]\n",
        "    return new_state\n",
        "\n",
        "\n",
        "def thermo_score_node(state: DBTLState) -> DBTLState:\n",
        "    \"\"\"\n",
        "    Lightweight 'match-only' thermo pass (no ChemAxon / ΔG):\n",
        "      - Emits steps_annotated.csv and pathways_ranked.csv (same heuristic as extractor).\n",
        "    \"\"\"\n",
        "    workdir    = Path(state[\"workdir\"])\n",
        "    mm_root    = workdir / \"micromamba\"\n",
        "    env_prefix = mm_root / \"envs\" / \"retrobiocat\"  # same env\n",
        "    retro_out  = workdir / \"retro_out\"\n",
        "    finish_out = workdir / \"retro_finish_out\"\n",
        "    finish_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    steps_plan_csv = state.get(\"steps_plan_csv\")\n",
        "    if not steps_plan_csv or not Path(steps_plan_csv).exists():\n",
        "        csv_solved = retro_out / \"pathways_solved_steps.csv\"\n",
        "        csv_all    = retro_out / \"pathways_all_steps.csv\"\n",
        "        steps_plan_csv = str(csv_solved if csv_solved.exists() else csv_all)\n",
        "\n",
        "    steps_out = str(finish_out / \"steps_annotated.csv\")\n",
        "    rank_out  = str(finish_out / \"pathways_ranked.csv\")\n",
        "\n",
        "    py = f\"\"\"\\\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "IN  = Path(r\"{steps_plan_csv}\")\n",
        "OUT_STEPS = Path(r\"{steps_out}\")\n",
        "OUT_RANK  = Path(r\"{rank_out}\")\n",
        "\n",
        "if not IN.exists():\n",
        "    raise FileNotFoundError(f\"Input steps table not found: {{IN}}\")\n",
        "\n",
        "df = pd.read_csv(IN)\n",
        "\n",
        "# Ensure required columns exist\n",
        "for col in [\"pathway_tag\",\"step_idx\",\"reaction_smiles\",\"substrates\",\"products\",\n",
        "            \"rbc2_score\",\"precedent_best_similarity\",\"selenzyme_url\"]:\n",
        "    if col not in df.columns:\n",
        "        df[col] = \"\" if col not in [\"rbc2_score\",\"precedent_best_similarity\"] else 0.0\n",
        "\n",
        "# Add placeholders for thermo\n",
        "df[\"dGprime_kJ_per_mol\"] = float(\"nan\")\n",
        "df[\"uncert_kJ_per_mol\"]  = float(\"nan\")\n",
        "df[\"thermo_pass\"]        = False\n",
        "df[\"equilibrator_formula\"] = \"\"\n",
        "\n",
        "# Save annotated\n",
        "df.to_csv(OUT_STEPS, index=False)\n",
        "\n",
        "# Ranking (same as extractor)\n",
        "tmp = df.copy()\n",
        "tmp[\"rbc2_score\"] = pd.to_numeric(tmp[\"rbc2_score\"], errors=\"coerce\").fillna(0.0)\n",
        "tmp[\"precedent_best_similarity\"] = pd.to_numeric(tmp[\"precedent_best_similarity\"], errors=\"coerce\").fillna(0.0)\n",
        "\n",
        "agg = tmp.groupby(\"pathway_tag\").agg(\n",
        "    steps_count=(\"step_idx\",\"max\"),\n",
        "    sum_rbc2=(\"rbc2_score\",\"sum\"),\n",
        "    sum_prec_sim=(\"precedent_best_similarity\",\"sum\"),\n",
        ").reset_index()\n",
        "\n",
        "agg[\"rank_score\"] = agg[\"sum_rbc2\"] + 0.2*agg[\"sum_prec_sim\"] - 0.1*agg[\"steps_count\"]\n",
        "ranked = agg.sort_values([\"rank_score\",\"sum_rbc2\",\"sum_prec_sim\",\"steps_count\"],\n",
        "                         ascending=[False,False,False,True]).reset_index(drop=True)\n",
        "ranked.to_csv(OUT_RANK, index=False)\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\" \", OUT_STEPS)\n",
        "print(\" \", OUT_RANK)\n",
        "\"\"\"\n",
        "    micromamba = workdir / \"bin\" / \"micromamba\"\n",
        "    if not micromamba.exists():\n",
        "        micromamba = \"micromamba\"\n",
        "\n",
        "    env = os.environ.copy()\n",
        "    env[\"MAMBA_ROOT_PREFIX\"] = str(mm_root)\n",
        "\n",
        "    try:\n",
        "        _run(f\"\"\"{micromamba} run -p \"{env_prefix}\" python - <<'PY'\\n{py}\\nPY\"\"\", env=env)\n",
        "    except subprocess.CalledProcessError:\n",
        "        _run(f\"python - <<'PY'\\n{py}\\nPY\")\n",
        "\n",
        "    coverage = 0\n",
        "    method = \"matchonly\"\n",
        "\n",
        "    new_state = {\n",
        "        **state,\n",
        "        \"thermo_method\": method,\n",
        "        \"steps_annotated_csv\": steps_out,\n",
        "        \"ranked_csv\": rank_out,\n",
        "    }\n",
        "    new_state[\"logs\"] = state.get(\"logs\", []) + [\n",
        "        f\"thermo: {method}, coverage={coverage}\",\n",
        "        f\"steps_annotated={steps_out}\",\n",
        "        f\"ranked={rank_out}\",\n",
        "    ]\n",
        "    return new_state\n",
        "\n",
        "\n",
        "def rank_node(state: DBTLState) -> DBTLState:\n",
        "    \"\"\"\n",
        "    Merge thermo info (if available) into pathway ranking; else keep RBC2+precedent ranking.\n",
        "    Emits pathways_ranked_final.csv\n",
        "    \"\"\"\n",
        "    workdir = Path(state[\"workdir\"])\n",
        "    finish_out = workdir / \"retro_finish_out\"\n",
        "    finish_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    steps_csv = state.get(\"steps_annotated_csv\") or state.get(\"steps_plan_csv\")\n",
        "    if not steps_csv or not Path(steps_csv).exists():\n",
        "        raise FileNotFoundError(\"rank_node: steps CSV not found in state\")\n",
        "\n",
        "    df = pd.read_csv(steps_csv)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    has_thermo = any(c in df.columns for c in [\"dGprime_kJ_per_mol\", \"thermo_pass\"])\n",
        "    thermo_mode = bool(has_thermo and df[\"thermo_pass\"].any())  # likely False in match-only\n",
        "\n",
        "    df[\"rbc2_score\"] = pd.to_numeric(df.get(\"rbc2_score\", 0.0), errors=\"coerce\").fillna(0.0)\n",
        "    df[\"precedent_best_similarity\"] = pd.to_numeric(df.get(\"precedent_best_similarity\", 0.0),\n",
        "                                                    errors=\"coerce\").fillna(0.0)\n",
        "    if \"dGprime_kJ_per_mol\" in df:\n",
        "        df[\"dGprime_kJ_per_mol\"] = pd.to_numeric(df[\"dGprime_kJ_per_mol\"], errors=\"coerce\")\n",
        "\n",
        "    group = df.groupby(\"pathway_tag\", dropna=True)\n",
        "\n",
        "    if thermo_mode:\n",
        "        ranked = (\n",
        "            group.agg(\n",
        "                steps_count=(\"step_idx\",\"max\"),\n",
        "                sum_rbc2=(\"rbc2_score\",\"sum\"),\n",
        "                sum_prec_sim=(\"precedent_best_similarity\",\"sum\"),\n",
        "                thermo_pass_steps=(\"thermo_pass\",\"sum\"),\n",
        "                sum_dGprime=(\"dGprime_kJ_per_mol\",\"sum\"),\n",
        "            )\n",
        "            .reset_index()\n",
        "        )\n",
        "        ranked[\"all_steps_pass\"] = ranked[\"thermo_pass_steps\"] == ranked[\"steps_count\"]\n",
        "        ranked[\"rank_score\"] = (\n",
        "            ranked[\"sum_rbc2\"]\n",
        "            + 0.2 * ranked[\"sum_prec_sim\"]\n",
        "            - 0.1 * ranked[\"steps_count\"]\n",
        "            - 0.001 * ranked[\"sum_dGprime\"].fillna(0.0)\n",
        "            + ranked[\"all_steps_pass\"].astype(float) * 0.5\n",
        "        )\n",
        "        method = \"rbc2+precedent+thermo\"\n",
        "    else:\n",
        "        ranked = (\n",
        "            group.agg(\n",
        "                steps_count=(\"step_idx\",\"max\"),\n",
        "                sum_rbc2=(\"rbc2_score\",\"sum\"),\n",
        "                sum_prec_sim=(\"precedent_best_similarity\",\"sum\"),\n",
        "            )\n",
        "            .reset_index()\n",
        "        )\n",
        "        ranked[\"rank_score\"] = (\n",
        "            ranked[\"sum_rbc2\"] + 0.2 * ranked[\"sum_prec_sim\"] - 0.1 * ranked[\"steps_count\"]\n",
        "        )\n",
        "        method = \"rbc2+precedent\"\n",
        "\n",
        "    ranked = ranked.sort_values(\n",
        "        [\"rank_score\",\"sum_rbc2\",\"sum_prec_sim\",\"steps_count\"],\n",
        "        ascending=[False, False, False, True],\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    out_csv = str(finish_out / \"pathways_ranked_final.csv\")\n",
        "    ranked.to_csv(out_csv, index=False)\n",
        "\n",
        "    new_state = {\n",
        "        **state,\n",
        "        \"ranked_final_csv\": out_csv,\n",
        "        \"ranking_method\": method,\n",
        "    }\n",
        "    new_state[\"logs\"] = state.get(\"logs\", []) + [\n",
        "        f\"ranked pathways ({method}, {len(ranked)} entries)\",\n",
        "        f\"ranked_final={out_csv}\",\n",
        "    ]\n",
        "    return new_state\n",
        "\n",
        "\n",
        "def selenzyme_node(state: DBTLState) -> DBTLState:\n",
        "    \"\"\"\n",
        "    Collect Selenzyme links and try to scrape top sequences (polite, tolerant).\n",
        "    Falls back to counting links if blocked. Emits selenzyme_scrape.csv if rows found.\n",
        "    \"\"\"\n",
        "    workdir = Path(state[\"workdir\"])\n",
        "    finish_out = workdir / \"retro_finish_out\"\n",
        "    finish_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    steps_csv = state.get(\"steps_annotated_csv\") or state.get(\"steps_plan_csv\")\n",
        "    if not steps_csv or not Path(steps_csv).exists():\n",
        "        raise FileNotFoundError(\"selenzyme_node: no steps CSV found in state\")\n",
        "\n",
        "    steps = pd.read_csv(steps_csv)\n",
        "    if \"selenzyme_url\" not in steps.columns:\n",
        "        new_state = {\n",
        "            **state,\n",
        "            \"selenzyme_rows\": 0,\n",
        "            \"scraped_sequences_csv\": None,\n",
        "        }\n",
        "        new_state[\"logs\"] = state.get(\"logs\", []) + [\"selenzyme: no 'selenzyme_url' column; skipped\"]\n",
        "        return new_state\n",
        "\n",
        "    url_map: Dict[str, List[Tuple[str,int]]] = {}\n",
        "    for _, r in steps.iterrows():\n",
        "        url = str(r.get(\"selenzyme_url\") or \"\").strip()\n",
        "        if not url:\n",
        "            continue\n",
        "        tag = str(r.get(\"pathway_tag\"))\n",
        "        idx = int(r.get(\"step_idx\", 0))\n",
        "        url_map.setdefault(url, []).append((tag, idx))\n",
        "\n",
        "    unique_urls = list(url_map.keys())\n",
        "\n",
        "    cfg = (state.get(\"constraints\", {}) or {}).get(\"selenzyme\", {}) or {}\n",
        "    do_scrape: bool   = bool(cfg.get(\"scrape\", True))\n",
        "    max_urls: int     = int(cfg.get(\"max_urls\", 40))\n",
        "    timeout_s: int    = int(cfg.get(\"timeout_s\", 15))\n",
        "    sleep_s: float    = float(cfg.get(\"sleep_s\", 1.0))\n",
        "\n",
        "    urls_to_hit = unique_urls[:max_urls]\n",
        "    scraped_rows: List[Dict] = []\n",
        "    blocked_reason: Optional[str] = None\n",
        "\n",
        "    def _try_scrape(url: str) -> List[Dict]:\n",
        "        nonlocal blocked_reason\n",
        "        try:\n",
        "            import requests\n",
        "            from bs4 import BeautifulSoup  # type: ignore\n",
        "\n",
        "            headers = {\n",
        "                \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0 Safari/537.36\",\n",
        "                \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
        "                \"Connection\": \"keep-alive\",\n",
        "            }\n",
        "            resp = requests.get(url, headers=headers, timeout=timeout_s)\n",
        "            if resp.status_code in (403, 429):\n",
        "                raise RuntimeError(f\"HTTP {resp.status_code}\")\n",
        "            if not resp.ok or not resp.text:\n",
        "                return []\n",
        "            html = resp.text\n",
        "            soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "            table = None\n",
        "            for t in soup.find_all(\"table\"):\n",
        "                ths = [th.get_text(strip=True).lower() for th in t.find_all(\"th\")]\n",
        "                joined = \" \".join(ths)\n",
        "                if any(k in joined for k in [\"uniprot\", \"organism\", \"score\", \"ec\", \"enzyme\"]):\n",
        "                    table = t\n",
        "                    break\n",
        "\n",
        "            rows_local: List[Dict] = []\n",
        "            if table:\n",
        "                headers = [th.get_text(strip=True) for th in table.find_all(\"th\")]\n",
        "                idx_map = {h.lower(): i for i, h in enumerate(headers)}\n",
        "\n",
        "                def _get(td_list, key_variants):\n",
        "                    for k in key_variants:\n",
        "                        i = idx_map.get(k)\n",
        "                        if i is not None and i < len(td_list):\n",
        "                            return td_list[i].get_text(strip=True)\n",
        "                    return \"\"\n",
        "\n",
        "                for tr in table.find_all(\"tr\"):\n",
        "                    tds = tr.find_all(\"td\")\n",
        "                    if not tds:\n",
        "                        continue\n",
        "                    acc = _get(tds, [\"uniprot\", \"accession\", \"uniprot id\"])\n",
        "                    org = _get(tds, [\"organism\", \"source\", \"species\"])\n",
        "                    scr = _get(tds, [\"score\", \"similarity\", \"sim\"])\n",
        "                    ec  = _get(tds, [\"ec\", \"ec number\"])\n",
        "                    enz = _get(tds, [\"enzyme\", \"name\", \"protein\"])\n",
        "\n",
        "                    if not acc:\n",
        "                        a = tds[0].find(\"a\")\n",
        "                        if a and a.get_text(strip=True):\n",
        "                            acc = a.get_text(strip=True)\n",
        "                    if not acc:\n",
        "                        m = re.search(r\"[A-NR-Z0-9]{{6,10}}\", tr.get_text(\" \", strip=True))\n",
        "                        if m:\n",
        "                            acc = m.group(0)\n",
        "\n",
        "                    try:\n",
        "                        scr_val = float(re.sub(\"[^0-9.+-eE]\", \"\", scr)) if scr else None\n",
        "                    except Exception:\n",
        "                        scr_val = None\n",
        "\n",
        "                    rows_local.append({\n",
        "                        \"accession\": acc,\n",
        "                        \"organism\": org,\n",
        "                        \"score\": scr_val if scr_val is not None else scr,\n",
        "                        \"ec\": ec,\n",
        "                        \"enzyme_name\": enz,\n",
        "                    })\n",
        "\n",
        "            if not rows_local:\n",
        "                tokens = re.findall(r\"\\b[OPQ][0-9][A-Z0-9]{{3}}[0-9]\\b|\\b[A-NR-Z0-9]{{6}}\\b\", html)\n",
        "                rows_local = [{\"accession\": t, \"organism\": \"\", \"score\": \"\", \"ec\": \"\", \"enzyme_name\": \"\"} for t in dict.fromkeys(tokens)]\n",
        "\n",
        "            return rows_local\n",
        "\n",
        "        except Exception as e:\n",
        "            blocked_reason = str(e)\n",
        "            return []\n",
        "\n",
        "    if do_scrape and len(urls_to_hit) > 0:\n",
        "        for i, url in enumerate(urls_to_hit, 1):\n",
        "            rows_local = _try_scrape(url)\n",
        "            for (tag, idx) in url_map.get(url, []):\n",
        "                for r in rows_local:\n",
        "                    scraped_rows.append({\n",
        "                        \"pathway_tag\": tag,\n",
        "                        \"step_idx\": idx,\n",
        "                        \"selenzyme_url\": url,\n",
        "                        **r\n",
        "                    })\n",
        "            if i < len(urls_to_hit):\n",
        "                try:\n",
        "                    time.sleep(sleep_s)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    scraped_csv_path: Optional[str] = None\n",
        "    if scraped_rows:\n",
        "        out_csv = finish_out / \"selenzyme_scrape.csv\"\n",
        "        pd.DataFrame(scraped_rows, columns=[\n",
        "            \"pathway_tag\",\"step_idx\",\"selenzyme_url\",\n",
        "            \"accession\",\"organism\",\"score\",\"ec\",\"enzyme_name\"\n",
        "        ]).to_csv(out_csv, index=False)\n",
        "        scraped_csv_path = str(out_csv)\n",
        "\n",
        "    total_links = len(unique_urls)\n",
        "    rows = len(scraped_rows)\n",
        "\n",
        "    log_lines = [\n",
        "        f\"selenzyme: links={total_links}, scraped_rows={rows}, mode={'scrape' if do_scrape else 'count-only'}\"\n",
        "    ]\n",
        "    if blocked_reason and rows == 0 and do_scrape:\n",
        "        log_lines.append(f\"selenzyme: scrape blocked or failed ({blocked_reason}); fell back to count-only\")\n",
        "\n",
        "    new_state = {\n",
        "        **state,\n",
        "        \"selenzyme_rows\": rows,\n",
        "        \"scraped_sequences_csv\": scraped_csv_path,\n",
        "    }\n",
        "    new_state[\"logs\"] = state.get(\"logs\", []) + log_lines\n",
        "    return new_state\n",
        "\n",
        "\n",
        "def selenzyme_rank_node(state):\n",
        "    \"\"\"\n",
        "    Reads steps_enzyme_plan.csv (or choice) and writes steps_enzyme_choice.csv with:\n",
        "      - selenzyme_url intact\n",
        "      - seed_uniprots column ALWAYS present ('' when none)\n",
        "      - delimiters normalized to ';' (so downstream cleaner sees them)\n",
        "    \"\"\"\n",
        "    import re, time\n",
        "    from pathlib import Path\n",
        "    import pandas as pd\n",
        "\n",
        "    t0 = time.time()\n",
        "    workdir = Path(state.get(\"workdir\") or state.get(\"run_dir\") or \".\")\n",
        "    finish  = workdir / \"retro_finish_out\"\n",
        "    finish.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # input can be steps_enzyme_plan.csv or already-ranked file; prefer plan if present\n",
        "    plan = finish / \"steps_enzyme_plan.csv\"\n",
        "    out  = finish / \"steps_enzyme_choice.csv\"\n",
        "\n",
        "    if not plan.exists():\n",
        "        raise FileNotFoundError(f\"missing: {plan}\")\n",
        "\n",
        "    df = pd.read_csv(plan)\n",
        "\n",
        "    # --- ensure column exists ---\n",
        "    if \"seed_uniprots\" not in df.columns:\n",
        "        df[\"seed_uniprots\"] = \"\"\n",
        "\n",
        "    # --- normalize anything we *do* have to canonical ';' delimiter ---\n",
        "    # accept commas, pipes, spaces, semicolons; keep only UniProt-like tokens\n",
        "    def _norm(s: str) -> str:\n",
        "        if not isinstance(s, str) or not s.strip():\n",
        "            return \"\"\n",
        "        toks = re.split(r\"[,\\s;|]+\", s.strip())\n",
        "        toks = [t.upper() for t in toks if re.fullmatch(r\"[A-Z0-9]{6,10}\", t)]\n",
        "        return \";\".join(sorted(set(toks)))\n",
        "\n",
        "    df[\"seed_uniprots\"] = df[\"seed_uniprots\"].map(_norm)\n",
        "\n",
        "    # (optional) if you scraped anything temporary like 'seed_scraped' merge & normalize here:\n",
        "    if \"seed_scraped\" in df.columns:\n",
        "        merged = []\n",
        "        for a, b in zip(df[\"seed_uniprots\"], df[\"seed_scraped\"]):\n",
        "            aa = set(_norm(a).split(\";\")) if a else set()\n",
        "            bb = set(_norm(b).split(\";\")) if isinstance(b, str) else set()\n",
        "            tok = \";\".join(sorted((aa | bb) - {\"\"}))\n",
        "            merged.append(tok)\n",
        "        df[\"seed_uniprots\"] = merged\n",
        "\n",
        "    df.to_csv(out, index=False)\n",
        "    n_nonempty = int((df[\"seed_uniprots\"].fillna(\"\")!=\"\").sum())\n",
        "    state.setdefault(\"logs\", []).append(\n",
        "        f\"selenzyme_rank: seed_uniprots populated for {n_nonempty} / {len(df)} steps\"\n",
        "    )\n",
        "    state[\"selenzyme_choice_csv\"] = str(out)\n",
        "    state[\"workdir\"] = str(workdir)  # keep around for downstream nodes\n",
        "    return state\n",
        "\n",
        "\n",
        "def doe_node(state: DBTLState) -> DBTLState:\n",
        "    \"\"\"\n",
        "    Build a DoE screening sheet + markdown brief for the top-ranked pathway.\n",
        "    Also merges the top-ranked sequence per step (if available).\n",
        "    \"\"\"\n",
        "    from urllib.parse import quote_plus\n",
        "\n",
        "    workdir = Path(state[\"workdir\"])\n",
        "    finish_out = workdir / \"retro_finish_out\"\n",
        "    finish_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    rank_csv  = state.get(\"ranked_csv\") or state.get(\"ranked_final_csv\")\n",
        "    steps_csv = state.get(\"steps_plan_csv\") or state.get(\"steps_annotated_csv\") or str(finish_out / \"steps_enzyme_plan.csv\")\n",
        "    if not (rank_csv and Path(rank_csv).exists()):\n",
        "        raise FileNotFoundError(\"doe_node: ranked_csv missing or not found.\")\n",
        "    if not (steps_csv and Path(steps_csv).exists()):\n",
        "        raise FileNotFoundError(\"doe_node: steps CSV missing or not found.\")\n",
        "\n",
        "    ranked = pd.read_csv(rank_csv)\n",
        "    steps  = pd.read_csv(steps_csv)\n",
        "    ranked.columns = [c.strip() for c in ranked.columns]\n",
        "    steps.columns  = [c.strip() for c in steps.columns]\n",
        "\n",
        "    best_tag = str(ranked.iloc[0][\"pathway_tag\"])\n",
        "    psteps = (\n",
        "        steps[steps[\"pathway_tag\"] == best_tag]\n",
        "        .sort_values(\"step_idx\")\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    # bring in top-ranked sequence per step (optional)\n",
        "    seq_csv = state.get(\"sequences_ranked_csv\")\n",
        "    merged_n = 0\n",
        "    top_seq_by_step = None\n",
        "    if seq_csv and Path(seq_csv).exists():\n",
        "        seq = pd.read_csv(seq_csv)\n",
        "        seq.columns = [c.strip() for c in seq.columns]\n",
        "        if \"pathway_tag\" in seq.columns and \"rank_score\" in seq.columns:\n",
        "            seq_best = seq[seq[\"pathway_tag\"] == best_tag].copy()\n",
        "            if not seq_best.empty:\n",
        "                seq_best[\"rank_score\"] = pd.to_numeric(seq_best[\"rank_score\"], errors=\"coerce\").fillna(0.0)\n",
        "                seq_best = (\n",
        "                    seq_best.sort_values([\"step_idx\",\"rank_score\"], ascending=[True, False])\n",
        "                            .groupby(\"step_idx\", as_index=False)\n",
        "                            .first()\n",
        "                )\n",
        "                keep_cols = {\n",
        "                    \"step_idx\":\"step_idx\",\n",
        "                    \"accession\":\"sequence_accession\",\n",
        "                    \"organism\":\"source_organism\",\n",
        "                    \"uniprot_url\":\"uniprot_url\"\n",
        "                }\n",
        "                for k in keep_cols.keys():\n",
        "                    if k not in seq_best.columns:\n",
        "                        seq_best[k] = \"\"\n",
        "                top_seq_by_step = seq_best[list(keep_cols.keys())].rename(columns=keep_cols)\n",
        "\n",
        "    cols = [\n",
        "        \"pathway_tag\",\"step_idx\",\"retrobiocat_reaction\",\"reaction_smiles\",\n",
        "        \"selected_enzyme\",\"possible_enzymes\",\"selenzyme_url\",\n",
        "        \"sequence_accession\",\"source_organism\",\"uniprot_url\",\n",
        "        \"assay_buffer\",\"pH\",\"temp_C\",\"cofactor\",\"cofactor_recycle\",\n",
        "        \"substrate_conc_mM\",\"enzyme_loading_mg_per_mL\",\"time_h\",\n",
        "        \"conversion_%\",\"notes\"\n",
        "    ]\n",
        "    rows = []\n",
        "    for _, r in psteps.iterrows():\n",
        "        query = quote_plus(str(r.get(\"selected_enzyme\") or r.get(\"retrobiocat_reaction\")))\n",
        "        uniprot_search = f\"https://www.uniprot.org/uniprotkb?query={query}\"\n",
        "        rows.append({\n",
        "            \"pathway_tag\": best_tag,\n",
        "            \"step_idx\": int(r.get(\"step_idx\", 0)),\n",
        "            \"retrobiocat_reaction\": r.get(\"retrobiocat_reaction\", \"\"),\n",
        "            \"reaction_smiles\": r.get(\"reaction_smiles\", \"\"),\n",
        "            \"selected_enzyme\": r.get(\"selected_enzyme\", \"\"),\n",
        "            \"possible_enzymes\": r.get(\"possible_enzymes\", \"\"),\n",
        "            \"selenzyme_url\": r.get(\"selenzyme_url\", \"\"),\n",
        "            \"sequence_accession\": \"\",\n",
        "            \"source_organism\": \"\",\n",
        "            \"uniprot_url\": uniprot_search,\n",
        "            \"assay_buffer\": \"\",\n",
        "            \"pH\": \"\",\n",
        "            \"temp_C\": \"\",\n",
        "            \"cofactor\": \"\",\n",
        "            \"cofactor_recycle\": \"\",\n",
        "            \"substrate_conc_mM\": \"\",\n",
        "            \"enzyme_loading_mg_per_mL\": \"\",\n",
        "            \"time_h\": \"\",\n",
        "            \"conversion_%\": \"\",\n",
        "            \"notes\": \"\",\n",
        "        })\n",
        "    df_screen = pd.DataFrame(rows, columns=cols)\n",
        "\n",
        "    if top_seq_by_step is not None and not top_seq_by_step.empty:\n",
        "        before_na = df_screen[\"sequence_accession\"].isna().sum() + (df_screen[\"sequence_accession\"] == \"\").sum()\n",
        "        df_screen = df_screen.merge(top_seq_by_step, on=\"step_idx\", how=\"left\", suffixes=(\"\",\"_best\"))\n",
        "        for col in [\"sequence_accession\",\"source_organism\",\"uniprot_url\"]:\n",
        "            best_col = f\"{col}_best\"\n",
        "            if best_col in df_screen.columns:\n",
        "                df_screen[col] = df_screen[best_col].where(df_screen[best_col].notna() & (df_screen[best_col]!=\"\"), df_screen[col])\n",
        "                df_screen.drop(columns=[best_col], inplace=True)\n",
        "        after_na = df_screen[\"sequence_accession\"].isna().sum() + (df_screen[\"sequence_accession\"] == \"\").sum()\n",
        "        merged_n = max(0, before_na - after_na)\n",
        "\n",
        "    screen_csv = str(finish_out / \"enzyme_screening_sheet.csv\")\n",
        "    df_screen.to_csv(screen_csv, index=False)\n",
        "\n",
        "    md_path = str(finish_out / \"pathway_brief.md\")\n",
        "    lines = []\n",
        "    lines.append(f\"# Pathway {best_tag} — Enzyme Screening Summary\\n\")\n",
        "    lines.append(f\"**Total Steps:** {len(psteps)}\\n\")\n",
        "    lines.append(f\"**Ranking File:** `{Path(rank_csv).name}`\\n\")\n",
        "\n",
        "    def bullet(txt): return f\"- {txt}\"\n",
        "\n",
        "    for _, r in psteps.iterrows():\n",
        "        lines.append(f\"\\n## Step {int(r['step_idx'])}: {r.get('retrobiocat_reaction','')}\\n\")\n",
        "        lines.append(bullet(f\"Reaction SMILES: `{r.get('reaction_smiles','')}`\"))\n",
        "        lines.append(bullet(f\"Selected enzyme: {r.get('selected_enzyme','-')}\"))\n",
        "        lines.append(bullet(f\"Possible enzymes: {r.get('possible_enzymes','-')}\"))\n",
        "        if \"precedent_best_similarity\" in psteps.columns and pd.notna(r.get(\"precedent_best_similarity\")):\n",
        "            lines.append(bullet(f\"Precedent similarity: {r.get('precedent_best_similarity')}\"))\n",
        "        if r.get(\"selenzyme_url\"):\n",
        "            lines.append(bullet(f\"[Selenzyme link]({r.get('selenzyme_url')})\"))\n",
        "        if merged_n and \"sequence_accession\" in df_screen.columns:\n",
        "            acc = df_screen.loc[df_screen[\"step_idx\"]==int(r[\"step_idx\"]),\"sequence_accession\"].values[0]\n",
        "            org = df_screen.loc[df_screen[\"step_idx\"]==int(r[\"step_idx\"]),\"source_organism\"].values[0]\n",
        "            up  = df_screen.loc[df_screen[\"step_idx\"]==int(r[\"step_idx\"]),\"uniprot_url\"].values[0]\n",
        "            if acc:\n",
        "                lines.append(bullet(f\"Top sequence: [{acc}]({up}) ({org})\"))\n",
        "        else:\n",
        "            if r.get(\"selected_enzyme\"):\n",
        "                q = quote_plus(r.get(\"selected_enzyme\"))\n",
        "                lines.append(bullet(f\"[UniProt search](https://www.uniprot.org/uniprotkb?query={q})\"))\n",
        "\n",
        "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(lines))\n",
        "\n",
        "    new_state = {\n",
        "        **state,\n",
        "        \"screening_sheet_csv\": screen_csv,\n",
        "        \"pathway_brief_md\": md_path,\n",
        "        \"doe_pathway_tag\": best_tag,\n",
        "        \"doe_steps\": len(psteps),\n",
        "        \"doe_sequences_merged\": int(merged_n),\n",
        "    }\n",
        "    new_state[\"logs\"] = state.get(\"logs\", []) + [\n",
        "        f\"DoE sheet + brief ready for {best_tag}\",\n",
        "        f\"screening={screen_csv}\",\n",
        "        f\"brief={md_path}\",\n",
        "        f\"sequences merged into DoE: {merged_n}\",\n",
        "    ]\n",
        "    return new_state\n",
        "\n",
        "\n",
        "def human_gate_node(state: DBTLState) -> DBTLState:\n",
        "    \"\"\"\n",
        "    Pause-and-review checkpoint node. Writes a small summary file and\n",
        "    checks for an external 'signals.human_approved' flag.\n",
        "    \"\"\"\n",
        "    workdir = Path(state[\"workdir\"])\n",
        "    finish_out = workdir / \"retro_finish_out\"\n",
        "    finish_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    summary = {\n",
        "        \"top_pathway\": state.get(\"doe_pathway_tag\"),\n",
        "        \"steps\": state.get(\"doe_steps\"),\n",
        "        \"thermo_method\": state.get(\"thermo_method\"),\n",
        "        \"sequence_rank_counts\": state.get(\"sequence_rank_counts\", {}),\n",
        "        \"screening_sheet\": state.get(\"screening_sheet_csv\"),\n",
        "        \"brief\": state.get(\"pathway_brief_md\"),\n",
        "    }\n",
        "\n",
        "    gate_path = finish_out / \"_HUMAN_GATE.md\"\n",
        "    with open(gate_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"# Human Approval Gate\\n\\n\")\n",
        "        f.write(\"Please review the current design-build-test-learn outputs:\\n\\n\")\n",
        "        for k, v in summary.items():\n",
        "            f.write(f\"- **{k}**: {v}\\n\")\n",
        "        f.write(\"\\nMark `approved=True` in the next LangGraph signal to continue.\\n\")\n",
        "\n",
        "    signals = state.get(\"signals\", {})\n",
        "    approved = bool(signals.get(\"human_approved\")) or state.get(\"approved\", False)\n",
        "\n",
        "    new_state = {\n",
        "        **state,\n",
        "        \"approved\": approved,\n",
        "        \"human_gate_md\": str(gate_path),\n",
        "    }\n",
        "    new_state[\"logs\"] = state.get(\"logs\", []) + [\n",
        "        f\"human_gate: approval file ready at {gate_path}\",\n",
        "        f\"human_gate: approved={approved}\",\n",
        "    ]\n",
        "    return new_state\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def export_node(state: DBTLState) -> DBTLState:\n",
        "    \"\"\"\n",
        "    Export all key DBTL artifacts and write a manifest.json.\n",
        "    \"\"\"\n",
        "    workdir = Path(state[\"workdir\"])\n",
        "    finish_out = workdir / \"retro_finish_out\"\n",
        "    export_dir = workdir / \"retro_export\"\n",
        "    export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    artifacts = []\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, str) and any(v.endswith(ext) for ext in [\".csv\",\".md\",\".json\",\".xlsx\"]):\n",
        "            if os.path.exists(v):\n",
        "                dst = export_dir / Path(v).name\n",
        "                try:\n",
        "                    shutil.copy2(v, dst)\n",
        "                    artifacts.append(str(dst))\n",
        "                except Exception as e:\n",
        "                    state.setdefault(\"logs\", []).append(f\"export_node: failed to copy {v}: {e}\")\n",
        "\n",
        "    manifest = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"export_dir\": str(export_dir),\n",
        "        \"artifacts\": artifacts,\n",
        "        \"meta\": {\n",
        "            \"pathway_tag\": state.get(\"doe_pathway_tag\"),\n",
        "            \"approved\": state.get(\"approved\"),\n",
        "            \"thermo_method\": state.get(\"thermo_method\"),\n",
        "        },\n",
        "    }\n",
        "    manifest_path = export_dir / \"manifest.json\"\n",
        "    with open(manifest_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(manifest, f, indent=2)\n",
        "\n",
        "    new_state = {\n",
        "        **state,\n",
        "        \"export_manifest\": str(manifest_path),\n",
        "        \"export_dir\": str(export_dir),\n",
        "    }\n",
        "    new_state[\"logs\"] = state.get(\"logs\", []) + [\n",
        "        f\"export_node: exported {len(artifacts)} artifacts\",\n",
        "        f\"export_node: manifest={manifest_path}\",\n",
        "    ]\n",
        "    return new_state\n",
        "\n",
        "\n",
        "def simulate_node(state: \"DBTLState\") -> \"DBTLState\":\n",
        "    \"\"\"\n",
        "    Simulate pathway feasibility (toy COBRApy flux demo + mass-balance check).\n",
        "    Writes:\n",
        "      - retro_finish_out/simulation_fluxes.csv\n",
        "      - retro_finish_out/simulation_log.txt\n",
        "    Falls back gracefully if COBRApy is unavailable.\n",
        "    \"\"\"\n",
        "    import os, subprocess, textwrap, json, shutil, time\n",
        "    from pathlib import Path\n",
        "    from string import Template\n",
        "\n",
        "    def _log(s, msg):\n",
        "        s = {**s}\n",
        "        s[\"logs\"] = [*s.get(\"logs\", []), msg]\n",
        "        return s\n",
        "\n",
        "    workdir = Path(state[\"workdir\"]).expanduser().resolve()\n",
        "    retro_out = workdir / \"retro_out\"\n",
        "    finish_out = workdir / \"retro_finish_out\"\n",
        "    finish_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Inputs\n",
        "    rank_csv  = state.get(\"ranked_final_csv\") or state.get(\"ranked_csv\")\n",
        "    steps_csv = state.get(\"steps_annotated_csv\") or state.get(\"steps_plan_csv\")\n",
        "    if not rank_csv or not Path(rank_csv).exists():\n",
        "        return _log(state, \"simulate: no ranking CSV; skipped\")\n",
        "    if not steps_csv or not Path(steps_csv).exists():\n",
        "        return _log(state, \"simulate: no steps CSV; skipped\")\n",
        "\n",
        "    # Outputs\n",
        "    out_flux = finish_out / \"simulation_fluxes.csv\"\n",
        "    log_path = finish_out / \"simulation_log.txt\"\n",
        "\n",
        "    # Use the same micromamba env as RBC2\n",
        "    mm_root    = workdir / \"micromamba\"\n",
        "    env_prefix = mm_root / \"envs\" / \"retrobiocat\"\n",
        "    micromamba = workdir / \"bin\" / \"micromamba\"\n",
        "    if not micromamba.exists():\n",
        "        micromamba = \"micromamba\"\n",
        "\n",
        "    env = os.environ.copy()\n",
        "    env[\"MAMBA_ROOT_PREFIX\"] = str(mm_root)\n",
        "\n",
        "    # Ensure cobra is present (best-effort)\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            f\"\"\"{micromamba} run -p \"{env_prefix}\" python -c \"import cobra\" \"\"\",\n",
        "            shell=True, env=env, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n",
        "        )\n",
        "        cobra_ok = True\n",
        "    except subprocess.CalledProcessError:\n",
        "        cobra_ok = False\n",
        "        try:\n",
        "            subprocess.run(\n",
        "                f\"\"\"{micromamba} run -p \"{env_prefix}\" python -m pip install cobra\"\"\",\n",
        "                shell=True, env=env, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n",
        "            )\n",
        "            cobra_ok = True\n",
        "        except subprocess.CalledProcessError:\n",
        "            cobra_ok = False\n",
        "\n",
        "    # ---- Embedded script (Template with $placeholders to avoid {} issues) ----\n",
        "    tpl = Template(r\"\"\"\n",
        "import pandas as pd, math, csv, sys\n",
        "from pathlib import Path\n",
        "\n",
        "RANK_CSV = Path(\"$rank_csv\")\n",
        "STEPS_CSV = Path(\"$steps_csv\")\n",
        "OUT_FLUX = Path(\"$out_flux\")\n",
        "LOG_PATH = Path(\"$log_path\")\n",
        "\n",
        "log_lines = []\n",
        "\n",
        "def log(x):\n",
        "    log_lines.append(str(x))\n",
        "\n",
        "ranked = pd.read_csv(RANK_CSV)\n",
        "steps  = pd.read_csv(STEPS_CSV)\n",
        "best_tag = str(ranked.iloc[0][\"pathway_tag\"])\n",
        "\n",
        "psteps = (steps[steps[\"pathway_tag\"] == best_tag]\n",
        "          .sort_values(\"step_idx\")\n",
        "          .reset_index(drop=True))\n",
        "\n",
        "# Basic mass-balance parse: count participants LHS/RHS for sanity\n",
        "def split_rxn(r):\n",
        "    if not isinstance(r, str) or \">>\" not in r: return [], []\n",
        "    L,R = r.split(\">>\",1)\n",
        "    subs=[s for s in L.split(\".\") if s]; prods=[p for p in R.split(\".\") if p]\n",
        "    return subs, prods\n",
        "\n",
        "imbalances = []\n",
        "for _, row in psteps.iterrows():\n",
        "    subs, prods = split_rxn(str(row.get(\"reaction_smiles\",\"\")))\n",
        "    imbalances.append(abs(len(subs) - len(prods)))\n",
        "mass_ok = (sum(imbalances) == 0)\n",
        "log(f\"mass_balance_ok={mass_ok} (total_imbalance={sum(imbalances)})\")\n",
        "\n",
        "# If COBRApy is available, create a toy model and assign unit flux per step\n",
        "try:\n",
        "    import cobra\n",
        "    model = cobra.Model(\"toy_pathway\")\n",
        "    # Make exchange for overall substrate mix and product pool\n",
        "    exch_in  = cobra.Reaction(\"EX_subs\")\n",
        "    exch_out = cobra.Reaction(\"EX_prod\")\n",
        "    model.add_reactions([exch_in, exch_out])\n",
        "    exch_in.lower_bound  = -1000.0; exch_in.upper_bound  = 0.0\n",
        "    exch_out.lower_bound = 0.0;     exch_out.upper_bound = 1000.0\n",
        "\n",
        "    # create a metabolite per unique token just to wire reactions\n",
        "    tokens = set()\n",
        "    for rxn in psteps[\"reaction_smiles\"].astype(str):\n",
        "        L,R = split_rxn(rxn)\n",
        "        tokens.update(L); tokens.update(R)\n",
        "    # Minimal placeholders; we don't use stoichiometries beyond 1\n",
        "    mets = {}\n",
        "    for t in tokens:\n",
        "        m_id = (\"m_\" + \"\".join([c if c.isalnum() else \"_\" for c in t]))[:60]\n",
        "        mets[t] = cobra.Metabolite(id=m_id, name=t, compartment=\"c\")\n",
        "\n",
        "    # Add step reactions (each consumes its LHS tokens and produces RHS tokens)\n",
        "    step_flux = []\n",
        "    for _, row in psteps.iterrows():\n",
        "        sid = f\"R_step_{int(row['step_idx'])}\"\n",
        "        rxn = cobra.Reaction(sid)\n",
        "        L,R = split_rxn(str(row.get(\"reaction_smiles\",\"\")))\n",
        "        rxn.lower_bound = 0.0; rxn.upper_bound = 1000.0\n",
        "        rxn.add_metabolites({ mets[s]: -1.0 for s in L if s in mets })\n",
        "        rxn.add_metabolites({ mets[p]:  1.0 for p in R if p in mets })\n",
        "        model.add_reactions([rxn])\n",
        "        step_flux.append((sid, 1.0))  # target steady-state flux guess\n",
        "\n",
        "    # Objective: push flux through the last step\n",
        "    if step_flux:\n",
        "        last_sid = step_flux[-1][0]\n",
        "        model.objective = last_sid\n",
        "\n",
        "    sol = model.optimize()\n",
        "    fluxes = []\n",
        "    if sol.status == \"optimal\":\n",
        "        for sid, _ in step_flux:\n",
        "            fluxes.append({\"pathway_tag\": best_tag,\n",
        "                           \"step_id\": sid,\n",
        "                           \"flux\": float(sol.fluxes.get(sid, 0.0))})\n",
        "        flux_ok = True\n",
        "    else:\n",
        "        flux_ok = False\n",
        "        for sid, _ in step_flux:\n",
        "            fluxes.append({\"pathway_tag\": best_tag, \"step_id\": sid, \"flux\": float(\"nan\")})\n",
        "\n",
        "    pd.DataFrame(fluxes).to_csv(OUT_FLUX, index=False)\n",
        "    log(f\"cobra_status={sol.status}, flux_ok={flux_ok}, rows={len(fluxes)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    # COBRA missing or failed — emit a stub CSV with zeros\n",
        "    fluxes = []\n",
        "    for _, row in psteps.iterrows():\n",
        "        fluxes.append({\"pathway_tag\": best_tag,\n",
        "                       \"step_id\": f\"R_step_{int(row['step_idx'])}\",\n",
        "                       \"flux\": 0.0})\n",
        "    pd.DataFrame(fluxes).to_csv(OUT_FLUX, index=False)\n",
        "    log(f\"cobra_unavailable_or_failed: {e}; wrote zero-flux stub\")\n",
        "\n",
        "with open(LOG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(log_lines))\n",
        "print(\"simulate: wrote\", OUT_FLUX, \"and\", LOG_PATH)\n",
        "\"\"\")\n",
        "\n",
        "    py = textwrap.dedent(tpl.substitute(\n",
        "        rank_csv=str(rank_csv),\n",
        "        steps_csv=str(steps_csv),\n",
        "        out_flux=str(out_flux),\n",
        "        log_path=str(log_path),\n",
        "    ))\n",
        "\n",
        "    # run inside env\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            f\"\"\"{micromamba} run -p \"{env_prefix}\" python - <<'PY'\\n{py}\\nPY\"\"\",\n",
        "            shell=True, env=env, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT\n",
        "        )\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # if even that fails, record and continue\n",
        "        with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"\\nsubprocess failed:\\n\" + (e.stdout or \"\"))\n",
        "\n",
        "    new_state = {\n",
        "        **state,\n",
        "        \"simulation_flux_csv\": str(out_flux) if out_flux.exists() else None,\n",
        "        \"simulation_log\": str(log_path) if log_path.exists() else None,\n",
        "    }\n",
        "    new_state[\"logs\"] = [*state.get(\"logs\", []), f\"simulate: fluxes={out_flux.exists()}, log={log_path.exists()}\"]\n",
        "    return new_state\n",
        "\n",
        "import time, math, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# --- helpers ---------------------------------------------------------------\n",
        "\n",
        "import os, json, time, math, subprocess, datetime\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "def _log(state, msg):\n",
        "    print(msg)\n",
        "    state.setdefault(\"logs\", []).append(msg)\n",
        "\n",
        "\n",
        "def ensure_equilibrator(env_prefix: Path):\n",
        "    \"\"\"\n",
        "    Make sure equilibrator (api + cache) is installed in the env with pins that\n",
        "    are compatible with your rbc2 pins (numpy==1.26.4, pandas>=2).\n",
        "    Safe to re-run; will no-op if already satisfied.\n",
        "    \"\"\"\n",
        "    pins = [\n",
        "        \"numpy==1.26.4\",\n",
        "        \"pandas==2.2.2\",\n",
        "        \"pint==0.22\",\n",
        "        \"equilibrator-api==0.6.0\",\n",
        "        \"equilibrator-cache==0.6.0\",\n",
        "    ]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pins)\n",
        "    if rc != 0:\n",
        "        _log(state, f\"thermo: pip install warning (continuing):\\n{err.strip()}\")\n",
        "\n",
        "def ensure_cobra(env_prefix, state=None):\n",
        "    \"\"\"Install a cobra stack compatible with numpy>=1.26 / pandas>=2.x.\"\"\"\n",
        "    rc, out, err = _run_in_env(\n",
        "        env_prefix,\n",
        "        [\"python\",\"-c\",\"import cobra; print('cobra_ok')\"]\n",
        "    )\n",
        "    if rc == 0 and \"cobra_ok\" in (out or \"\"):\n",
        "        return\n",
        "    rc, out, err = _run_in_env(\n",
        "        env_prefix,\n",
        "        [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\",\"cobra==0.29.0\",\"optlang>=1.8.0\",\"swiglpk>=5.0.10\"]\n",
        "    )\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"simulate_gem: cobra install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "# --- THERMO NODE (patched) ------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import json, pandas as pd, os\n",
        "\n",
        "# ---------- helpers used by thermo_node ----------\n",
        "\n",
        "# -------- helpers used by thermo_node (safe to paste multiple times) --------\n",
        "\n",
        "\n",
        "\n",
        "# ----------- PATCH: robust micromamba discovery + runner -------------\n",
        "\n",
        "def _find_micromamba(env_prefix):\n",
        "    \"\"\"\n",
        "    Return a usable micromamba executable path.\n",
        "    Search common locations relative to the env, else bootstrap it to workdir/bin.\n",
        "    \"\"\"\n",
        "    import os, stat, tarfile, urllib.request\n",
        "    from pathlib import Path\n",
        "\n",
        "    p = Path(env_prefix).resolve()\n",
        "    # env_prefix = <workdir>/micromamba/envs/retrobiocat\n",
        "    # workdir is two levels up from 'envs/retrobiocat'\n",
        "    try:\n",
        "        workdir = p.parents[2]\n",
        "    except Exception:\n",
        "        workdir = Path(\"/content/runs/run_001\")\n",
        "\n",
        "    candidates = [\n",
        "        workdir / \"bin\" / \"micromamba\",                 # /content/runs/run_001/bin/micromamba\n",
        "        workdir / \"micromamba\" / \"bin\" / \"micromamba\",  # /content/runs/run_001/micromamba/bin/micromamba\n",
        "        Path(\"micromamba\"),                             # from PATH, if any\n",
        "    ]\n",
        "    for c in candidates:\n",
        "        if str(c) == \"micromamba\":\n",
        "            # If a PATH micromamba exists, just return the string; Popen will resolve it\n",
        "            return \"micromamba\"\n",
        "        if c.exists():\n",
        "            try:\n",
        "                mode = c.stat().st_mode\n",
        "                if not (mode & stat.S_IXUSR):\n",
        "                    c.chmod(mode | stat.S_IXUSR)\n",
        "            except Exception:\n",
        "                pass\n",
        "            return str(c)\n",
        "\n",
        "    # --- Bootstrap: download and extract micromamba into <workdir>/bin ---\n",
        "    workdir.mkdir(parents=True, exist_ok=True)\n",
        "    (workdir / \"bin\").mkdir(parents=True, exist_ok=True)\n",
        "    url = \"https://micro.mamba.pm/api/micromamba/linux-64/latest\"\n",
        "    tar_path = workdir / \"mm.tar.bz2\"\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url, tar_path.as_posix())\n",
        "        with tarfile.open(tar_path.as_posix(), mode=\"r:bz2\") as tf:\n",
        "            # Extract only 'bin/micromamba' if present; else extract all and hope path matches\n",
        "            members = [m for m in tf.getmembers() if m.name.endswith(\"/micromamba\") or m.name == \"micromamba\" or m.name.endswith(\"bin/micromamba\")]\n",
        "            if members:\n",
        "                for m in members:\n",
        "                    tf.extract(m, path=workdir)\n",
        "            else:\n",
        "                tf.extractall(path=workdir)\n",
        "        # Move to workdir/bin if needed\n",
        "        possible = [\n",
        "            workdir / \"bin\" / \"micromamba\",\n",
        "            workdir / \"micromamba\" / \"bin\" / \"micromamba\",\n",
        "            workdir / \"micromamba.exe\",  # just in case\n",
        "        ]\n",
        "        for c in possible:\n",
        "            if c.exists():\n",
        "                final = workdir / \"bin\" / \"micromamba\"\n",
        "                if c != final:\n",
        "                    try:\n",
        "                        final.write_bytes(c.read_bytes())\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                try:\n",
        "                    final.chmod(final.stat().st_mode | stat.S_IXUSR)\n",
        "                except Exception:\n",
        "                    pass\n",
        "                return str(final)\n",
        "    except Exception:\n",
        "        # last resort: let shell resolve it if available\n",
        "        return \"micromamba\"\n",
        "\n",
        "    return \"micromamba\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#########Thermo_node######################################################################\n",
        "\n",
        "# ---------- helpers used by thermo_node (safe to paste more than once) ----------\n",
        "\n",
        "\n",
        "def _ensure_equilibrator(env_prefix, state=None):\n",
        "    \"\"\"Idempotent install of equilibrator stack + compatible numpy/pandas/pint.\"\"\"\n",
        "    pins = [\n",
        "        \"numpy==1.26.4\",\n",
        "        \"pandas==2.2.2\",\n",
        "        \"pint==0.22\",\n",
        "        \"equilibrator-api==0.6.0\",\n",
        "        \"equilibrator-cache==0.6.0\",\n",
        "    ]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pins)\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: pip install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "def _ensure_rdkit(env_prefix, state=None):\n",
        "    \"\"\"\n",
        "    Best-effort RDKit so we can turn SMILES → InChIKey and improve matching.\n",
        "    Tries the light wheel (rdkit-pypi). If it fails, we continue without RDKit.\n",
        "    \"\"\"\n",
        "    # Check first\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-c\",\"import rdkit; print('ok')\"])\n",
        "    if rc == 0 and \"ok\" in (out or \"\"):\n",
        "        return\n",
        "    # Try install (quiet)\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"rdkit-pypi==2022.9.5\"])\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: RDKit install skipped (will continue without)\")\n",
        "\n",
        "\n",
        "# ------------------------------- thermo_node --------------------------------\n",
        "# -------- helpers used by thermo_node (safe to paste multiple times) --------\n",
        "\n",
        "\n",
        "def _ensure_equilibrator(env_prefix, state=None):\n",
        "    \"\"\"Best-effort, idempotent install of equilibrator stack with safe pins.\"\"\"\n",
        "    pins = [\n",
        "        \"numpy==1.26.4\",\n",
        "        \"pandas==2.2.2\",\n",
        "        \"pint==0.22\",\n",
        "        \"equilibrator-api==0.6.0\",\n",
        "        \"equilibrator-cache==0.6.0\",\n",
        "    ]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pins)\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: pip install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "def _ensure_rdkit(env_prefix, state=None):\n",
        "    \"\"\"\n",
        "    Install RDKit into the same micromamba env (used to convert SMILES→InChIKey).\n",
        "    Using conda-forge build for compatibility.\n",
        "    \"\"\"\n",
        "    rc, out, err = _run_in_env(\n",
        "        env_prefix,\n",
        "        [\"python\",\"-c\",\"import rdkit; print('rdkit_ok')\"]\n",
        "    )\n",
        "    if rc == 0 and \"rdkit_ok\" in (out or \"\"):\n",
        "        return\n",
        "    # Install via mamba/conda (micromamba run is fine)\n",
        "    rc, out, err = _run_in_env(\n",
        "        env_prefix,\n",
        "        [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"rdkit-pypi\"]\n",
        "    )\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: RDKit install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "# ------------------------------- thermo_node --------------------------------\n",
        "\n",
        "# ---------- helpers used by thermo_node (safe to paste multiple times) ----------\n",
        "\n",
        "\n",
        "def _ensure_equilibrator(env_prefix, state=None):\n",
        "    \"\"\"Best-effort, idempotent install of equilibrator stack with safe pins.\"\"\"\n",
        "    pins = [\n",
        "        \"numpy==1.26.4\",\n",
        "        \"pandas==2.2.2\",\n",
        "        \"pint==0.22\",\n",
        "        \"equilibrator-api==0.6.0\",\n",
        "        \"equilibrator-cache==0.6.0\",\n",
        "    ]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pins)\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: pip install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "def _ensure_rdkit(env_prefix, state=None):\n",
        "    \"\"\"Install RDKit (used for SMILES→InChIKey) into the same env.\"\"\"\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-c\",\"import rdkit; print('rdkit_ok')\"])\n",
        "    if rc == 0 and \"rdkit_ok\" in (out or \"\"):\n",
        "        return\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"rdkit-pypi\"])\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: RDKit install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "# -------------------------------- thermo_node ----------------------------------\n",
        "# ----------------------------- shared helpers ------------------------------\n",
        "\n",
        "\n",
        "def _ensure_equilibrator(env_prefix, state=None):\n",
        "    \"\"\"Best-effort, idempotent install of equilibrator stack with safe pins.\"\"\"\n",
        "    pins = [\n",
        "        \"numpy==1.26.4\",\n",
        "        \"pandas==2.2.2\",\n",
        "        \"pint==0.22\",\n",
        "        \"equilibrator-api==0.6.0\",\n",
        "        \"equilibrator-cache==0.6.0\",\n",
        "    ]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pins)\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: pip install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "def _ensure_rdkit(env_prefix, state=None):\n",
        "    \"\"\"\n",
        "    Install RDKit into the same micromamba env (used to convert SMILES→InChIKey).\n",
        "    We use the PyPI wheel for portability.\n",
        "    \"\"\"\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-c\",\"import rdkit; print('rdkit_ok')\"])\n",
        "    if rc == 0 and \"rdkit_ok\" in (out or \"\"):\n",
        "        return\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"rdkit-pypi\"])\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: RDKit install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "def _ensure_cobra(env_prefix, state=None):\n",
        "    \"\"\"\n",
        "    Install a cobra stack compatible with numpy>=1.26 / pandas>=2.0.\n",
        "    \"\"\"\n",
        "    rc, out, err = _run_in_env(\n",
        "        env_prefix,\n",
        "        [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\",\"cobra==0.29.0\",\"optlang>=1.8.0\",\"swiglpk>=5.0.10\"]\n",
        "    )\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"simulate_gem: cobra install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "# ------------------------------- thermo_node --------------------------------\n",
        "\n",
        "# ---------------- helpers used by thermo/sim nodes (safe to redefine) ----------------\n",
        "\n",
        "# -------- robust micromamba resolver + runner --------\n",
        "# ---------- robust micromamba resolver + runner (drop-in patch) ----------\n",
        "\n",
        "def _resolve_micromamba(env_prefix):\n",
        "    \"\"\"\n",
        "    Find a usable micromamba binary.\n",
        "    Tries the 'expected' location plus common fallbacks and $MICROMAMBA_EXE.\n",
        "    If it finds a fallback, it mirrors it into the expected path for future calls.\n",
        "    \"\"\"\n",
        "    import os, shutil\n",
        "    from pathlib import Path\n",
        "\n",
        "    expected = Path(env_prefix).parent.parent / \"bin\" / \"micromamba\"\n",
        "    fallbacks = [\n",
        "        expected,\n",
        "        Path(\"/content/runs/run_001/bin/micromamba\"),\n",
        "        Path(\"/content/bin/micromamba\"),\n",
        "        Path(os.environ.get(\"MICROMAMBA_EXE\", \"\")).expanduser(),\n",
        "    ]\n",
        "\n",
        "    for p in fallbacks:\n",
        "        if p and str(p) != \"\" and Path(p).exists():\n",
        "            # Mirror into the expected path if needed\n",
        "            if p != expected and not expected.exists():\n",
        "                try:\n",
        "                    expected.parent.mkdir(parents=True, exist_ok=True)\n",
        "                    try:\n",
        "                        expected.symlink_to(p)\n",
        "                    except Exception:\n",
        "                        shutil.copy2(p, expected)\n",
        "                        expected.chmod(expected.stat().st_mode | 0o111)\n",
        "                except Exception:\n",
        "                    # best-effort; still return the working fallback path\n",
        "                    pass\n",
        "            return str(p)\n",
        "\n",
        "    # If we got here, nothing was found\n",
        "    raise FileNotFoundError(\n",
        "        \"micromamba not found. Checked:\\n\"\n",
        "        f\" - {expected}\\n\"\n",
        "        \" - /content/runs/run_001/bin/micromamba\\n\"\n",
        "        \" - /content/bin/micromamba\\n\"\n",
        "        \" - $MICROMAMBA_EXE\"\n",
        "    )\n",
        "\n",
        "\n",
        "def _run_in_env(env_prefix, argv, input_text=None, extra_env=None):\n",
        "    \"\"\"\n",
        "    Run argv inside the micromamba env at env_prefix. Return (rc, stdout, stderr).\n",
        "    Uses the robust micromamba resolver above.\n",
        "    \"\"\"\n",
        "    import os, subprocess\n",
        "    mm = _resolve_micromamba(env_prefix)\n",
        "    cmd = [mm, \"run\", \"-p\", str(env_prefix)] + list(argv)\n",
        "\n",
        "    env = os.environ.copy()\n",
        "    if extra_env:\n",
        "        env.update(extra_env)\n",
        "\n",
        "    p = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdin=subprocess.PIPE if input_text is not None else None,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True,\n",
        "        env=env,\n",
        "    )\n",
        "    out, err = p.communicate(input=input_text)\n",
        "    return p.returncode, out, err\n",
        "\n",
        "\n",
        "def _ensure_equilibrator(env_prefix, state=None):\n",
        "    \"\"\"Best-effort, idempotent install of equilibrator stack with safe pins.\"\"\"\n",
        "    pins = [\n",
        "        \"numpy==1.26.4\",\n",
        "        \"pandas==2.2.2\",\n",
        "        \"pint==0.22\",\n",
        "        \"equilibrator-api==0.6.0\",\n",
        "        \"equilibrator-cache==0.6.0\",\n",
        "    ]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pins)\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: pip install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "def _ensure_rdkit(env_prefix, state=None):\n",
        "    \"\"\"Install RDKit (pip wheel) into the same env; used for SMILES normalization.\"\"\"\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-c\",\"import rdkit; print('rdkit_ok')\"])\n",
        "    if rc == 0 and \"rdkit_ok\" in (out or \"\"):\n",
        "        return\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"rdkit-pypi\"])\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: RDKit install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "def _ensure_cobra(env_prefix, state=None):\n",
        "    \"\"\"Make sure cobra & friends are present in env (modern, pandas>=2 compatible).\"\"\"\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-c\",\"import cobra; print('cobra_ok')\"])\n",
        "    if rc == 0 and \"cobra_ok\" in (out or \"\"):\n",
        "        return\n",
        "    pkgs = [\"cobra==0.29.0\", \"optlang>=1.8.0\", \"swiglpk>=5.0.10\"]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pkgs)\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"simulate: cobra install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "# --------------------------------- THERMO NODE ---------------------------------\n",
        "\n",
        "# -------- helpers used by thermo_node (safe to paste multiple times) --------\n",
        "\n",
        "\n",
        "\n",
        "def _ensure_equilibrator(env_prefix, state=None):\n",
        "    \"\"\"Best-effort, idempotent install of equilibrator stack with safe pins.\"\"\"\n",
        "    pins = [\n",
        "        \"numpy==1.26.4\",\n",
        "        \"pandas==2.2.2\",\n",
        "        \"pint==0.22\",\n",
        "        \"equilibrator-api==0.6.0\",\n",
        "        \"equilibrator-cache==0.6.0\",\n",
        "    ]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pins)\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: pip install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "def _ensure_rdkit(env_prefix, state=None):\n",
        "    \"\"\"\n",
        "    Install RDKit into the same micromamba env (used to convert SMILES→InChIKey).\n",
        "    Uses rdkit-pypi (wheel). If that fails we continue gracefully.\n",
        "    \"\"\"\n",
        "    rc, out, err = _run_in_env(\n",
        "        env_prefix,\n",
        "        [\"python\",\"-c\",\"import rdkit; print('rdkit_ok')\"]\n",
        "    )\n",
        "    if rc == 0 and (out or \"\").strip().endswith(\"rdkit_ok\"):\n",
        "        return\n",
        "    rc, out, err = _run_in_env(\n",
        "        env_prefix,\n",
        "        [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"rdkit-pypi\"]\n",
        "    )\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: RDKit install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "# ------------------------------- thermo_node --------------------------------\n",
        "\n",
        "# ---------- helpers used by thermo_node (safe to paste multiple times) ----------\n",
        "\n",
        "def _run_in_env(env_prefix, argv, input_text=None, extra_env=None):\n",
        "    \"\"\"\n",
        "    Run a command inside the micromamba env at env_prefix.\n",
        "    Returns (rc, stdout, stderr).\n",
        "    \"\"\"\n",
        "    import os, subprocess\n",
        "    from pathlib import Path\n",
        "    mm = Path(env_prefix).parent.parent / \"bin\" / \"micromamba\"\n",
        "    cmd = [str(mm), \"run\", \"-p\", str(env_prefix)] + list(argv)\n",
        "    env = os.environ.copy()\n",
        "    if extra_env:\n",
        "        env.update(extra_env)\n",
        "    p = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdin=subprocess.PIPE if input_text is not None else None,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True,\n",
        "        env=env,\n",
        "    )\n",
        "    out, err = p.communicate(input=input_text)\n",
        "    return p.returncode, out, err\n",
        "\n",
        "\n",
        "def _ensure_equilibrator(env_prefix, state=None):\n",
        "    \"\"\"Best-effort, idempotent install of equilibrator stack with safe pins.\"\"\"\n",
        "    pins = [\n",
        "        \"numpy==1.26.4\",\n",
        "        \"pandas==2.2.2\",\n",
        "        \"pint==0.22\",\n",
        "        \"equilibrator-api==0.6.0\",\n",
        "        \"equilibrator-cache==0.6.0\",\n",
        "    ]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pins)\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: pip install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "def _ensure_rdkit(env_prefix, state=None):\n",
        "    \"\"\"\n",
        "    Install RDKit into the same micromamba env (used to convert SMILES→InChIKey).\n",
        "    \"\"\"\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-c\",\"import rdkit; print('rdkit_ok')\"])\n",
        "    if rc == 0 and \"rdkit_ok\" in (out or \"\"):\n",
        "        return\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"rdkit-pypi\"])\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: RDKit install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "# -------------------------------- thermo_node (patched) --------------------------------\n",
        "\n",
        "# ---- helper to ensure RDKit in the *notebook* interpreter (not micromamba) ----\n",
        "def _ensure_rdkit_outer():\n",
        "    \"\"\"Ensure rdkit is importable in the current Python (outside micromamba).\"\"\"\n",
        "    try:\n",
        "        import rdkit  # noqa: F401\n",
        "        return\n",
        "    except Exception:\n",
        "        import sys, subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rdkit-pypi\"])\n",
        "        import rdkit  # noqa: F401\n",
        "\n",
        "\n",
        "# -------------------------------- thermo_node ---------------------------------\n",
        "\n",
        "# === Minimal helpers so thermo_node + simulate_gem_node work ===\n",
        "from pathlib import Path\n",
        "import subprocess, os, math, time, pandas as pd\n",
        "\n",
        "def _find_micromamba(workdir):\n",
        "    for c in [\n",
        "        Path(workdir) / \"bin\" / \"micromamba\",\n",
        "        Path(workdir) / \"micromamba\" / \"bin\" / \"micromamba\",\n",
        "        Path(\"/content/runs/run_001/bin/micromamba\"),\n",
        "        Path(\"/content/runs/run_001/micromamba/bin/micromamba\"),\n",
        "    ]:\n",
        "        if c.exists():\n",
        "            return c\n",
        "    return \"micromamba\"\n",
        "\n",
        "\n",
        "def _ensure_pkg(env_prefix, *specs):\n",
        "    \"\"\"Idempotent pip install for one or more package specs inside env_prefix.\"\"\"\n",
        "    return _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\",*specs])\n",
        "\n",
        "\n",
        "def _ensure_equilibrator_and_rdkit(env_prefix, state=None):\n",
        "    \"\"\"\n",
        "    Make sure the env has a compatible equilibrator stack + RDKit.\n",
        "    This is safe to call on every run (fast if already satisfied).\n",
        "    \"\"\"\n",
        "    pins_eq = [\n",
        "        \"pip\", \"setuptools\", \"wheel\",\n",
        "        \"numpy==1.26.4\", \"pandas==2.2.2\", \"pint==0.22\",\n",
        "        \"equilibrator-api==0.6.0\", \"equilibrator-cache==0.6.0\",\n",
        "    ]\n",
        "    rc1, out1, err1 = _ensure_pkg(env_prefix, *pins_eq)\n",
        "    if state is not None and rc1 != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: warning installing equilibrator stack (continuing)\")\n",
        "        if err1:\n",
        "            state[\"logs\"].append(err1.strip().splitlines()[-1])\n",
        "\n",
        "    # RDKit (wheel; no conda needed)\n",
        "    rc2, out2, err2 = _ensure_pkg(env_prefix, \"rdkit-pypi\")\n",
        "    if state is not None and rc2 != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"thermo: warning installing RDKit (continuing)\")\n",
        "        if err2:\n",
        "            state[\"logs\"].append(err2.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "\n",
        "def extract_node(state: dict) -> dict:\n",
        "    _log(state, \"▶ start extract\")\n",
        "    wd = Path(state[\"workdir\"])\n",
        "    retro = wd / \"retro_out\"\n",
        "    finish = wd / \"retro_finish_out\"\n",
        "    finish.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # sanity: if retrosynthesis failed, abort early with context\n",
        "    retro_flag = state.get(\"retro_status\")  # set by your retrosynthesis node if you added it\n",
        "    if retro_flag == \"failed\":\n",
        "        errlog = retro / \"_rbc2_runner.err.log\"\n",
        "        tail = _log_tail(errlog)\n",
        "        raise RuntimeError(\n",
        "            \"Retrosynthesis produced a stub (empty outputs). \"\n",
        "            \"See _rbc2_runner.err.log tail below:\\n\" + tail\n",
        "        )\n",
        "\n",
        "    # candidate inputs (newer writers first, then legacy)\n",
        "    candidates = [\n",
        "        retro / \"pathways_solved_steps.csv\",\n",
        "        retro / \"pathways_all_steps.csv\",\n",
        "        retro / \"steps.csv\",             # legacy\n",
        "        retro / \"pathways.csv\",          # legacy\n",
        "    ]\n",
        "\n",
        "    df = None\n",
        "    source = None\n",
        "    for p in candidates:\n",
        "        if _file_nonempty(p):\n",
        "            try:\n",
        "                df = pd.read_csv(p)\n",
        "                source = p.name\n",
        "                break\n",
        "            except pd.errors.EmptyDataError:\n",
        "                pass  # keep searching\n",
        "\n",
        "    # Fallback: construct from JSON if CSVs are empty but we have route JSONs\n",
        "    if df is None:\n",
        "        routes_json = retro / \"routes.json\"\n",
        "        if _file_nonempty(routes_json):\n",
        "            with open(routes_json, \"r\", encoding=\"utf-8\") as f:\n",
        "                routes = json.load(f)\n",
        "            rows = []\n",
        "            for tag, route in routes.items():\n",
        "                for i, step in enumerate(route.get(\"steps\", []), start=1):\n",
        "                    rows.append({\n",
        "                        \"pathway_tag\": tag,\n",
        "                        \"step_idx\": i,\n",
        "                        \"reaction_smiles\": step.get(\"reaction_smiles\", \"\"),\n",
        "                        \"substrates\": \" . \".join(step.get(\"substrates\", [])),\n",
        "                        \"products\": \" . \".join(step.get(\"products\", [])),\n",
        "                        \"rxn_type\": step.get(\"rxn_type\", \"\"),\n",
        "                        \"name\": step.get(\"name\", \"\"),\n",
        "                        \"rbc2_score\": step.get(\"score\", 0.0),\n",
        "                    })\n",
        "            if rows:\n",
        "                df = pd.DataFrame(rows)\n",
        "                source = \"routes.json\"\n",
        "            else:\n",
        "                df = None\n",
        "\n",
        "    if df is None or df.empty:\n",
        "        # Helpful diagnostics\n",
        "        diag = []\n",
        "        for p in candidates + [retro / \"routes.json\"]:\n",
        "            diag.append(f\"{p} : {'OK' if _file_nonempty(p) else 'missing/empty'}\")\n",
        "        err_tail = _log_tail(retro / \"_rbc2_runner.err.log\")\n",
        "        raise RuntimeError(\n",
        "            \"extract_node could not find usable retrosynthesis outputs.\\n\"\n",
        "            + \"\\n\".join(diag)\n",
        "            + (\"\\n\\n_rbc2_runner.err.log (tail):\\n\" + err_tail if err_tail else \"\")\n",
        "        )\n",
        "\n",
        "    # Normalize/ensure required columns\n",
        "    for col in [\"pathway_tag\",\"step_idx\",\"reaction_smiles\",\"substrates\",\"products\",\n",
        "                \"rbc2_score\",\"precedent_best_similarity\",\"selenzyme_url\"]:\n",
        "        if col not in df.columns:\n",
        "            df[col] = 0.0 if col in (\"rbc2_score\",\"precedent_best_similarity\") else \"\"\n",
        "\n",
        "    # Persist standard downstream files\n",
        "    steps_plan = finish / \"steps_enzyme_plan.csv\"\n",
        "    ranked_no_thermo = finish / \"pathways_ranked_no_thermo.csv\"\n",
        "\n",
        "    df.to_csv(steps_plan, index=False)\n",
        "\n",
        "    # very light ranking (same as your previous)\n",
        "    tmp = df.copy()\n",
        "    tmp[\"rbc2_score\"] = pd.to_numeric(tmp[\"rbc2_score\"], errors=\"coerce\").fillna(0.0)\n",
        "    tmp[\"precedent_best_similarity\"] = pd.to_numeric(tmp[\"precedent_best_similarity\"], errors=\"coerce\").fillna(0.0)\n",
        "    agg = tmp.groupby(\"pathway_tag\").agg(\n",
        "        steps_count=(\"step_idx\",\"max\"),\n",
        "        sum_rbc2=(\"rbc2_score\",\"sum\"),\n",
        "        sum_prec_sim=(\"precedent_best_similarity\",\"sum\"),\n",
        "    ).reset_index()\n",
        "    agg[\"rank_score\"] = agg[\"sum_rbc2\"] + 0.2*agg[\"sum_prec_sim\"] - 0.1*agg[\"steps_count\"]\n",
        "    ranked = agg.sort_values(\n",
        "        [\"rank_score\",\"sum_rbc2\",\"sum_prec_sim\",\"steps_count\"],\n",
        "        ascending=[False,False,False,True]\n",
        "    ).reset_index(drop=True)\n",
        "    ranked.to_csv(ranked_no_thermo, index=False)\n",
        "\n",
        "    _log(state, f\"extracted pathways from {source} \"\n",
        "                f\"({len(df)} step rows, {ranked.shape[0]} pathways)\")\n",
        "    state[\"extract_steps_csv\"] = str(steps_plan)\n",
        "    state[\"extract_rank_csv\"]  = str(ranked_no_thermo)\n",
        "    _log(state, \"✔ done extract\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def rank_node(state: dict) -> dict:\n",
        "    \"\"\"\n",
        "    #Lightweight shim so your call `state = rank_node(state)` won’t error.\n",
        "    #If thermo_node already wrote 'pathways_ranked_final.csv', we just log and return.\n",
        "    #Otherwise, we promote 'pathways_ranked_no_thermo.csv' to 'pathways_ranked_final.csv'.\n",
        "    \"\"\"\n",
        "    from pathlib import Path\n",
        "    import shutil\n",
        "\n",
        "    def log(msg): state.setdefault(\"logs\", []).append(msg)\n",
        "\n",
        "    run_id  = state.get(\"run_id\", \"run\")\n",
        "    workdir = Path(state.get(\"workdir\", f\"/content/runs/{run_id}\"))\n",
        "    finish_out = Path(state.get(\"retro_finish_out_dir\", workdir / \"retro_finish_out\"))\n",
        "    finish_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ranked_final = finish_out / \"pathways_ranked_final.csv\"\n",
        "    if ranked_final.exists():\n",
        "        log(\"▶ start rank\")\n",
        "        log(\"ranked pathways (already computed with thermo)\")\n",
        "        log(f\"ranked_final={ranked_final}\")\n",
        "        log(\"✔ done rank (0.0s)\")\n",
        "        return state\n",
        "\n",
        "    ranked_no = finish_out / \"pathways_ranked_no_thermo.csv\"\n",
        "    if ranked_no.exists():\n",
        "        shutil.copy2(ranked_no, ranked_final)\n",
        "        log(\"▶ start rank\")\n",
        "        log(\"ranked pathways (no thermo available; copied no_thermo as final)\")\n",
        "        log(f\"ranked_final={ranked_final}\")\n",
        "        log(\"✔ done rank (0.0s)\")\n",
        "    else:\n",
        "        log(\"▶ start rank\")\n",
        "        log(\"rank_node: no ranking inputs found\")\n",
        "        log(\"✔ done rank (0.0s)\")\n",
        "\n",
        "    return state\n",
        "\n",
        "# ---------- helpers used by simulate_gem_node (safe to paste multiple times) ----------\n",
        "\n",
        "\n",
        "def _ensure_cobra(env_prefix, state=None):\n",
        "    \"\"\"Install a cobra version compatible with numpy>=1.26 / pandas>=2.\"\"\"\n",
        "    pkgs = [\"cobra==0.29.0\", \"optlang>=1.8.0\", \"swiglpk>=5.0.10\"]\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"--upgrade\"] + pkgs)\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"simulate_gem: cobra install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "def _run_and_log(cmd, log_path, cwd=None, env=None):\n",
        "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, cwd=cwd, env=env, text=True)\n",
        "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for line in p.stdout:\n",
        "            f.write(line)\n",
        "    rc = p.wait()\n",
        "    return rc\n",
        "\n",
        "def _write_rbc2_driver(py_path: Path, target_smi: str, retro_out: Path):\n",
        "    code = f\"\"\"\n",
        "import json, pandas as pd\n",
        "from pathlib import Path\n",
        "from rbc2 import MCTS, get_expanders\n",
        "\n",
        "retro_out = Path({json.dumps(str(retro_out))})\n",
        "retro_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "target_smi = {json.dumps(target_smi)}\n",
        "expanders  = get_expanders([\"retrobiocat\"])  # or add others: [\"retrobiocat\",\"enzymemap\",\"bkmst\",\"retrorules\"]\n",
        "\n",
        "mcts = MCTS(target_smi, expanders)\n",
        "mcts.config.max_search_time = int(20)  # seconds; tune as you like\n",
        "mcts.run()\n",
        "\n",
        "all_paths    = mcts.get_all_pathways()\n",
        "solved_paths = mcts.get_solved_pathways()\n",
        "\n",
        "def pathway_rows(pwy, tag):\n",
        "    rows = []\n",
        "    for i, rxn in enumerate(pwy.reactions, start=1):\n",
        "        rows.append({{\n",
        "            \"pathway_tag\": tag,\n",
        "            \"step_idx\": i,\n",
        "            \"reaction_smiles\": rxn.reaction_smiles(),\n",
        "            \"substrates\": \" . \".join(rxn.substrates),\n",
        "            \"products\":  rxn.product,\n",
        "            \"rxn_type\": rxn.rxn_type,\n",
        "            \"name\": rxn.name,\n",
        "            \"rbc2_score\": rxn.score,\n",
        "            \"precedent_best_similarity\": 0.0,  # placeholder; your ranker can fill if available later\n",
        "            \"selenzyme_url\": \"\"\n",
        "        }})\n",
        "    return rows\n",
        "\n",
        "def write_bundle(paths, prefix):\n",
        "    all_rows = []\n",
        "    for k, pwy in enumerate(paths, start=1):\n",
        "        tag = f\"P{k:03d}\"\n",
        "        (retro_out / f\"{{tag}}.json\").write_text(json.dumps(pwy.save(), indent=2))\n",
        "        all_rows.extend(pathway_rows(pwy, tag))\n",
        "    if all_rows:\n",
        "        df = pd.DataFrame(all_rows)\n",
        "        df.to_csv(retro_out / f\"pathways_{{prefix}}_steps.csv\", index=False)\n",
        "        # legacy name for downstream compatibility\n",
        "        if prefix == \"all\":\n",
        "            df.to_csv(retro_out / \"steps.csv\", index=False)\n",
        "    return len(all_rows)\n",
        "\n",
        "n_all = write_bundle(all_paths, \"all\")\n",
        "n_sol = write_bundle(solved_paths, \"solved\")\n",
        "\n",
        "print(f\"[rbc2] Total pathways: {{len(all_paths)}} | Solved: {{len(solved_paths)}} | Rows(all): {{n_all}}\")\n",
        "\"\"\"\n",
        "    py_path.write_text(textwrap.dedent(code))\n",
        "\n",
        "# =========================\n",
        "# FIXED RETROSYNTHESIS NODE\n",
        "# =========================\n",
        "from pathlib import Path\n",
        "import json, traceback, pandas as pd, os, time\n",
        "\n",
        "# --- helpers: paths + shell ---------------------------------------------------\n",
        "from pathlib import Path\n",
        "import subprocess, shlex, json, os, textwrap, sys\n",
        "from datetime import datetime\n",
        "\n",
        "def _p(*parts):\n",
        "    return Path(*map(str, parts)).resolve()\n",
        "\n",
        "def _now():\n",
        "    return datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%SZ\")\n",
        "\n",
        "def _mkdir(p):\n",
        "    p = Path(p); p.mkdir(parents=True, exist_ok=True); return p\n",
        "\n",
        "def _write_text(p, txt):\n",
        "    p = Path(p); _mkdir(p.parent); p.write_text(txt); return p\n",
        "\n",
        "def _file_nonempty(p):\n",
        "    p = Path(p)\n",
        "    try:\n",
        "        return p.exists() and p.is_file() and p.stat().st_size > 0\n",
        "    except FileNotFoundError:\n",
        "        return False\n",
        "\n",
        "def _log_tail(p, n=60):\n",
        "    p = Path(p)\n",
        "    if not p.exists(): return \"(no log)\"\n",
        "    try:\n",
        "        with p.open(\"r\", errors=\"ignore\") as fh:\n",
        "            lines = fh.readlines()\n",
        "        return \"\".join(lines[-n:])\n",
        "    except Exception as e:\n",
        "        return f\"(could not read log: {e})\"\n",
        "\n",
        "def _run(cmd, cwd=None, env=None, log_path=None):\n",
        "    \"\"\"Run a shell command and stream stdout/stderr to a log file.\"\"\"\n",
        "    proc_env = os.environ.copy()\n",
        "    if env: proc_env.update(env)\n",
        "    if isinstance(cmd, str):\n",
        "        args = cmd if os.name == \"nt\" else cmd\n",
        "        shell = True\n",
        "    else:\n",
        "        args = cmd\n",
        "        shell = False\n",
        "    log_fh = None\n",
        "    try:\n",
        "        if log_path:\n",
        "            _mkdir(Path(log_path).parent)\n",
        "            log_fh = open(log_path, \"a\", buffering=1, encoding=\"utf-8\", errors=\"ignore\")\n",
        "            log_fh.write(f\"\\n[{_now()}] CMD: {cmd if isinstance(cmd,str) else ' '.join(map(shlex.quote,cmd))}\\n\")\n",
        "        proc = subprocess.Popen(args, cwd=cwd, env=proc_env, shell=shell,\n",
        "                                stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
        "                                text=True, bufsize=1, universal_newlines=True)\n",
        "        for line in proc.stdout:\n",
        "            if log_fh: log_fh.write(line)\n",
        "        proc.wait()\n",
        "        rc = proc.returncode\n",
        "        if log_fh: log_fh.write(f\"[{_now()}] RC={rc}\\n\")\n",
        "        return rc\n",
        "    finally:\n",
        "        if log_fh: log_fh.close()\n",
        "\n",
        "# --- node: retrosynthesis (runs RBC2 *inside micromamba*) ---------------------\n",
        "\n",
        "def retrosynthesis_node(state: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Runs RBC2 inside the micromamba env (retrobiocat) and writes outputs into\n",
        "    <workdir>/retro_out so the rest of your pipeline (extract/thermo/...) works.\n",
        "    \"\"\"\n",
        "    import os, json, textwrap, subprocess, shlex\n",
        "    from pathlib import Path\n",
        "    from datetime import datetime, timezone\n",
        "\n",
        "    def _ts():\n",
        "        return datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
        "\n",
        "    workdir = Path(state[\"workdir\"]).resolve()\n",
        "    retro   = workdir / \"retro_out\"\n",
        "    logsdir = workdir / \"logs\"\n",
        "    bindir  = workdir / \"bin\"\n",
        "    cfgdir  = workdir / \"config\"\n",
        "    env_prefix = workdir / \"micromamba\" / \"envs\" / \"retrobiocat\"\n",
        "\n",
        "    retro.mkdir(parents=True, exist_ok=True)\n",
        "    logsdir.mkdir(parents=True, exist_ok=True)\n",
        "    bindir.mkdir(parents=True, exist_ok=True)\n",
        "    cfgdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    out_log = logsdir / \"_rbc2_runner.out.log\"\n",
        "    err_log = logsdir / \"_rbc2_runner.err.log\"\n",
        "\n",
        "    # Write a small config file the runner will read\n",
        "    cfg_json = cfgdir / \"retro_cfg.json\"\n",
        "    cfg_json.write_text(json.dumps({\n",
        "        \"target_smiles\": state[\"target_smiles\"],\n",
        "        \"max_steps\": int(state.get(\"constraints\", {}).get(\"max_steps\", 5)),\n",
        "        \"outdir\": retro.as_posix()\n",
        "    }, indent=2))\n",
        "\n",
        "    # Write the runner script WITHOUT outer f-strings (to avoid brace interpolation)\n",
        "    runner_py = bindir / \"rbc2_runner.py\"\n",
        "    runner_source = r'''\n",
        "import json, sys\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "def ts():\n",
        "    return datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
        "\n",
        "# Paths provided by the parent process\n",
        "CFG_JSON_PATH = r\"{CFG_JSON_PATH}\"\n",
        "\n",
        "cfg = json.loads(Path(CFG_JSON_PATH).read_text())\n",
        "target = cfg[\"target_smiles\"]\n",
        "max_steps = int(cfg[\"max_steps\"])\n",
        "outdir = Path(cfg[\"outdir\"])\n",
        "outdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"[{}] RBC2: starting for target {}\".format(ts(), target))\n",
        "\n",
        "try:\n",
        "    from rbc2 import MCTS, get_expanders\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"RBC2 import failed: {}: {}\".format(e.__class__.__name__, e))\n",
        "\n",
        "# Conservative, broadly-compatible call pattern\n",
        "expanders = get_expanders([\"retrobiocat\"])\n",
        "mcts = MCTS(target, expanders)\n",
        "mcts.config.max_search_time = int(20)\n",
        "mcts.config.max_depth = max_steps\n",
        "\n",
        "mcts.run()\n",
        "\n",
        "all_paths = mcts.get_all_pathways()\n",
        "solved_paths = mcts.get_solved_pathways()\n",
        "\n",
        "# Serialize a minimal steps.csv and pathways.csv the extractor expects\n",
        "import pandas as pd\n",
        "\n",
        "def rows_for(paths):\n",
        "    rows = []\n",
        "    for p_i, pwy in enumerate(paths):\n",
        "        tag = \"P%03d\" % (p_i + 1)\n",
        "        for s_i, rxn in enumerate(pwy.reactions, start=1):\n",
        "            rows.append({\n",
        "                \"pathway_tag\": tag,\n",
        "                \"step_idx\": s_i,\n",
        "                \"reaction_smiles\": rxn.reaction_smiles(),\n",
        "                \"substrates\": \" . \".join(rxn.substrates),\n",
        "                \"products\": rxn.product,\n",
        "                \"rxn_type\": getattr(rxn, \"rxn_type\", \"\"),\n",
        "                \"name\": getattr(rxn, \"name\", \"\"),\n",
        "                \"rbc2_score\": float(getattr(rxn, \"score\", 0.0)),\n",
        "                \"precedent_best_similarity\": float(getattr(rxn, \"precedent_best_similarity\", 0.0)),\n",
        "                \"selenzyme_url\": getattr(rxn, \"selenzyme_url\", \"\"),\n",
        "            })\n",
        "    return rows\n",
        "\n",
        "# Write main outputs\n",
        "all_rows = rows_for(all_paths)\n",
        "if all_rows:\n",
        "    pd.DataFrame(all_rows).to_csv(outdir / \"steps.csv\", index=False)\n",
        "    pd.DataFrame({\"pathway_tag\": sorted({r[\"pathway_tag\"] for r in all_rows})}).to_csv(outdir / \"pathways.csv\", index=False)\n",
        "\n",
        "# Optional \"all\" and \"solved\" variants if you like\n",
        "solved_rows = rows_for(solved_paths)\n",
        "if solved_rows:\n",
        "    pd.DataFrame(solved_rows).to_csv(outdir / \"pathways_solved_steps.csv\", index=False)\n",
        "if all_rows:\n",
        "    pd.DataFrame(all_rows).to_csv(outdir / \"pathways_all_steps.csv\", index=False)\n",
        "\n",
        "print(\"[{}] RBC2 complete → {}\".format(ts(), outdir))\n",
        "'''\n",
        "    runner_py.write_text(\n",
        "        runner_source.replace(\"{CFG_JSON_PATH}\", cfg_json.as_posix())\n",
        "    )\n",
        "\n",
        "    # Locate micromamba\n",
        "    micromamba = workdir / \"bin\" / \"micromamba\"\n",
        "    if not micromamba.exists():\n",
        "        micromamba = Path(\"micromamba\")  # fallback\n",
        "\n",
        "    cmd = [\n",
        "        str(micromamba),\n",
        "        \"run\",\n",
        "        \"-p\", str(env_prefix),\n",
        "        \"python\",\n",
        "        str(runner_py),\n",
        "    ]\n",
        "\n",
        "    # Run and capture logs\n",
        "    import subprocess, shlex\n",
        "    with out_log.open(\"wb\") as out, err_log.open(\"wb\") as err:\n",
        "        proc = subprocess.run(cmd, stdout=out, stderr=err, cwd=str(workdir))\n",
        "\n",
        "    state.setdefault(\"logs\", []).append({\n",
        "        \"node\": \"retrosynthesis\",\n",
        "        \"ts\": _ts(),\n",
        "        \"cmd\": \" \".join(shlex.quote(c) for c in cmd),\n",
        "        \"rc\": proc.returncode,\n",
        "        \"out_log\": out_log.as_posix(),\n",
        "        \"err_log\": err_log.as_posix(),\n",
        "    })\n",
        "\n",
        "    # Validate outputs so extractor won’t crash on empties\n",
        "    def _nonempty(p: Path) -> bool:\n",
        "        try:\n",
        "            return p.exists() and p.stat().st_size > 0\n",
        "        except Exception:\n",
        "            return False\n",
        "\n",
        "    must_have = [retro / \"steps.csv\", retro / \"pathways.csv\"]\n",
        "    if proc.returncode != 0 or not all(_nonempty(p) for p in must_have):\n",
        "        tail = \"\"\n",
        "        try:\n",
        "            if err_log.exists():\n",
        "                lines = err_log.read_text().splitlines()\n",
        "                tail = \"\\n\" + \"\\n\".join(lines[-50:])\n",
        "        except Exception:\n",
        "            pass\n",
        "        raise RuntimeError(\n",
        "            \"Retrosynthesis produced no usable outputs; see logs.\\n\"\n",
        "            + (\"--- _rbc2_runner.err.log (tail) ---\\n\" + tail if tail else \"\")\n",
        "        )\n",
        "\n",
        "    return state\n",
        "\n",
        "import subprocess, shutil\n",
        "\n",
        "def ensure_equilibrator(env_prefix):\n",
        "    mm = \"/content/runs/run_001/bin/micromamba\"\n",
        "    pkgs = [\"equilibrator-api==0.6.0\", \"equilibrator-cache==0.6.0\"]\n",
        "    subprocess.run(\n",
        "        [mm, \"run\", \"-p\", env_prefix, \"python\", \"-m\", \"pip\", \"install\", *pkgs],\n",
        "        check=False\n",
        "    )\n",
        "\n",
        "# --------------------------- compound_map_node -----------------------------\n",
        "\n",
        "def _ensure_rdkit_outer():\n",
        "    \"\"\"Ensure rdkit is importable in the *notebook* interpreter (not micromamba).\"\"\"\n",
        "    try:\n",
        "        import rdkit  # noqa: F401\n",
        "        return\n",
        "    except Exception:\n",
        "        import sys, subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rdkit-pypi\"])\n",
        "        import rdkit  # noqa: F401\n",
        "\n",
        "def _tokenize_rxn_smiles(rxn):\n",
        "    if not isinstance(rxn, str) or \">>\" not in rxn:\n",
        "        return [], []\n",
        "    L, R = rxn.split(\">>\", 1)\n",
        "    subs  = [s.strip() for s in L.split(\".\") if s.strip()]\n",
        "    prods = [p.strip() for p in R.split(\".\") if p.strip()]\n",
        "    return subs, prods\n",
        "\n",
        "def compound_map_node(state):\n",
        "    \"\"\"\n",
        "    Build a minimal compound map from the reaction SMILES in steps_enzyme_plan.csv.\n",
        "    Output: retro_finish_out/metabolite_map.csv with columns:\n",
        "      token, smiles, inchikey\n",
        "    Notes:\n",
        "      - Runs in the outer Python (no micromamba required).\n",
        "      - If RDKit is available, uses MolToInchiKey; otherwise writes empty inchikey.\n",
        "    \"\"\"\n",
        "    import os, csv\n",
        "    from pathlib import Path\n",
        "    import pandas as pd\n",
        "\n",
        "    def _log(msg):\n",
        "        print(msg)\n",
        "        state.setdefault(\"logs\", []).append(msg)\n",
        "\n",
        "    workdir = Path(state[\"workdir\"])\n",
        "    finish  = workdir / \"retro_finish_out\"\n",
        "    retro   = workdir / \"retro_out\"\n",
        "    finish.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    steps_csv = finish / \"steps_enzyme_plan.csv\"\n",
        "    if not steps_csv.exists():\n",
        "        # fall back to extractor output\n",
        "        alt = retro / \"steps.csv\"\n",
        "        if alt.exists():\n",
        "            steps_csv = alt\n",
        "        else:\n",
        "            _log(\"compound_map: no steps table found\")\n",
        "            return state\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(steps_csv)\n",
        "    except Exception as e:\n",
        "        _log(\"compound_map: failed to read steps CSV: %s: %s\" % (type(e).__name__, e))\n",
        "        return state\n",
        "\n",
        "    # Minimal tokenizer for \"L.SMILES...>>R.SMILES...\"\n",
        "    def _split_rxn(r):\n",
        "        if not isinstance(r, str) or \">>\" not in r:\n",
        "            return [], []\n",
        "        L, R = r.split(\">>\", 1)\n",
        "        subs  = [s.strip() for s in L.split(\".\") if s.strip()]\n",
        "        prods = [p.strip() for p in R.split(\".\") if p.strip()]\n",
        "        return subs, prods\n",
        "\n",
        "    tokens = set()\n",
        "    for rxn in df.get(\"reaction_smiles\", pd.Series([\"\"] * len(df))).astype(str).fillna(\"\"):\n",
        "        L, R = _split_rxn(rxn)\n",
        "        tokens.update(L); tokens.update(R)\n",
        "    tokens = sorted(tokens)\n",
        "\n",
        "    # Try RDKit\n",
        "    have_rdkit = False\n",
        "    try:\n",
        "        from rdkit import Chem\n",
        "        have_rdkit = True\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    rows = []\n",
        "    for t in tokens:\n",
        "        ik = \"\"\n",
        "        if have_rdkit:\n",
        "            try:\n",
        "                m = Chem.MolFromSmiles(t)\n",
        "                if m is not None:\n",
        "                    ik = Chem.MolToInchiKey(m) or \"\"\n",
        "            except Exception:\n",
        "                ik = \"\"\n",
        "        rows.append({\"token\": t, \"smiles\": t, \"inchikey\": ik})\n",
        "\n",
        "    out_csv = finish / \"metabolite_map.csv\"\n",
        "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=[\"token\", \"smiles\", \"inchikey\"])\n",
        "        w.writeheader()\n",
        "        for r in rows:\n",
        "            w.writerow(r)\n",
        "\n",
        "    filled = sum(1 for r in rows if r.get(\"inchikey\"))\n",
        "    _log(\"compound_map: wrote %s (inchikey filled %d / %d)\" % (str(out_csv), filled, len(rows)))\n",
        "\n",
        "    state.setdefault(\"artifacts\", []).append(str(out_csv))\n",
        "    return state\n",
        "\n",
        "\n",
        "from urllib.parse import quote_plus\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def add_selenzyme_links_node(state):\n",
        "    \"\"\"\n",
        "    Ensure a 'selenzyme_url' column exists and is string-typed, and fill any\n",
        "    missing/invalid entries with a deterministic Selenzyme link built from\n",
        "    reaction_smiles. Writes back to retro_finish_out/steps_enzyme_plan.csv.\n",
        "    \"\"\"\n",
        "    import urllib.parse as _url\n",
        "    import pandas as _pd\n",
        "    from pathlib import Path as _Path\n",
        "    import math as _math\n",
        "    import numpy as _np\n",
        "\n",
        "    def _log(msg):\n",
        "        print(msg)\n",
        "        state.setdefault(\"logs\", []).append(msg)\n",
        "\n",
        "    _log(\"▶ start add_selenzyme_links\")\n",
        "\n",
        "    workdir   = _Path(state[\"workdir\"])\n",
        "    finish    = workdir / \"retro_finish_out\"\n",
        "    retro_out = workdir / \"retro_out\"\n",
        "    finish.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Prefer the enriched table if it already exists\n",
        "    steps_csv = finish / \"steps_enzyme_plan.csv\"\n",
        "    if not steps_csv.exists():\n",
        "        # Fallback to extractor output\n",
        "        cand = retro_out / \"steps.csv\"\n",
        "        if not cand.exists():\n",
        "            _log(\"add_selenzyme_links: no steps file found; skipping\")\n",
        "            _log(\"✔ done add_selenzyme_links\")\n",
        "            return state\n",
        "        steps_csv = cand\n",
        "\n",
        "    df = _pd.read_csv(steps_csv)\n",
        "\n",
        "    # Guarantee required columns\n",
        "    for col in [\"pathway_tag\", \"step_idx\", \"reaction_smiles\"]:\n",
        "        if col not in df.columns:\n",
        "            df[col] = \"\" if col != \"step_idx\" else 0\n",
        "\n",
        "    # Make sure the url column exists and is object/str dtype (not float)\n",
        "    if \"selenzyme_url\" not in df.columns:\n",
        "        df[\"selenzyme_url\"] = \"\"\n",
        "    # Normalize any non-string junk to empty string\n",
        "    def _norm_to_str(x):\n",
        "        # Treat NaN, None, empty list, and the literal string \"[]\"/\"nan\" as empty\n",
        "        if x is None:\n",
        "            return \"\"\n",
        "        if isinstance(x, float) and _math.isnan(x):\n",
        "            return \"\"\n",
        "        if isinstance(x, list):\n",
        "            return \"\"\n",
        "        sx = str(x)\n",
        "        if sx.strip() in (\"\", \"[]\", \"nan\", \"NaN\", \"None\"):\n",
        "            return \"\"\n",
        "        return sx\n",
        "\n",
        "    df[\"selenzyme_url\"] = df[\"selenzyme_url\"].map(_norm_to_str).astype(\"string\")\n",
        "\n",
        "    # Build URLs only where empty AND reaction_smiles looks valid\n",
        "    def mk_url(rxn: str) -> str:\n",
        "        rxn = \"\" if rxn is None else str(rxn)\n",
        "        if \">>\" not in rxn:\n",
        "            return \"\"\n",
        "        return \"https://selenzyme.org/selenzy?reaction=\" + _url.quote(rxn, safe=\"\")\n",
        "\n",
        "    before_nonempty = df[\"selenzyme_url\"].ne(\"\") & df[\"selenzyme_url\"].notna()\n",
        "    needs_fill = ~before_nonempty & df[\"reaction_smiles\"].astype(str).str.contains(\">>\", na=False)\n",
        "\n",
        "    # Fill\n",
        "    if needs_fill.any():\n",
        "        df.loc[needs_fill, \"selenzyme_url\"] = df.loc[needs_fill, \"reaction_smiles\"].astype(str).map(mk_url).astype(\"string\")\n",
        "\n",
        "    # Count after fill: treat empty string as missing\n",
        "    filled_count = (df[\"selenzyme_url\"].notna() & df[\"selenzyme_url\"].ne(\"\")).sum()\n",
        "\n",
        "    # Always write the enriched table to finish/\n",
        "    out_csv = finish / \"steps_enzyme_plan.csv\"\n",
        "    df.to_csv(out_csv, index=False)\n",
        "\n",
        "    _log(f\"selenzyme_links: filled {int(filled_count)} URLs out of {len(df)} rows → {out_csv}\")\n",
        "    _log(\"✔ done add_selenzyme_links\")\n",
        "    return state\n",
        "\n",
        "\n",
        "# --- Micromamba bootstrap + robust _run_in_env (Python cell) ---\n",
        "from pathlib import Path\n",
        "import os, subprocess, sys, textwrap\n",
        "\n",
        "MAMBA_ROOT = Path(\"/content/runs/run_001/micromamba\")\n",
        "MAMBA_BIN  = Path(\"/content/runs/run_001/bin/micromamba\")\n",
        "ENV_PREFIX = MAMBA_ROOT / \"envs\" / \"retrobiocat\"\n",
        "\n",
        "\n",
        "def _ensure_cobra(env_prefix, state=None):\n",
        "    \"\"\"Install a cobra stack compatible with numpy>=1.26 / pandas>=2 inside the env (idempotent).\"\"\"\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-c\",\"import cobra; print('cobra_ok')\"])\n",
        "    if rc == 0 and (out or \"\").strip().endswith(\"cobra_ok\"):\n",
        "        return\n",
        "    rc, out, err = _run_in_env(env_prefix, [\"python\",\"-m\",\"pip\",\"install\",\"-q\",\"cobra==0.29.0\",\"optlang>=1.8.0\",\"swiglpk>=5.0.10\"])\n",
        "    if state is not None and rc != 0:\n",
        "        state.setdefault(\"logs\", []).append(\"simulate_gem: cobra install warning (continuing)\")\n",
        "        if err:\n",
        "            state[\"logs\"].append(err.strip().splitlines()[-1])\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Wire the graph\n",
        "# =========================\n",
        "from functools import partial\n",
        "\n",
        "# --- build the graph ---\n",
        "graph = StateGraph(DBTLState)\n",
        "\n",
        "# Design/analysis stack\n",
        "graph.add_node(\"retrosynthesis\", retrosynthesis_node)\n",
        "graph.add_node(\"extract\", extract_node)\n",
        "graph.add_node(\"add_selenzyme_links\", add_selenzyme_links_node)\n",
        "graph.add_node(\"thermo\", thermo_node)\n",
        "graph.add_node(\"rank\", rank_node)\n",
        "graph.add_node(\"simulate_gem\", simulate_gem_node)\n",
        "graph.add_node(\"strain_optimize\", strain_optimize_node)\n",
        "\n",
        "# Enzyme/sequence stack\n",
        "graph.add_node(\"selenzyme_rank\", selenzyme_rank_node)\n",
        "graph.add_node(\"sequence_fetch\", lambda s: sequence_fetch_node(s, per_step=10, reviewed_first=False, timeout=12.0))\n",
        "graph.add_node(\"sequence_rank\", sequence_rank_node)\n",
        "\n",
        "# Build + new Test/Learn\n",
        "graph.add_node(\"build\", build_node)\n",
        "graph.add_node(\"test\", test_node)\n",
        "graph.add_node(\"learn\", learn_node)\n",
        "\n",
        "# Optional export (if you already have one)\n",
        "graph.add_node(\"export\", export_node)\n",
        "\n",
        "# --- entry point ---\n",
        "graph.set_entry_point(\"retrosynthesis\")\n",
        "\n",
        "# --- forward edges through Design ---\n",
        "graph.add_edge(\"retrosynthesis\", \"extract\")\n",
        "graph.add_edge(\"extract\", \"add_selenzyme_links\")\n",
        "graph.add_edge(\"add_selenzyme_links\", \"thermo\")\n",
        "graph.add_edge(\"thermo\", \"rank\")\n",
        "graph.add_edge(\"rank\", \"simulate_gem\")\n",
        "\n",
        "# --- enzyme/sequence route (after simulate_gem) ---\n",
        "graph.add_edge(\"simulate_gem\", \"selenzyme_rank\")\n",
        "# --- enzyme/sequence route (after simulate_gem) ---\n",
        "graph.add_edge(\"simulate_gem\", \"selenzyme_rank\")\n",
        "graph.add_edge(\"selenzyme_rank\", \"sequence_fetch\")\n",
        "graph.add_edge(\"sequence_fetch\", \"sequence_rank\")\n",
        "\n",
        "# Gate strain_optimize on basic coverage; compute a quick report if missing\n",
        "def _coverage_router(state):\n",
        "    import pandas as pd, pathlib\n",
        "    finish = pathlib.Path(state.get(\"workdir\") or state.get(\"run_dir\") or \".\") / \"retro_finish_out\"\n",
        "    rep_csv = finish / \"sequence_coverage_report.csv\"\n",
        "\n",
        "    try:\n",
        "        if rep_csv.exists():\n",
        "            rep = pd.read_csv(rep_csv)\n",
        "        else:\n",
        "            # Minimal on-the-fly report\n",
        "            steps = pd.read_csv(finish / \"steps_enzyme_plan.csv\")[[\"pathway_tag\",\"step_idx\"]].drop_duplicates()\n",
        "            cands = pd.read_csv(finish / \"steps_sequence_candidates.csv\")[[\"pathway_tag\",\"step_idx\"]].drop_duplicates()\n",
        "            picks = pd.read_csv(finish / \"steps_sequence_plan.csv\")[[\"pathway_tag\",\"step_idx\"]].drop_duplicates()\n",
        "\n",
        "            n_cands = (cands.groupby([\"pathway_tag\",\"step_idx\"])\n",
        "                            .size().reset_index(name=\"n_candidates\"))\n",
        "            rep = (steps.merge(n_cands, on=[\"pathway_tag\",\"step_idx\"], how=\"left\")\n",
        "                         .fillna({\"n_candidates\": 0}))\n",
        "            picked_pairs = set(zip(picks.pathway_tag, picks.step_idx))\n",
        "            rep[\"picked\"] = [(pt, si) in picked_pairs for pt, si in zip(rep.pathway_tag, rep.step_idx)]\n",
        "\n",
        "            def _reason(row):\n",
        "                if row[\"n_candidates\"] == 0: return \"no_candidates_found\"\n",
        "                if not row[\"picked\"]:       return \"not_selected_in_rank\"\n",
        "                return \"ok\"\n",
        "            rep[\"reason\"] = rep.apply(_reason, axis=1)\n",
        "            rep.sort_values([\"pathway_tag\",\"step_idx\"]).to_csv(rep_csv, index=False)\n",
        "\n",
        "        ok = (rep[\"n_candidates\"] > 0).mean() >= 0.80\n",
        "    except Exception:\n",
        "        ok = False\n",
        "\n",
        "    return \"ok\" if ok else \"retry\"\n",
        "\n",
        "# Route: if coverage OK → strain_optimize → build; else retry enzyme search\n",
        "graph.add_conditional_edges(\n",
        "    \"sequence_rank\",\n",
        "    _coverage_router,\n",
        "    {\"ok\": \"strain_optimize\", \"retry\": \"selenzyme_rank\"}\n",
        ")\n",
        "\n",
        "# After strain optimization, proceed to build → test → learn\n",
        "graph.add_edge(\"strain_optimize\", \"build\")\n",
        "graph.add_edge(\"build\", \"test\")\n",
        "graph.add_edge(\"test\", \"learn\")\n",
        "\n",
        "# Learn routes: loop back or finish/export\n",
        "def _learn_router(state):\n",
        "    return \"loop\" if state.get(\"signals\", {}).get(\"loop_back\") else \"finish\"\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"learn\",\n",
        "    _learn_router,\n",
        "    {\"loop\": \"selenzyme_rank\", \"finish\": \"export\"}\n",
        ")\n",
        "\n",
        "graph.add_edge(\"export\", END)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Example run\n",
        "# =========================\n",
        "# init_state = DBTLState(\n",
        "#     run_id=\"run_001\",\n",
        "#    workdir=\"/content/runs/run_001\",\n",
        "#     target_smiles=\"COC1=C(C=CC(=C1)C=O)O\",\n",
        "#     host=\"Escherichia coli\",\n",
        "#     constraints={\"max_steps\":\"5\"},\n",
        "#     logs=[]\n",
        "# )\n",
        "# for state in app.stream(init_state, stream_mode=\"values\"):\n",
        "#     node   = state.get(\"last_node\", \"?\")\n",
        "#     status = state.get(\"status\", \"?\")\n",
        "#     print(f\"[{node}] {status}\")\n",
        "# print(\"Final logs:\")\n",
        "# print(\"\\n\".join(state.get(\"logs\", [])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zgnSIe6U26K5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgnSIe6U26K5",
        "outputId": "86ed5ab9-6be5-463c-efb3-7000ff67c0a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "↓ downloading micromamba… https://micro.mamba.pm/api/micromamba/linux-64/latest\n",
            "→ extracting micromamba (auto-detect compression)…\n",
            "✅ micromamba: /content/bin/micromamba exists? True\n",
            "✅ ready. Re-run your execution cell.\n"
          ]
        }
      ],
      "source": [
        "# --- hotfix: place micromamba at /content/bin/micromamba and set root prefix ---\n",
        "import io, os, stat, tarfile, urllib.request, pathlib, subprocess\n",
        "\n",
        "BIN_DST = pathlib.Path(\"/content/bin/micromamba\")\n",
        "ROOT    = pathlib.Path(\"/content/runs/run_001/micromamba\")\n",
        "ENV     = ROOT / \"envs\" / \"retrobiocat\"\n",
        "\n",
        "# 1) put micromamba exactly where older helpers expect it\n",
        "if not BIN_DST.exists():\n",
        "    BIN_DST.parent.mkdir(parents=True, exist_ok=True)\n",
        "    url = \"https://micro.mamba.pm/api/micromamba/linux-64/latest\"\n",
        "    print(\"↓ downloading micromamba…\", url)\n",
        "    with urllib.request.urlopen(url) as r:\n",
        "        data = r.read()\n",
        "    print(\"→ extracting micromamba (auto-detect compression)…\")\n",
        "    with tarfile.open(fileobj=io.BytesIO(data), mode=\"r:*\") as tf:\n",
        "        member = None\n",
        "        for m in tf.getmembers():\n",
        "            name = m.name.replace(\"\\\\\", \"/\")\n",
        "            if name.endswith(\"/micromamba\") and \"/bin/\" in name:\n",
        "                member = m\n",
        "                break\n",
        "        if member is None:\n",
        "            for m in tf.getmembers():\n",
        "                if m.name.split(\"/\")[-1] == \"micromamba\":\n",
        "                    member = m\n",
        "                    break\n",
        "        if member is None:\n",
        "            raise RuntimeError(\"micromamba binary not found in archive\")\n",
        "        with tf.extractfile(member) as src, open(BIN_DST, \"wb\") as dst:\n",
        "            dst.write(src.read())\n",
        "    BIN_DST.chmod(BIN_DST.stat().st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)\n",
        "print(\"✅ micromamba:\", BIN_DST, \"exists?\", BIN_DST.exists())\n",
        "\n",
        "# 2) use the same root prefix your pipeline expects\n",
        "os.environ[\"MAMBA_ROOT_PREFIX\"] = str(ROOT)\n",
        "\n",
        "# 3) ensure the env exists (fast if already there)\n",
        "if not ENV.exists():\n",
        "    subprocess.check_call([str(BIN_DST), \"create\", \"-y\", \"-p\", str(ENV), \"-c\", \"conda-forge\", \"python=3.10\", \"pip\"])\n",
        "\n",
        "# 4) very light sanity ping\n",
        "subprocess.check_call([str(BIN_DST), \"run\", \"-p\", str(ENV), \"python\", \"-c\", \"import sys; print('python in env:', sys.executable)\"])\n",
        "print(\"✅ ready. Re-run your execution cell.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40nRr5WxPRJx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40nRr5WxPRJx",
        "outputId": "e43d856d-9cbd-4284-f67d-649b81c821c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ linked /content/runs/run_001/micromamba/bin/micromamba -> /content/runs/run_001/bin/micromamba\n",
            "✅ micromamba shim ready at: /content/runs/run_001/micromamba/bin/micromamba\n",
            "   also available at: /content/runs/run_001/bin/micromamba (exists: True )\n"
          ]
        }
      ],
      "source": [
        "# --- micromamba path shim (idempotent) ---\n",
        "import io, os, stat, tarfile, urllib.request, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "expected = Path(\"/content/runs/run_001/micromamba/bin/micromamba\")\n",
        "candidates = [\n",
        "    Path(\"/content/runs/run_001/bin/micromamba\"),\n",
        "    Path(\"/content/bin/micromamba\"),\n",
        "]\n",
        "\n",
        "def ensure_binary(p: Path):\n",
        "    if p.exists():\n",
        "        return p\n",
        "    # download micromamba and place it here\n",
        "    p.parent.mkdir(parents=True, exist_ok=True)\n",
        "    url = \"https://micro.mamba.pm/api/micromamba/linux-64/latest\"\n",
        "    print(\"↓ downloading micromamba…\", url)\n",
        "    with urllib.request.urlopen(url) as r:\n",
        "        data = r.read()\n",
        "    print(\"→ extracting micromamba (auto-detect compression)…\")\n",
        "    with tarfile.open(fileobj=io.BytesIO(data), mode=\"r:*\") as tf:\n",
        "        member = None\n",
        "        for m in tf.getmembers():\n",
        "            name = m.name.replace(\"\\\\\", \"/\")\n",
        "            if name.endswith(\"/micromamba\") and \"/bin/\" in name:\n",
        "                member = m\n",
        "                break\n",
        "        if member is None:\n",
        "            for m in tf.getmembers():\n",
        "                if m.name.split(\"/\")[-1] == \"micromamba\":\n",
        "                    member = m\n",
        "                    break\n",
        "        if member is None:\n",
        "            raise RuntimeError(\"micromamba binary not found in archive\")\n",
        "        with tf.extractfile(member) as src, open(p, \"wb\") as dst:\n",
        "            dst.write(src.read())\n",
        "    p.chmod(p.stat().st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)\n",
        "    return p\n",
        "\n",
        "# 1) find or fetch a working micromamba\n",
        "src = None\n",
        "for c in candidates:\n",
        "    if c.exists():\n",
        "        src = c\n",
        "        break\n",
        "if src is None:\n",
        "    # put a copy in /content/runs/run_001/bin for convenience\n",
        "    src = ensure_binary(Path(\"/content/runs/run_001/bin/micromamba\"))\n",
        "\n",
        "# 2) mirror it into the \"expected\" legacy location\n",
        "if not expected.exists():\n",
        "    expected.parent.mkdir(parents=True, exist_ok=True)\n",
        "    try:\n",
        "        expected.symlink_to(src)\n",
        "        print(f\"→ linked {expected} -> {src}\")\n",
        "    except Exception:\n",
        "        shutil.copy2(src, expected)\n",
        "        expected.chmod(expected.stat().st_mode | 0o111)\n",
        "        print(f\"→ copied {src} -> {expected}\")\n",
        "\n",
        "# 3) make sure root prefix is set so micromamba uses the same tree\n",
        "os.environ[\"MAMBA_ROOT_PREFIX\"] = \"/content/runs/run_001/micromamba\"\n",
        "\n",
        "print(\"✅ micromamba shim ready at:\", expected)\n",
        "print(\"   also available at:\", src, \"(exists:\", src.exists(), \")\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def strain_optimize_node(state):\n",
        "    import subprocess, json, pathlib, os, textwrap\n",
        "\n",
        "    def _log(msg):\n",
        "        print(msg)\n",
        "        state.setdefault(\"logs\", []).append(msg)\n",
        "\n",
        "    _log(\"▶ start strain_optimize\")\n",
        "\n",
        "    env_path = \"/content/runs/run_001/micromamba/envs/retrobiocat\"\n",
        "    workdir  = pathlib.Path(state.get(\"workdir\") or \".\")\n",
        "    finish   = workdir / \"retro_finish_out\"\n",
        "    finish.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    cfg       = (state.get(\"strain\") or {}).copy()\n",
        "    model_path = state.get(\"sbml_model_path\") or \"\"\n",
        "\n",
        "    # sane defaults\n",
        "    cfg.setdefault(\"solver\", \"glpk\")\n",
        "    cfg.setdefault(\"time_limit_s\", 300)\n",
        "    cfg.setdefault(\"fva\", False)\n",
        "    cfg.setdefault(\"search\", \"auto\")\n",
        "    cfg.setdefault(\"max_kos\", 2)\n",
        "    cfg.setdefault(\"min_growth\", 0.0)\n",
        "    cfg.setdefault(\"objective_id\", None)  # biomass rxn id\n",
        "    cfg.setdefault(\"product_rxn\", None)   # desired product rxn id\n",
        "\n",
        "    # heuristic candidate selection tweaks\n",
        "    cfg.setdefault(\"ko_filters\", {\n",
        "        \"skip_exchange\": True,\n",
        "        \"skip_transport\": True,\n",
        "        \"protect_essentials\": True,   # drop KOs that kill growth below min_growth\n",
        "        \"prefer_subsystems\": [        # boosts selection priority\n",
        "            \"Glycolysis/Gluconeogenesis\",\"TCA cycle\",\"Pentose Phosphate Pathway\",\n",
        "            \"Pyruvate Metabolism\",\"Anaplerotic reactions\"\n",
        "        ],\n",
        "        \"max_candidates\": 100\n",
        "    })\n",
        "    # optional triples sweep\n",
        "    cfg.setdefault(\"triples\", {\n",
        "        \"enable\": False,\n",
        "        \"top_k\": 30,       # restrict to top-k candidates before triples\n",
        "        \"patience\": 50     # stop if no improvement after N combos\n",
        "    })\n",
        "\n",
        "    # Build the inner script WITHOUT any .format/f-string interpolation.\n",
        "    py = textwrap.dedent(\"\"\"\n",
        "    import os, json, itertools, copy\n",
        "    import pandas as pd\n",
        "    from pathlib import Path\n",
        "\n",
        "    OUT_DIR    = Path(os.environ[\"FINISH\"])\n",
        "    MODEL_PATH = os.environ[\"MODEL_PATH\"]\n",
        "    CFG        = json.loads(os.environ[\"CFG_JSON\"])\n",
        "    SOLVER     = os.environ.get(\"SOLVER\") or \"glpk\"\n",
        "    TIME_LIMIT = float(os.environ.get(\"TIME_LIMIT\") or 0)\n",
        "\n",
        "    summary_json = OUT_DIR / \"strain_opt_summary.json\"\n",
        "    flux_csv     = OUT_DIR / \"strain_opt_fluxes.csv\"\n",
        "    fva_csv      = OUT_DIR / \"strain_opt_fva.csv\"\n",
        "    ko_csv       = OUT_DIR / \"strain_opt_ko_results.csv\"\n",
        "    ok_csv       = OUT_DIR / \"strain_opt_optknock.csv\"\n",
        "\n",
        "    def set_solver(model, solver_name, time_limit):\n",
        "        try:\n",
        "            model.solver = solver_name\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            if time_limit:\n",
        "                # try common optlang handles\n",
        "                try:\n",
        "                    model.solver.configuration.timeout = time_limit\n",
        "                except Exception:\n",
        "                    try:\n",
        "                        model.solver.problem.parameters.timelimit = time_limit\n",
        "                    except Exception:\n",
        "                        pass\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    def apply_medium(model, medium_map):\n",
        "        for rxn_id, lb in (medium_map or {}).items():\n",
        "            if rxn_id in model.reactions:\n",
        "                try:\n",
        "                    model.reactions.get_by_id(rxn_id).lower_bound = float(lb)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    def apply_knockouts(model, ko_list):\n",
        "        for ko in (ko_list or []):\n",
        "            if ko in model.reactions:\n",
        "                model.reactions.get_by_id(ko).knock_out()\n",
        "            elif ko in model.genes:\n",
        "                model.genes.get_by_id(ko).knock_out()\n",
        "\n",
        "    def run_fba(model, objective_id=None):\n",
        "        if objective_id and objective_id in model.reactions:\n",
        "            model.objective = objective_id\n",
        "        sol = model.optimize()\n",
        "        status = getattr(sol, \"status\", \"unknown\")\n",
        "        obj    = float(getattr(sol, \"objective_value\", 0.0) or 0.0)\n",
        "        fluxes = None\n",
        "        try:\n",
        "            fs = sol.fluxes\n",
        "            fluxes = pd.DataFrame({\"reaction_id\": fs.index, \"flux\": fs.values})\n",
        "        except Exception:\n",
        "            pass\n",
        "        return status, obj, fluxes\n",
        "\n",
        "    def run_fva(model, reaction_ids=None, fraction_of_optimum=0.9):\n",
        "        from cobra.flux_analysis import flux_variability_analysis\n",
        "        try:\n",
        "            df = flux_variability_analysis(\n",
        "                model,\n",
        "                reaction_list=[model.reactions.get_by_id(i) for i in reaction_ids] if reaction_ids else None,\n",
        "                fraction_of_optimum=fraction_of_optimum\n",
        "            )\n",
        "            return df.reset_index().rename(columns={\"index\":\"reaction_id\"})\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    def product_flux(flux_df, product_rxn):\n",
        "        if flux_df is None or not product_rxn:\n",
        "            return None\n",
        "        try:\n",
        "            row = flux_df.loc[flux_df[\"reaction_id\"] == product_rxn]\n",
        "            return float(row[\"flux\"].iloc[0]) if len(row) else None\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    def constrain_growth(model, biomass_id, min_growth):\n",
        "        if biomass_id and biomass_id in model.reactions and min_growth is not None:\n",
        "            try:\n",
        "                model.reactions.get_by_id(biomass_id).lower_bound = float(min_growth)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    def annotate_reaction(r):\n",
        "        rid = r.id\n",
        "        name = getattr(r, \"name\", \"\") or \"\"\n",
        "        subsystem = getattr(r, \"subsystem\", \"\") or \"\"\n",
        "        is_exchange = bool(r.boundary) or rid.startswith(\"EX_\") or \"exchange\" in name.lower()\n",
        "        is_transport = (\"transport\" in name.lower()) or (\"transport\" in subsystem.lower()) or rid.startswith(\"TCE\") or rid.startswith(\"TRANS\")\n",
        "        return rid, subsystem, is_exchange, is_transport\n",
        "\n",
        "    def choose_ko_candidates(model, flux_df, filters):\n",
        "        # start from reactions with highest |flux|\n",
        "        if flux_df is None or not len(flux_df):\n",
        "            rxns = [r.id for r in model.reactions]\n",
        "            df = pd.DataFrame({\"reaction_id\": rxns, \"abs_flux\":[0.0]*len(rxns)})\n",
        "        else:\n",
        "            df = flux_df.copy()\n",
        "            df[\"abs_flux\"] = df[\"flux\"].abs()\n",
        "\n",
        "        # annotate and filter\n",
        "        ann = [annotate_reaction(model.reactions.get_by_id(rid)) for rid in df[\"reaction_id\"] if rid in model.reactions]\n",
        "        ann_df = pd.DataFrame(ann, columns=[\"reaction_id\",\"subsystem\",\"is_exchange\",\"is_transport\"])\n",
        "        df = df.merge(ann_df, on=\"reaction_id\", how=\"left\")\n",
        "\n",
        "        if filters.get(\"skip_exchange\", True):\n",
        "            df = df[df[\"is_exchange\"] != True]\n",
        "        if filters.get(\"skip_transport\", True):\n",
        "            df = df[df[\"is_transport\"] != True]\n",
        "\n",
        "        # boost preferred subsystems\n",
        "        prefs = set(filters.get(\"prefer_subsystems\", []) or [])\n",
        "        df[\"score\"] = df[\"abs_flux\"] + df[\"subsystem\"].apply(lambda s: 10.0 if s in prefs else 0.0)\n",
        "\n",
        "        # keep top N\n",
        "        maxN = int(filters.get(\"max_candidates\", 100) or 100)\n",
        "        df = df.sort_values(\"score\", ascending=False).head(maxN).reset_index(drop=True)\n",
        "        return df[\"reaction_id\"].tolist()\n",
        "\n",
        "    def drop_essential_kos(model, biomass_id, min_growth, cand_ids):\n",
        "        safe = []\n",
        "        for rid in cand_ids:\n",
        "            m = copy.deepcopy(model)\n",
        "            apply_knockouts(m, [rid])\n",
        "            status, obj, fl = run_fba(m, objective_id=biomass_id)\n",
        "            # keep if growth >= min_growth\n",
        "            if obj is not None and obj >= float(min_growth or 0.0):\n",
        "                safe.append(rid)\n",
        "        return safe\n",
        "\n",
        "    def heuristic_ko_search(model, product_rxn, biomass_id, min_growth, max_kos, ko_ids, triples_cfg):\n",
        "        results = []\n",
        "\n",
        "        # baseline\n",
        "        m0 = copy.deepcopy(model)\n",
        "        constrain_growth(m0, biomass_id, min_growth)\n",
        "        st, obj, fl = run_fba(m0, objective_id=product_rxn or biomass_id)\n",
        "        results.append({\"kos\": [], \"status\": st, \"objective\": obj, \"product_flux\": product_flux(fl, product_rxn)})\n",
        "\n",
        "        # singles\n",
        "        for a in ko_ids:\n",
        "            m = copy.deepcopy(model)\n",
        "            apply_knockouts(m, [a])\n",
        "            constrain_growth(m, biomass_id, min_growth)\n",
        "            st, obj, fl = run_fba(m, objective_id=product_rxn or biomass_id)\n",
        "            results.append({\"kos\": [a], \"status\": st, \"objective\": obj, \"product_flux\": product_flux(fl, product_rxn)})\n",
        "\n",
        "        # doubles\n",
        "        if int(max_kos or 0) >= 2:\n",
        "            for a, b in itertools.combinations(ko_ids, 2):\n",
        "                m = copy.deepcopy(model)\n",
        "                apply_knockouts(m, [a, b])\n",
        "                constrain_growth(m, biomass_id, min_growth)\n",
        "                st, obj, fl = run_fba(m, objective_id=product_rxn or biomass_id)\n",
        "                results.append({\"kos\": [a, b], \"status\": st, \"objective\": obj, \"product_flux\": product_flux(fl, product_rxn)})\n",
        "\n",
        "        # triples (optional)\n",
        "        if triples_cfg.get(\"enable\") and int(max_kos or 0) >= 3:\n",
        "            top_k = int(triples_cfg.get(\"top_k\", 30) or 30)\n",
        "            patience = int(triples_cfg.get(\"patience\", 50) or 50)\n",
        "            # reduce search space to top_k by best single/double result\n",
        "            df_tmp = pd.DataFrame(results).dropna(subset=[\"product_flux\"])\n",
        "            ranked = df_tmp.explode(\"kos\")\n",
        "            ranked = ranked[ranked[\"kos\"].notna()]\n",
        "            top = ranked.groupby(\"kos\")[\"product_flux\"].max().sort_values(ascending=False).head(top_k).index.tolist()\n",
        "            best_pf = df_tmp[\"product_flux\"].max() if len(df_tmp) else -1e9\n",
        "            no_improve = 0\n",
        "            for a, b, c in itertools.combinations(top, 3):\n",
        "                if no_improve >= patience:\n",
        "                    break\n",
        "                m = copy.deepcopy(model)\n",
        "                apply_knockouts(m, [a, b, c])\n",
        "                constrain_growth(m, biomass_id, min_growth)\n",
        "                st, obj, fl = run_fba(m, objective_id=product_rxn or biomass_id)\n",
        "                pf = product_flux(fl, product_rxn)\n",
        "                results.append({\"kos\": [a, b, c], \"status\": st, \"objective\": obj, \"product_flux\": pf})\n",
        "                if pf is not None and pf > best_pf:\n",
        "                    best_pf = pf\n",
        "                    no_improve = 0\n",
        "                else:\n",
        "                    no_improve += 1\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    def try_optknock(model, product_rxn, biomass_id, max_kos):\n",
        "        try:\n",
        "            import cameo\n",
        "            from cameo.strain_design.deterministic.linear_programming import OptKnock\n",
        "            from cameo.strain_design.heuristic.evolutionary.optimization import OptGen\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "        designs = []\n",
        "\n",
        "        # OptKnock\n",
        "        try:\n",
        "            ok = OptKnock(model, fraction_of_optimum=0.1, max_knockouts=int(max_kos or 2))\n",
        "            res = ok.run(max_knockouts=int(max_kos or 2))\n",
        "            if hasattr(res, \"data_frame\"):\n",
        "                for row in res.data_frame.itertuples(index=False):\n",
        "                    ks = list(getattr(row, \"knockouts\", [])) or list(getattr(row, \"design\", [])) or []\n",
        "                    fit = getattr(row, \"objective_value\", None) or getattr(row, \"fitness\", None)\n",
        "                    designs.append({\"method\":\"optknock\", \"design\": ks, \"fitness\": fit})\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # OptGen\n",
        "        try:\n",
        "            if product_rxn and product_rxn in model.reactions:\n",
        "                model.objective = product_rxn\n",
        "            og = OptGen(model=model, size=int(max_kos or 2), max_evaluations=200)\n",
        "            res = og.run(max_evaluations=200)\n",
        "            if hasattr(res, \"data_frame\"):\n",
        "                for row in res.data_frame.itertuples(index=False):\n",
        "                    ks = list(getattr(row, \"knockouts\", [])) or list(getattr(row, \"design\", [])) or []\n",
        "                    fit = getattr(row, \"objective_value\", None) or getattr(row, \"fitness\", None)\n",
        "                    designs.append({\"method\":\"optgen\", \"design\": ks, \"fitness\": fit})\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        return pd.DataFrame(designs) if designs else None\n",
        "\n",
        "    # -------- main --------\n",
        "    try:\n",
        "        from cobra.io import read_sbml_model\n",
        "        import cobra\n",
        "    except Exception as e:\n",
        "        with open(summary_json, \"w\") as f:\n",
        "            json.dump({\"error\": f\"cobra import failed: {type(e).__name__}: {e}\"}, f, indent=2)\n",
        "        print(\"strain_optimize: cobra import failed\")\n",
        "        raise\n",
        "\n",
        "    model = read_sbml_model(MODEL_PATH)\n",
        "    set_solver(model, SOLVER, TIME_LIMIT)\n",
        "\n",
        "    apply_medium(model, CFG.get(\"medium\", {}))\n",
        "\n",
        "    biomass_id = CFG.get(\"objective_id\")\n",
        "    product_rxn = CFG.get(\"product_rxn\")\n",
        "    min_growth = float(CFG.get(\"min_growth\", 0.0) or 0.0)\n",
        "    max_kos    = int(CFG.get(\"max_kos\", 2) or 2)\n",
        "\n",
        "    # baseline FBA (biomass objective)\n",
        "    base_status, base_obj, base_flux = run_fba(model.copy(), objective_id=biomass_id)\n",
        "    if base_flux is not None:\n",
        "        base_flux.to_csv(flux_csv, index=False)\n",
        "    base_prod = product_flux(base_flux, product_rxn)\n",
        "\n",
        "    # FVA (optional)\n",
        "    fva_df = None\n",
        "    if bool(CFG.get(\"fva\", False)):\n",
        "        rxn_ids = [r.id for r in model.reactions][:500]\n",
        "        fva_df = run_fva(model.copy(), reaction_ids=rxn_ids, fraction_of_optimum=0.9)\n",
        "        if fva_df is not None:\n",
        "            fva_df.to_csv(fva_csv, index=False)\n",
        "\n",
        "    # search strategy\n",
        "    search = (CFG.get(\"search\") or \"auto\").lower()\n",
        "    if search not in (\"auto\",\"heuristic\",\"optknock\"):\n",
        "        search = \"auto\"\n",
        "\n",
        "    # seed candidate list (by flux)\n",
        "    _, _, seed_flux = run_fba(model.copy(), objective_id=biomass_id)\n",
        "    ko_ids = choose_ko_candidates(model, seed_flux, CFG.get(\"ko_filters\", {}))\n",
        "\n",
        "    # protect essentials if requested\n",
        "    if (CFG.get(\"ko_filters\", {}).get(\"protect_essentials\", True)) and len(ko_ids):\n",
        "        ko_ids = drop_essential_kos(model, biomass_id, min_growth, ko_ids)\n",
        "\n",
        "    ko_df = None\n",
        "    ok_df = None\n",
        "\n",
        "    if search in (\"auto\",\"optknock\"):\n",
        "        ok_df = try_optknock(model.copy(), product_rxn, biomass_id, max_kos)\n",
        "        if ok_df is not None and len(ok_df):\n",
        "            ok_df.to_csv(ok_csv, index=False)\n",
        "\n",
        "    if (ok_df is None or not len(ok_df)) and search in (\"auto\",\"heuristic\"):\n",
        "        ko_df = heuristic_ko_search(\n",
        "            model.copy(), product_rxn, biomass_id, min_growth, max_kos, ko_ids,\n",
        "            CFG.get(\"triples\", {})\n",
        "        )\n",
        "        if ko_df is not None and len(ko_df):\n",
        "            ko_df.to_csv(ko_csv, index=False)\n",
        "\n",
        "    # pick best by product flux\n",
        "    best = {\"method\":\"none\",\"kos\":[], \"product_flux\": base_prod, \"status\": base_status}\n",
        "    def consider(df, method):\n",
        "        nonlocal best\n",
        "        if df is None or not len(df):\n",
        "            return\n",
        "        d = df.dropna(subset=[\"product_flux\"])\n",
        "        if not len(d):\n",
        "            return\n",
        "        i = d[\"product_flux\"].astype(float).idxmax()\n",
        "        row = d.loc[i]\n",
        "        cand = {\"method\": method, \"kos\": list(row[\"kos\"]) if \"kos\" in row else list(row.get(\"design\", [])),\n",
        "                \"product_flux\": float(row[\"product_flux\"]), \"status\": str(row.get(\"status\",\"\"))}\n",
        "        if best[\"product_flux\"] is None or cand[\"product_flux\"] > (best[\"product_flux\"] or -1e9):\n",
        "            best = cand\n",
        "\n",
        "    consider(ko_df, \"heuristic\")\n",
        "    # map cameo frame if needed\n",
        "    if ok_df is not None and len(ok_df):\n",
        "        tmp = ok_df.copy()\n",
        "        if \"design\" not in tmp.columns and \"knockouts\" in tmp.columns:\n",
        "            tmp[\"design\"] = tmp[\"knockouts\"]\n",
        "        if \"fitness\" in tmp.columns and \"product_flux\" not in tmp.columns:\n",
        "            tmp[\"product_flux\"] = tmp[\"fitness\"]\n",
        "        if \"design\" in tmp.columns and \"product_flux\" in tmp.columns:\n",
        "            tmp = tmp.rename(columns={\"design\":\"kos\"})\n",
        "            consider(tmp, \"optknock/optgen\")\n",
        "\n",
        "    summary = {\n",
        "        \"solver\": SOLVER,\n",
        "        \"time_limit_s\": TIME_LIMIT,\n",
        "        \"biomass_id\": biomass_id,\n",
        "        \"product_rxn\": product_rxn,\n",
        "        \"min_growth\": min_growth,\n",
        "        \"base\": {\"status\": base_status, \"objective\": base_obj, \"product_flux\": base_prod},\n",
        "        \"selected_design\": best,\n",
        "        \"files\": {\n",
        "            \"fluxes_csv\": str(flux_csv),\n",
        "            \"fva_csv\": str(fva_csv) if fva_df is not None else None,\n",
        "            \"ko_results_csv\": str(ko_csv) if (ko_df is not None and len(ko_df)) else None,\n",
        "            \"optknock_csv\": str(ok_csv) if (ok_df is not None and len(ok_df)) else None\n",
        "        }\n",
        "    }\n",
        "    with open(summary_json, \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    print(\"strain_optimize:\", json.dumps({\"selected\": summary[\"selected_design\"], \"base_prod\": base_prod}))\n",
        "    \"\"\")\n",
        "\n",
        "    # run inside micromamba env with env vars carrying parameters\n",
        "    env = os.environ.copy()\n",
        "    env.update({\n",
        "        \"FINISH\": str(finish),\n",
        "        \"MODEL_PATH\": str(model_path),\n",
        "        \"CFG_JSON\": json.dumps(cfg),\n",
        "        \"SOLVER\": str(cfg.get(\"solver\")),\n",
        "        \"TIME_LIMIT\": str(cfg.get(\"time_limit_s\"))\n",
        "    })\n",
        "\n",
        "    cmd = [\"/content/runs/run_001/bin/micromamba\", \"run\", \"-p\", env_path, \"python\", \"-c\", py]\n",
        "    r = subprocess.run(cmd, capture_output=True, text=True, env=env)\n",
        "    if r.stdout.strip():\n",
        "        _log(r.stdout.strip())\n",
        "    if r.returncode != 0:\n",
        "        _log(f\"strain_optimize: ERROR → {r.stderr.strip()}\")\n",
        "    else:\n",
        "        state[\"strain_optimize_summary\"]   = str(finish / \"strain_opt_summary.json\")\n",
        "        state[\"strain_optimize_fluxes\"]    = str(finish / \"strain_opt_fluxes.csv\")\n",
        "        state[\"strain_optimize_fva\"]       = str(finish / \"strain_opt_fva.csv\")\n",
        "        state[\"strain_optimize_kos\"]       = str(finish / \"strain_opt_ko_results.csv\")\n",
        "        state[\"strain_optimize_optknock\"]  = str(finish / \"strain_opt_optknock.csv\")\n",
        "        _log(\"✔ done strain_optimize\")\n",
        "    return state\n",
        "\n"
      ],
      "metadata": {
        "id": "-85VJ2ZNCysP"
      },
      "id": "-85VJ2ZNCysP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q9papcDa6xRJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9papcDa6xRJ",
        "outputId": "54aefc6c-f183-4b5b-d921-1902e753fab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/runs/run_001/micromamba/envs/retrobiocat/bin/python: No module named equilibrator_cache.cli\n"
          ]
        }
      ],
      "source": [
        "! /content/runs/run_001/bin/micromamba run -p /content/runs/run_001/micromamba/envs/retrobiocat \\\n",
        "  python -m equilibrator_cache.cli download --to /content/runs/run_001/equilibrator_cache\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Execution cell ===\n",
        "\n",
        "# sanity checks (unchanged)\n",
        "import os, urllib.request, pathlib\n",
        "\n",
        "# 1) Prepare model if needed\n",
        "model_path = pathlib.Path(\"/content/models/iML1515.xml\")\n",
        "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "if not model_path.exists():\n",
        "    urllib.request.urlretrieve(\n",
        "        \"https://github.com/opencobra/COBRA.tutorials/raw/main/src/data/iML1515.xml\",\n",
        "        str(model_path)\n",
        "    )\n",
        "print(\"✅ SBML model ready:\", model_path)\n",
        "\n",
        "# 2) Initialize state\n",
        "state = {\n",
        "    \"run_id\": \"run_001\",\n",
        "    \"workdir\": \"/content/runs/run_001\",\n",
        "    \"target_smiles\": \"COC1=C(C=CC(=C1)C=O)O\",\n",
        "    \"host\": \"Escherichia coli\",\n",
        "    \"signals\": {\"human_approved\": True},\n",
        "    \"approved\": True,  # human gate default\n",
        "    \"constraints\": {\n",
        "        \"max_steps\": 5,\n",
        "        \"net_access\": True,\n",
        "        \"uniprot\": {\"timeout_s\": 10, \"max_hits_per_query\": 3},\n",
        "        \"expanders\": [\"RetroBioCat\", \"EnzymeMap\", \"BKMS\", \"RetroRules\"],\n",
        "        \"max_search_time_s\": 15,\n",
        "    },\n",
        "    \"thermo_params\": {\n",
        "        \"pH\": 7.5,\n",
        "        \"ionic_strength\": 0.25,\n",
        "        \"pMg\": 3.0,\n",
        "        \"temperature_K\": 298.15,\n",
        "        \"pass_margin_kJ\": 0.0,\n",
        "    },\n",
        "    \"sbml_model_path\": str(model_path),\n",
        "    \"metabolite_map\": {},\n",
        "    \"simulate\": {\"mu_min\": 0.15, \"v_prod_min\": 1e-4, \"product_id\": None},\n",
        "    \"logs\": [],\n",
        "}\n",
        "\n",
        "# 3) Run sequentially (with simple guards around sequence stage)\n",
        "state[\"logs\"].clear()\n",
        "\n",
        "# upstream stages\n",
        "state = retrosynthesis_node(state)\n",
        "state = extract_node(state)\n",
        "state = add_selenzyme_links_node(state)\n",
        "state = selenzyme_rank_node(state)\n",
        "state = compound_map_node(state)\n",
        "state = thermo_node(state)\n",
        "state = rank_node(state)\n",
        "state = simulate_gem_node(state)\n",
        "state = selenzyme_rank_node(state) or state                           # (optional if you already run it)\n",
        "state = sequence_fetch_node(state, per_step=10, reviewed_first=False, timeout=12.0) or state\n",
        "state = sequence_rank_node(state) or state                             # picks 1 per step\n",
        "state = build_node(state) or state                                  # FASTA + cloning plan\n",
        "state = test_node(state) or state\n",
        "state = learn_node(state) or state\n",
        "\n",
        "# --- sequence coverage summary logger ---\n",
        "# --- sequence coverage summary logger (robust) ---\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "finish = Path(\"/content/runs/run_001/retro_finish_out\")\n",
        "\n",
        "def _safe_read(path, cols=None):\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        if cols:  # keep only needed cols if asked\n",
        "            for c in cols:\n",
        "                if c not in df.columns:\n",
        "                    df[c] = []\n",
        "            df = df[cols]\n",
        "        return df\n",
        "    except Exception:\n",
        "        return pd.DataFrame(columns=cols or [])\n",
        "\n",
        "steps = _safe_read(finish / \"steps_enzyme_plan.csv\", cols=[\"pathway_tag\",\"step_idx\"])\n",
        "cands = _safe_read(finish / \"steps_sequence_candidates.csv\", cols=[\"pathway_tag\",\"step_idx\"])\n",
        "picks = _safe_read(finish / \"steps_sequence_plan.csv\", cols=[\"pathway_tag\",\"step_idx\"])\n",
        "\n",
        "# dtype normalize\n",
        "for df in (steps, cands, picks):\n",
        "    df[\"pathway_tag\"] = df[\"pathway_tag\"].astype(str)\n",
        "    df[\"step_idx\"] = pd.to_numeric(df[\"step_idx\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "steps = steps.drop_duplicates().assign(source=\"steps\")\n",
        "cands = cands.drop_duplicates().assign(source=\"candidates\")\n",
        "picks = picks.drop_duplicates().assign(source=\"picks\")\n",
        "\n",
        "# aggregate counts\n",
        "n_cands = (\n",
        "    cands.groupby([\"pathway_tag\",\"step_idx\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"n_candidates\")\n",
        ") if len(cands) else pd.DataFrame(columns=[\"pathway_tag\",\"step_idx\",\"n_candidates\"])\n",
        "\n",
        "# merge with master step list\n",
        "rep = steps.merge(n_cands, on=[\"pathway_tag\",\"step_idx\"], how=\"left\").fillna({\"n_candidates\": 0})\n",
        "\n",
        "pick_set = set(zip(picks.pathway_tag, picks.step_idx)) if len(picks) else set()\n",
        "rep[\"picked\"] = [(pt, si) in pick_set for pt, si in zip(rep.pathway_tag, rep.step_idx)]\n",
        "\n",
        "def _reason(row):\n",
        "    if int(row[\"n_candidates\"]) == 0:\n",
        "        return \"no_candidates_found\"\n",
        "    if not bool(row[\"picked\"]):\n",
        "        return \"not_selected_in_rank\"\n",
        "    return \"ok\"\n",
        "\n",
        "rep[\"reason\"] = rep.apply(_reason, axis=1)\n",
        "rep = rep.sort_values([\"pathway_tag\", \"step_idx\"]).reset_index(drop=True)\n",
        "\n",
        "out_csv = finish / \"sequence_coverage_report.csv\"\n",
        "rep.to_csv(out_csv, index=False)\n",
        "print(f\"✅ wrote coverage summary → {out_csv}\")\n",
        "print(rep.groupby(\"reason\").size() if len(rep) else \"no rows\")\n",
        "print(rep.head(15))\n",
        "\n",
        "\n",
        "# (optional) human approval gate before export\n",
        "state = human_gate_node(state)\n",
        "state = export_node(state)\n",
        "\n",
        "# 4) Stream logs\n",
        "for l in state[\"logs\"]:\n",
        "    print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r81MBB-Y3KZr",
        "outputId": "eae1f2f9-bf58-4588-f7b1-2eb5bb5792ab"
      },
      "id": "r81MBB-Y3KZr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ SBML model ready: /content/models/iML1515.xml\n",
            "▶ start extract\n",
            "extracted pathways from pathways_solved_steps.csv (82 step rows, 23 pathways)\n",
            "✔ done extract\n",
            "▶ start add_selenzyme_links\n",
            "selenzyme_links: filled 82 URLs out of 82 rows → /content/runs/run_001/retro_finish_out/steps_enzyme_plan.csv\n",
            "✔ done add_selenzyme_links\n",
            "compound_map: wrote /content/runs/run_001/retro_finish_out/metabolite_map.csv (inchikey filled 0 / 25)\n",
            "▶ start thermo\n",
            "thermo: token IDs available for 0 / 23 tokens\n",
            "thermo: id routes: {'via_explicit_id': 0, 'via_inchikey_literal': 0, 'via_rdkit_inchikey': 0, 'via_rdkit_inchikey_only': 23, 'via_pubchem_kegg': 0, 'via_pubchem_smiles': 0, 'via_pubchem_cas': 0, 'via_match_smiles': 0, 'via_name': 0, 'unmapped': 23}\n",
            "thermo: NOTE – RDKit produced InChIKeys but none resolved to KEGG via PubChem.\n",
            "thermo: example tokens with IK but no KEGG (first 5): ['CNC(=O)C(=O)c1ccc(O)c(OC)c1', 'CNC(=O)C(O)c1ccc(O)c(OC)c1', 'COC1=C(C=CC(=C1)C=O)O', 'COc1cc(C(=O)C#N)ccc1O', 'COc1cc(C(=O)C(=O)C(=O)O)ccc1O']\n",
            "thermo: equilibrator ran in env\n",
            "thermo: steps evaluable 0 / 82\n",
            "✔ done thermo (75.1s)\n",
            "▶ start simulate_gem\n",
            "simulate_gem: results=/content/runs/run_001/retro_finish_out/sim_fba_summary.csv\n",
            "✔ done simulate_gem (18.7s)\n",
            "▶ start sequence_fetch (v4)\n",
            "sequence_fetch: wrote 744 candidates → /content/runs/run_001/retro_finish_out/steps_sequence_candidates.csv\n",
            "✔ done sequence_fetch (20.4s)\n",
            "▶ start sequence_rank\n",
            "sequence_rank: wrote 75 picks → /content/runs/run_001/retro_finish_out/steps_sequence_plan.csv\n",
            "✔ done sequence_rank (0.0s)\n",
            "▶ start build (codon-opt + Golden Gate plan)\n",
            "build: wrote 75 constructs -> sequences_codon_opt.fasta, cloning_plan.csv\n",
            "✔ done build (0.1s)\n",
            "✔ done test_node (75 constructs tested) → /content/runs/run_001/retro_finish_out/test_results.csv\n",
            "learn_node: mean activities by status = {'active': 77.3054378543772, 'inactive': 25.209849188972143}\n",
            "✔ done learn_node → learn_update.json\n",
            "✅ wrote coverage summary → /content/runs/run_001/retro_finish_out/sequence_coverage_report.csv\n",
            "reason\n",
            "no_candidates_found     7\n",
            "ok                     75\n",
            "dtype: int64\n",
            "   pathway_tag  step_idx source  n_candidates  picked               reason\n",
            "0         P001         1  steps           1.0    True                   ok\n",
            "1         P001         2  steps           1.0    True                   ok\n",
            "2         P001         3  steps           1.0    True                   ok\n",
            "3         P001         4  steps           1.0    True                   ok\n",
            "4         P001         5  steps           1.0    True                   ok\n",
            "5         P002         1  steps           1.0    True                   ok\n",
            "6         P002         2  steps           1.0    True                   ok\n",
            "7         P002         3  steps           1.0    True                   ok\n",
            "8         P002         4  steps           1.0    True                   ok\n",
            "9         P002         5  steps           0.0   False  no_candidates_found\n",
            "10        P003         1  steps           1.0    True                   ok\n",
            "11        P003         2  steps           1.0    True                   ok\n",
            "12        P003         3  steps           1.0    True                   ok\n",
            "13        P003         4  steps           0.0   False  no_candidates_found\n",
            "14        P004         1  steps           1.0    True                   ok\n",
            "{'node': 'retrosynthesis', 'ts': '2025-10-24T19:44:00Z', 'cmd': '/content/runs/run_001/bin/micromamba run -p /content/runs/run_001/micromamba/envs/retrobiocat python /content/runs/run_001/bin/rbc2_runner.py', 'rc': 0, 'out_log': '/content/runs/run_001/logs/_rbc2_runner.out.log', 'err_log': '/content/runs/run_001/logs/_rbc2_runner.err.log'}\n",
            "▶ start extract\n",
            "extracted pathways from pathways_solved_steps.csv (82 step rows, 23 pathways)\n",
            "✔ done extract\n",
            "▶ start add_selenzyme_links\n",
            "selenzyme_links: filled 82 URLs out of 82 rows → /content/runs/run_001/retro_finish_out/steps_enzyme_plan.csv\n",
            "✔ done add_selenzyme_links\n",
            "selenzyme_rank: seed_uniprots populated for 0 / 82 steps\n",
            "compound_map: wrote /content/runs/run_001/retro_finish_out/metabolite_map.csv (inchikey filled 0 / 25)\n",
            "▶ start thermo\n",
            "thermo: token IDs available for 0 / 23 tokens\n",
            "thermo: id routes: {'via_explicit_id': 0, 'via_inchikey_literal': 0, 'via_rdkit_inchikey': 0, 'via_rdkit_inchikey_only': 23, 'via_pubchem_kegg': 0, 'via_pubchem_smiles': 0, 'via_pubchem_cas': 0, 'via_match_smiles': 0, 'via_name': 0, 'unmapped': 23}\n",
            "thermo: NOTE – RDKit produced InChIKeys but none resolved to KEGG via PubChem.\n",
            "thermo: example tokens with IK but no KEGG (first 5): ['CNC(=O)C(=O)c1ccc(O)c(OC)c1', 'CNC(=O)C(O)c1ccc(O)c(OC)c1', 'COC1=C(C=CC(=C1)C=O)O', 'COc1cc(C(=O)C#N)ccc1O', 'COc1cc(C(=O)C(=O)C(=O)O)ccc1O']\n",
            "thermo: equilibrator ran in env\n",
            "thermo: steps evaluable 0 / 82\n",
            "✔ done thermo (75.1s)\n",
            "▶ start rank\n",
            "ranked pathways (already computed with thermo)\n",
            "ranked_final=/content/runs/run_001/retro_finish_out/pathways_ranked_final.csv\n",
            "✔ done rank (0.0s)\n",
            "▶ start simulate_gem\n",
            "simulate_gem: results=/content/runs/run_001/retro_finish_out/sim_fba_summary.csv\n",
            "selenzyme_rank: seed_uniprots populated for 0 / 82 steps\n",
            "▶ start sequence_fetch (v4)\n",
            "sequence_fetch: wrote 744 candidates → /content/runs/run_001/retro_finish_out/steps_sequence_candidates.csv\n",
            "✔ done sequence_fetch (20.4s)\n",
            "▶ start sequence_rank\n",
            "sequence_rank: wrote 75 picks → /content/runs/run_001/retro_finish_out/steps_sequence_plan.csv\n",
            "✔ done sequence_rank (0.0s)\n",
            "▶ start build (codon-opt + Golden Gate plan)\n",
            "build: wrote 75 constructs -> sequences_codon_opt.fasta, cloning_plan.csv\n",
            "✔ done build (0.1s)\n",
            "human_gate: approval file ready at /content/runs/run_001/retro_finish_out/_HUMAN_GATE.md\n",
            "human_gate: approved=True\n",
            "export_node: exported 5 artifacts\n",
            "export_node: manifest=/content/runs/run_001/retro_export/manifest.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/runs/run_001/bin/micromamba install -y -p /content/runs/run_001/micromamba/envs/retrobiocat -c conda-forge cobra\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuc1Z0rjbOfB",
        "outputId": "87b152a2-bb60-41e0-8708-7e35a9878d4b"
      },
      "id": "wuc1Z0rjbOfB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\n",
            "conda-forge/linux-64  ⣾  \n",
            "conda-forge/noarch    ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.3s\n",
            "conda-forge/linux-64   1%\n",
            "conda-forge/noarch     1%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\n",
            "conda-forge/linux-64   2%\n",
            "conda-forge/noarch     3%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\n",
            "conda-forge/linux-64   4%\n",
            "conda-forge/noarch     5%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\n",
            "conda-forge/linux-64   4%\n",
            "conda-forge/noarch     7%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\n",
            "conda-forge/linux-64   6%\n",
            "conda-forge/noarch    10%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\n",
            "conda-forge/linux-64   7%\n",
            "conda-forge/noarch    13%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\n",
            "conda-forge/linux-64  10%\n",
            "conda-forge/noarch    18%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\n",
            "conda-forge/linux-64  10%\n",
            "conda-forge/noarch    20%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n",
            "conda-forge/linux-64  12%\n",
            "conda-forge/noarch    24%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\n",
            "conda-forge/linux-64  14%\n",
            "conda-forge/noarch    27%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\n",
            "conda-forge/linux-64  16%\n",
            "conda-forge/noarch    30%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\n",
            "conda-forge/linux-64  16%\n",
            "conda-forge/noarch    32%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\n",
            "conda-forge/linux-64  17%\n",
            "conda-forge/noarch    34%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\n",
            "conda-forge/linux-64  19%\n",
            "conda-forge/noarch    38%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
            "conda-forge/linux-64  20%\n",
            "conda-forge/noarch    39%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
            "conda-forge/linux-64  21%\n",
            "conda-forge/noarch    41%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
            "conda-forge/linux-64  22%\n",
            "conda-forge/noarch    45%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
            "conda-forge/linux-64  23%\n",
            "conda-forge/noarch    47%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
            "conda-forge/linux-64  23%\n",
            "conda-forge/noarch    47%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
            "conda-forge/linux-64  24%\n",
            "conda-forge/noarch    48%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
            "conda-forge/linux-64  24%\n",
            "conda-forge/noarch    49%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
            "conda-forge/linux-64  25%\n",
            "conda-forge/noarch    50%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
            "conda-forge/linux-64  25%\n",
            "conda-forge/noarch    50%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
            "conda-forge/linux-64  26%\n",
            "conda-forge/noarch    51%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
            "conda-forge/linux-64  26%\n",
            "conda-forge/noarch    52%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
            "conda-forge/linux-64  26%\n",
            "conda-forge/noarch    53%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
            "conda-forge/linux-64  26%\n",
            "conda-forge/noarch    54%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
            "conda-forge/linux-64  27%\n",
            "conda-forge/noarch    55%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
            "conda-forge/linux-64  28%\n",
            "conda-forge/noarch    57%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
            "conda-forge/linux-64  28%\n",
            "conda-forge/noarch    58%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
            "conda-forge/linux-64  29%\n",
            "conda-forge/noarch    59%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
            "conda-forge/linux-64  30%\n",
            "conda-forge/noarch    61%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
            "conda-forge/linux-64  32%\n",
            "conda-forge/noarch    64%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
            "conda-forge/linux-64  33%\n",
            "conda-forge/noarch    66%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
            "conda-forge/linux-64  33%\n",
            "conda-forge/noarch    67%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
            "conda-forge/linux-64  33%\n",
            "conda-forge/noarch    69%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.9s\n",
            "conda-forge/linux-64  34%\n",
            "conda-forge/noarch    70%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
            "conda-forge/linux-64  35%\n",
            "conda-forge/noarch    71%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
            "conda-forge/linux-64  36%\n",
            "conda-forge/noarch    74%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.2s\n",
            "conda-forge/linux-64  37%\n",
            "conda-forge/noarch    75%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.3s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    78%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.4s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.6s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.7s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.0s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.2s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.3s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.5s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.6s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.7s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.8s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.9s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.0s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.1s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.2s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.3s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.4s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.5s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.6s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.7s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.8s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.9s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.0s\n",
            "conda-forge/linux-64  41%\n",
            "conda-forge/noarch    83%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.1s\n",
            "conda-forge/linux-64  44%\n",
            "conda-forge/noarch    89%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.2s\n",
            "conda-forge/linux-64  45%\n",
            "conda-forge/noarch    96%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                \n",
            "[+] 7.3s\n",
            "conda-forge/linux-64  49%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.4s\n",
            "conda-forge/linux-64  49%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.5s\n",
            "conda-forge/linux-64  55%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.6s\n",
            "conda-forge/linux-64  60%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.7s\n",
            "conda-forge/linux-64  63%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.8s\n",
            "conda-forge/linux-64  68%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.9s\n",
            "conda-forge/linux-64  72%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.0s\n",
            "conda-forge/linux-64  76%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.1s\n",
            "conda-forge/linux-64  80%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.2s\n",
            "conda-forge/linux-64  82%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.3s\n",
            "conda-forge/linux-64  86%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.4s\n",
            "conda-forge/linux-64  90%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.5s\n",
            "conda-forge/linux-64  95%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.6s\n",
            "conda-forge/linux-64  98%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.7s\n",
            "conda-forge/linux-64  99%\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                              \n",
            "[+] 8.8s\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n",
            "Pinned packages:\n",
            "\n",
            "  - python=3.10\n",
            "\n",
            "\n",
            "Transaction\n",
            "\n",
            "  Prefix: /content/runs/run_001/micromamba/envs/retrobiocat\n",
            "\n",
            "  Updating specs:\n",
            "\n",
            "   - cobra\n",
            "\n",
            "\n",
            "  Package                  Version  Build            Channel          Size\n",
            "────────────────────────────────────────────────────────────────────────────\n",
            "  Install:\n",
            "────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "  \u001b[32m+ annotated-types    \u001b[0m      0.7.0  pyhd8ed1ab_1     conda-forge      18kB\n",
            "  \u001b[32m+ anyio              \u001b[0m     4.11.0  pyhcf101f3_0     conda-forge     138kB\n",
            "  \u001b[32m+ appdirs            \u001b[0m      1.4.4  pyhd8ed1ab_1     conda-forge      15kB\n",
            "  \u001b[32m+ certifi            \u001b[0m  2025.10.5  pyhd8ed1ab_0     conda-forge     160kB\n",
            "  \u001b[32m+ cobra              \u001b[0m     0.29.1  pyhd8ed1ab_1     conda-forge       1MB\n",
            "  \u001b[32m+ cpython            \u001b[0m    3.10.19  py310hd8ed1ab_2  conda-forge      50kB\n",
            "  \u001b[32m+ depinfo            \u001b[0m      2.2.0  pyhd8ed1ab_1     conda-forge      21kB\n",
            "  \u001b[32m+ diskcache          \u001b[0m      5.6.3  pyhd8ed1ab_1     conda-forge      40kB\n",
            "  \u001b[32m+ exceptiongroup     \u001b[0m      1.3.0  pyhd8ed1ab_0     conda-forge      21kB\n",
            "  \u001b[32m+ future             \u001b[0m      1.0.0  pyhd8ed1ab_2     conda-forge     365kB\n",
            "  \u001b[32m+ glpk               \u001b[0m        5.0  h445213a_0       conda-forge       1MB\n",
            "  \u001b[32m+ gmp                \u001b[0m      6.3.0  hac33072_2       conda-forge     460kB\n",
            "  \u001b[32m+ gmpy2              \u001b[0m      2.2.1  py310h63ebcad_1  conda-forge     204kB\n",
            "  \u001b[32m+ h11                \u001b[0m     0.16.0  pyhd8ed1ab_0     conda-forge      38kB\n",
            "  \u001b[32m+ h2                 \u001b[0m      4.3.0  pyhcf101f3_0     conda-forge      96kB\n",
            "  \u001b[32m+ hpack              \u001b[0m      4.1.0  pyhd8ed1ab_0     conda-forge      31kB\n",
            "  \u001b[32m+ httpcore           \u001b[0m      1.0.9  pyh29332c3_0     conda-forge      49kB\n",
            "  \u001b[32m+ httpx              \u001b[0m     0.28.1  pyhd8ed1ab_0     conda-forge      63kB\n",
            "  \u001b[32m+ hyperframe         \u001b[0m      6.1.0  pyhd8ed1ab_0     conda-forge      17kB\n",
            "  \u001b[32m+ idna               \u001b[0m       3.11  pyhd8ed1ab_0     conda-forge      51kB\n",
            "  \u001b[32m+ importlib-metadata \u001b[0m      8.7.0  pyhe01879c_1     conda-forge      35kB\n",
            "  \u001b[32m+ importlib_metadata \u001b[0m      8.7.0  h40b2b14_1       conda-forge      22kB\n",
            "  \u001b[32m+ importlib_resources\u001b[0m      6.5.2  pyhd8ed1ab_0     conda-forge      34kB\n",
            "  \u001b[32m+ libflint           \u001b[0m      3.2.2  h754cb6e_0       conda-forge      22MB\n",
            "  \u001b[32m+ markdown-it-py     \u001b[0m      4.0.0  pyhd8ed1ab_0     conda-forge      65kB\n",
            "  \u001b[32m+ mdurl              \u001b[0m      0.1.2  pyhd8ed1ab_1     conda-forge      14kB\n",
            "  \u001b[32m+ mpc                \u001b[0m      1.3.1  h24ddda3_1       conda-forge     117kB\n",
            "  \u001b[32m+ mpfr               \u001b[0m      4.2.1  h90cbb55_3       conda-forge     635kB\n",
            "  \u001b[32m+ mpmath             \u001b[0m      1.3.0  pyhd8ed1ab_1     conda-forge     440kB\n",
            "  \u001b[32m+ optlang            \u001b[0m      1.8.3  pyhd8ed1ab_0     conda-forge      94kB\n",
            "  \u001b[32m+ pydantic           \u001b[0m     2.12.3  pyh3cfb1c2_0     conda-forge     320kB\n",
            "  \u001b[32m+ pydantic-core      \u001b[0m     2.41.4  py310hd8f68c5_0  conda-forge       2MB\n",
            "  \u001b[32m+ pygments           \u001b[0m     2.19.2  pyhd8ed1ab_0     conda-forge     889kB\n",
            "  \u001b[32m+ python-libsbml     \u001b[0m     5.20.5  py310h1a6248f_0  conda-forge       6MB\n",
            "  \u001b[32m+ rich               \u001b[0m     14.2.0  pyhcf101f3_0     conda-forge     201kB\n",
            "  \u001b[32m+ ruamel.yaml        \u001b[0m    0.18.16  py310h7c4b9e2_0  conda-forge     205kB\n",
            "  \u001b[32m+ ruamel.yaml.clib   \u001b[0m     0.2.14  py310h7c4b9e2_0  conda-forge     140kB\n",
            "  \u001b[32m+ sniffio            \u001b[0m      1.3.1  pyhd8ed1ab_1     conda-forge      15kB\n",
            "  \u001b[32m+ swiglpk            \u001b[0m     5.0.12  py310ha75aee5_0  conda-forge     104kB\n",
            "  \u001b[32m+ symengine          \u001b[0m     0.14.0  h064106a_1       conda-forge      15MB\n",
            "  \u001b[32m+ sympy              \u001b[0m     1.14.0  pyh2585a3b_105   conda-forge       5MB\n",
            "  \u001b[32m+ typing-inspection  \u001b[0m      0.4.2  pyhd8ed1ab_0     conda-forge      19kB\n",
            "  \u001b[32m+ zipp               \u001b[0m     3.23.0  pyhd8ed1ab_0     conda-forge      23kB\n",
            "\n",
            "  Summary:\n",
            "\n",
            "  Install: 43 packages\n",
            "\n",
            "  Total download: 56MB\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "\n",
            "\n",
            "Transaction starting\n",
            "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
            "Downloading        5%\n",
            "Extracting         0%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
            "Downloading      100%\n",
            "Extracting         0%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\n",
            "Downloading  (5)   0%\n",
            "Extracting         0%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpydantic-core                                        1.9MB @   6.0MB/s  0.2s\n",
            "[+] 0.3s\n",
            "Downloading  (5)   7%\n",
            "Extracting         0%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpython-libsbml                                       5.9MB @  10.1MB/s  0.2s\n",
            "sympy                                                4.6MB @   9.2MB/s  0.2s\n",
            "[+] 0.4s\n",
            "Downloading  (5)  35%\n",
            "Extracting   (1)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpygments                                           889.3kB @  ??.?MB/s  0.1s\n",
            "glpk                                                 1.0MB @  ??.?MB/s  0.1s\n",
            "[+] 0.5s\n",
            "Downloading  (5)  47%\n",
            "Extracting   (4)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gcobra                                                1.1MB @   1.7MB/s  0.2s\n",
            "gmp                                                460.1kB @  ??.?MB/s  0.1s\n",
            "mpmath                                             439.7kB @  ??.?MB/s  0.1s\n",
            "mpfr                                               634.8kB @   4.8MB/s  0.1s\n",
            "[+] 0.6s\n",
            "Downloading  (5)  73%\n",
            "Extracting   (8)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gsymengine                                           14.6MB @  23.8MB/s  0.5s\n",
            "future                                             364.6kB @  ??.?MB/s  0.1s\n",
            "pydantic                                           320.0kB @  ??.?MB/s  0.1s\n",
            "ruamel.yaml                                        204.9kB @  ??.?MB/s  0.1s\n",
            "gmpy2                                              204.1kB @  ??.?MB/s  0.1s\n",
            "[+] 0.7s\n",
            "Downloading  (5)  88%\n",
            "Extracting  (12)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Grich                                               200.8kB @  ??.?MB/s  0.1s\n",
            "certifi                                            160.2kB @  ??.?MB/s  0.1s\n",
            "anyio                                              138.2kB @  ??.?MB/s  0.1s\n",
            "ruamel.yaml.clib                                   140.0kB @  ??.?MB/s  0.1s\n",
            "[+] 0.8s\n",
            "Downloading  (5)  94%\n",
            "Extracting  (17)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gmpc                                                116.8kB @  ??.?MB/s  0.1s\n",
            "h2                                                  96.0kB @  ??.?MB/s  0.1s\n",
            "libflint                                            21.9MB @  25.7MB/s  0.7s\n",
            "optlang                                             94.1kB @  ??.?MB/s  0.1s\n",
            "swiglpk                                            104.4kB @  ??.?MB/s  0.1s\n",
            "[+] 0.9s\n",
            "Downloading  (5) 100%\n",
            "Extracting  (20)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gmarkdown-it-py                                      64.7kB @  ??.?MB/s  0.1s\n",
            "httpx                                               63.1kB @  ??.?MB/s  0.1s\n",
            "idna                                                50.7kB @  ??.?MB/s  0.1s\n",
            "cpython                                             50.2kB @  ??.?MB/s  0.1s\n",
            "httpcore                                            49.5kB @  ??.?MB/s  0.1s\n",
            "h11                                                 37.7kB @  ??.?MB/s  0.0s\n",
            "diskcache                                           40.1kB @  ??.?MB/s  0.1s\n",
            "importlib-metadata                                  34.6kB @  ??.?MB/s  0.1s\n",
            "importlib_resources                                 33.8kB @  ??.?MB/s  0.1s\n",
            "zipp                                                23.0kB @  ??.?MB/s  0.0s\n",
            "[+] 1.0s\n",
            "Downloading  (5) 100%\n",
            "Extracting  (30)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ghpack                                               30.7kB @  ??.?MB/s  0.1s\n",
            "exceptiongroup                                      21.3kB @  ??.?MB/s  0.1s\n",
            "annotated-types                                     18.1kB @  ??.?MB/s  0.1s\n",
            "[+] 1.1s\n",
            "Downloading  (5) 100%\n",
            "Extracting  (33)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gdepinfo                                             20.6kB @  ??.?MB/s  0.1s\n",
            "importlib_metadata                                  22.1kB @  ??.?MB/s  0.1s\n",
            "hyperframe                                          17.4kB @  ??.?MB/s  0.1s\n",
            "sniffio                                             15.0kB @ 263.0kB/s  0.1s\n",
            "typing-inspection                                   18.8kB @ 124.2kB/s  0.2s\n",
            "mdurl                                               14.5kB @ 202.2kB/s  0.1s\n",
            "[+] 1.2s\n",
            "Downloading  (1) 100%\n",
            "Extracting  (38)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gappdirs                                             14.8kB @ 105.3kB/s  0.1s\n",
            "[+] 1.3s\n",
            "Downloading      100%\n",
            "Extracting  (35)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\n",
            "Downloading      100%\n",
            "Extracting  (33)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\n",
            "Downloading      100%\n",
            "Extracting  (31)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\n",
            "Downloading      100%\n",
            "Extracting  (30)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
            "Downloading      100%\n",
            "Extracting  (27)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
            "Downloading      100%\n",
            "Extracting  (26)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
            "Downloading      100%\n",
            "Extracting  (24)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
            "Downloading      100%\n",
            "Extracting  (23)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
            "Downloading      100%\n",
            "Extracting  (21)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
            "Downloading      100%\n",
            "Extracting  (21)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
            "Downloading      100%\n",
            "Extracting  (21)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
            "Downloading      100%\n",
            "Extracting  (20)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
            "Downloading      100%\n",
            "Extracting  (18)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
            "Downloading      100%\n",
            "Extracting  (18)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
            "Downloading      100%\n",
            "Extracting  (18)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
            "Downloading      100%\n",
            "Extracting  (17)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
            "Downloading      100%\n",
            "Extracting  (16)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
            "Downloading      100%\n",
            "Extracting  (15)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
            "Downloading      100%\n",
            "Extracting  (14)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
            "Downloading      100%\n",
            "Extracting  (13)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
            "Downloading      100%\n",
            "Extracting  (13)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
            "Downloading      100%\n",
            "Extracting  (12)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
            "Downloading      100%\n",
            "Extracting  (11)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
            "Downloading      100%\n",
            "Extracting   (9)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
            "Downloading      100%\n",
            "Extracting   (8)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
            "Downloading      100%\n",
            "Extracting   (4)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.9s\n",
            "Downloading      100%\n",
            "Extracting   (1)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25hLinking pydantic-core-2.41.4-py310hd8f68c5_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [pydantic-core-2.41.4-py310hd8f68c5_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/pydantic_core/__init__.py\n",
            "    - lib/python3.10/site-packages/pydantic_core/__pycache__/__init__.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/pydantic_core/__pycache__/core_schema.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/pydantic_core/_pydantic_core.cpython-310-x86_64-linux-gnu.so\n",
            "    - lib/python3.10/site-packages/pydantic_core/_pydantic_core.pyi\n",
            "    - lib/python3.10/site-packages/pydantic_core/core_schema.py\n",
            "    - lib/python3.10/site-packages/pydantic_core/py.typed\n",
            "    - lib/python3.10/site-packages/pydantic_core-2.41.4.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/pydantic_core-2.41.4.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/pydantic_core-2.41.4.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/pydantic_core-2.41.4.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/pydantic_core-2.41.4.dist-info/licenses/LICENSE\n",
            "Linking python-libsbml-5.20.5-py310h1a6248f_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [python-libsbml-5.20.5-py310h1a6248f_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/libsbml/__init__.py\n",
            "    - lib/python3.10/site-packages/libsbml/__pycache__/__init__.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/libsbml/_libsbml.cpython-310-x86_64-linux-gnu.so\n",
            "    - lib/python3.10/site-packages/python_libsbml-5.20.5.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/python_libsbml-5.20.5.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/python_libsbml-5.20.5.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/python_libsbml-5.20.5.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/python_libsbml-5.20.5.dist-info/licenses/LICENSE.html\n",
            "    - lib/python3.10/site-packages/python_libsbml-5.20.5.dist-info/licenses/LICENSE.txt\n",
            "    - lib/python3.10/site-packages/python_libsbml-5.20.5.dist-info/top_level.txt\n",
            "Linking gmp-6.3.0-hac33072_2\n",
            "Linking ruamel.yaml.clib-0.2.14-py310h7c4b9e2_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [ruamel.yaml.clib-0.2.14-py310h7c4b9e2_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/_ruamel_yaml.cpython-310-x86_64-linux-gnu.so\n",
            "Linking mpfr-4.2.1-h90cbb55_3\n",
            "Linking glpk-5.0-h445213a_0\n",
            "Linking ruamel.yaml-0.18.16-py310h7c4b9e2_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [ruamel.yaml-0.18.16-py310h7c4b9e2_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__init__.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/__init__.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/anchor.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/comments.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/compat.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/composer.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/configobjwalker.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/constructor.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/cyaml.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/docinfo.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/dumper.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/emitter.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/error.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/events.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/loader.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/main.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/mergevalue.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/nodes.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/parser.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/reader.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/representer.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/resolver.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/scalarbool.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/scalarfloat.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/scalarint.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/scalarstring.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/scanner.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/serializer.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/tag.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/timestamp.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/tokens.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/__pycache__/util.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/anchor.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/comments.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/compat.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/composer.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/configobjwalker.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/constructor.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/cyaml.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/docinfo.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/dumper.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/emitter.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/error.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/events.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/loader.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/main.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/mergevalue.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/nodes.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/parser.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/py.typed\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/reader.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/representer.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/resolver.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/scalarbool.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/scalarfloat.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/scalarint.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/scalarstring.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/scanner.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/serializer.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/tag.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/timestamp.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/tokens.py\n",
            "    - lib/python3.10/site-packages/ruamel/yaml/util.py\n",
            "Linking mpc-1.3.1-h24ddda3_1\n",
            "Linking libflint-3.2.2-h754cb6e_0\n",
            "Linking swiglpk-5.0.12-py310ha75aee5_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [swiglpk-5.0.12-py310ha75aee5_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/swiglpk-5.0.12.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/swiglpk-5.0.12.dist-info/LICENSE\n",
            "    - lib/python3.10/site-packages/swiglpk-5.0.12.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/swiglpk-5.0.12.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/swiglpk-5.0.12.dist-info/REQUESTED\n",
            "    - lib/python3.10/site-packages/swiglpk-5.0.12.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/swiglpk-5.0.12.dist-info/top_level.txt\n",
            "    - lib/python3.10/site-packages/swiglpk/__init__.py\n",
            "    - lib/python3.10/site-packages/swiglpk/__pycache__/__init__.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/swiglpk/__pycache__/swiglpk.cpython-310.pyc\n",
            "    - lib/python3.10/site-packages/swiglpk/_swiglpk.cpython-310-x86_64-linux-gnu.so\n",
            "    - lib/python3.10/site-packages/swiglpk/glpk.i\n",
            "    - lib/python3.10/site-packages/swiglpk/swiglpk.py\n",
            "Linking gmpy2-2.2.1-py310h63ebcad_1\n",
            "Linking symengine-0.14.0-h064106a_1\n",
            "Linking typing-inspection-0.4.2-pyhd8ed1ab_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [typing-inspection-0.4.2-pyhd8ed1ab_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/typing_inspection-0.4.2.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/typing_inspection-0.4.2.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/typing_inspection-0.4.2.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/typing_inspection-0.4.2.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/typing_inspection-0.4.2.dist-info/licenses/LICENSE\n",
            "    - lib/python3.10/site-packages/typing_inspection/__init__.py\n",
            "    - lib/python3.10/site-packages/typing_inspection/introspection.py\n",
            "    - lib/python3.10/site-packages/typing_inspection/py.typed\n",
            "    - lib/python3.10/site-packages/typing_inspection/typing_objects.py\n",
            "    - lib/python3.10/site-packages/typing_inspection/typing_objects.pyi\n",
            "Linking appdirs-1.4.4-pyhd8ed1ab_1\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [appdirs-1.4.4-pyhd8ed1ab_1] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/appdirs-1.4.4.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/appdirs-1.4.4.dist-info/LICENSE.txt\n",
            "    - lib/python3.10/site-packages/appdirs-1.4.4.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/appdirs-1.4.4.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/appdirs-1.4.4.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/appdirs-1.4.4.dist-info/top_level.txt\n",
            "    - lib/python3.10/site-packages/appdirs.py\n",
            "Linking diskcache-5.6.3-pyhd8ed1ab_1\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [diskcache-5.6.3-pyhd8ed1ab_1] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/diskcache-5.6.3.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/diskcache-5.6.3.dist-info/LICENSE\n",
            "    - lib/python3.10/site-packages/diskcache-5.6.3.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/diskcache-5.6.3.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/diskcache-5.6.3.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/diskcache-5.6.3.dist-info/top_level.txt\n",
            "    - lib/python3.10/site-packages/diskcache/__init__.py\n",
            "    - lib/python3.10/site-packages/diskcache/cli.py\n",
            "    - lib/python3.10/site-packages/diskcache/core.py\n",
            "    - lib/python3.10/site-packages/diskcache/djangocache.py\n",
            "    - lib/python3.10/site-packages/diskcache/fanout.py\n",
            "    - lib/python3.10/site-packages/diskcache/persistent.py\n",
            "    - lib/python3.10/site-packages/diskcache/recipes.py\n",
            "Linking future-1.0.0-pyhd8ed1ab_2\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [future-1.0.0-pyhd8ed1ab_2] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/future-1.0.0.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/future-1.0.0.dist-info/LICENSE.txt\n",
            "    - lib/python3.10/site-packages/future-1.0.0.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/future-1.0.0.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/future-1.0.0.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/future-1.0.0.dist-info/entry_points.txt\n",
            "    - lib/python3.10/site-packages/future-1.0.0.dist-info/top_level.txt\n",
            "    - lib/python3.10/site-packages/future/__init__.py\n",
            "    - lib/python3.10/site-packages/future/backports/__init__.py\n",
            "    - lib/python3.10/site-packages/future/backports/_markupbase.py\n",
            "    - lib/python3.10/site-packages/future/backports/datetime.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/__init__.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/_encoded_words.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/_header_value_parser.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/_parseaddr.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/_policybase.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/base64mime.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/charset.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/encoders.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/errors.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/feedparser.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/generator.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/header.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/headerregistry.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/iterators.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/message.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/mime/__init__.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/mime/application.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/mime/audio.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/mime/base.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/mime/image.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/mime/message.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/mime/multipart.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/mime/nonmultipart.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/mime/text.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/parser.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/policy.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/quoprimime.py\n",
            "    - lib/python3.10/site-packages/future/backports/email/utils.py\n",
            "    - lib/python3.10/site-packages/future/backports/html/__init__.py\n",
            "    - lib/python3.10/site-packages/future/backports/html/entities.py\n",
            "    - lib/python3.10/site-packages/future/backports/html/parser.py\n",
            "    - lib/python3.10/site-packages/future/backports/http/__init__.py\n",
            "    - lib/python3.10/site-packages/future/backports/http/client.py\n",
            "    - lib/python3.10/site-packages/future/backports/http/cookiejar.py\n",
            "    - lib/python3.10/site-packages/future/backports/http/cookies.py\n",
            "    - lib/python3.10/site-packages/future/backports/http/server.py\n",
            "    - lib/python3.10/site-packages/future/backports/misc.py\n",
            "    - lib/python3.10/site-packages/future/backports/socket.py\n",
            "    - lib/python3.10/site-packages/future/backports/socketserver.py\n",
            "    - lib/python3.10/site-packages/future/backports/test/__init__.py\n",
            "    - lib/python3.10/site-packages/future/backports/test/badcert.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/badkey.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/dh512.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/https_svn_python_org_root.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/keycert.passwd.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/keycert.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/keycert2.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/nokia.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/nullbytecert.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/nullcert.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/pystone.py\n",
            "    - lib/python3.10/site-packages/future/backports/test/sha256.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/ssl_cert.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/ssl_key.passwd.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/ssl_key.pem\n",
            "    - lib/python3.10/site-packages/future/backports/test/ssl_servers.py\n",
            "    - lib/python3.10/site-packages/future/backports/test/support.py\n",
            "    - lib/python3.10/site-packages/future/backports/total_ordering.py\n",
            "    - lib/python3.10/site-packages/future/backports/urllib/__init__.py\n",
            "    - lib/python3.10/site-packages/future/backports/urllib/error.py\n",
            "    - lib/python3.10/site-packages/future/backports/urllib/parse.py\n",
            "    - lib/python3.10/site-packages/future/backports/urllib/request.py\n",
            "    - lib/python3.10/site-packages/future/backports/urllib/response.py\n",
            "    - lib/python3.10/site-packages/future/backports/urllib/robotparser.py\n",
            "    - lib/python3.10/site-packages/future/backports/xmlrpc/__init__.py\n",
            "    - lib/python3.10/site-packages/future/backports/xmlrpc/client.py\n",
            "    - lib/python3.10/site-packages/future/backports/xmlrpc/server.py\n",
            "    - lib/python3.10/site-packages/future/builtins/__init__.py\n",
            "    - lib/python3.10/site-packages/future/builtins/disabled.py\n",
            "    - lib/python3.10/site-packages/future/builtins/iterators.py\n",
            "    - lib/python3.10/site-packages/future/builtins/misc.py\n",
            "    - lib/python3.10/site-packages/future/builtins/new_min_max.py\n",
            "    - lib/python3.10/site-packages/future/builtins/newnext.py\n",
            "    - lib/python3.10/site-packages/future/builtins/newround.py\n",
            "    - lib/python3.10/site-packages/future/builtins/newsuper.py\n",
            "    - lib/python3.10/site-packages/future/moves/__init__.py\n",
            "    - lib/python3.10/site-packages/future/moves/_dummy_thread.py\n",
            "    - lib/python3.10/site-packages/future/moves/_markupbase.py\n",
            "    - lib/python3.10/site-packages/future/moves/_thread.py\n",
            "    - lib/python3.10/site-packages/future/moves/builtins.py\n",
            "    - lib/python3.10/site-packages/future/moves/collections.py\n",
            "    - lib/python3.10/site-packages/future/moves/configparser.py\n",
            "    - lib/python3.10/site-packages/future/moves/copyreg.py\n",
            "    - lib/python3.10/site-packages/future/moves/dbm/__init__.py\n",
            "    - lib/python3.10/site-packages/future/moves/dbm/dumb.py\n",
            "    - lib/python3.10/site-packages/future/moves/dbm/gnu.py\n",
            "    - lib/python3.10/site-packages/future/moves/dbm/ndbm.py\n",
            "    - lib/python3.10/site-packages/future/moves/html/__init__.py\n",
            "    - lib/python3.10/site-packages/future/moves/html/entities.py\n",
            "    - lib/python3.10/site-packages/future/moves/html/parser.py\n",
            "    - lib/python3.10/site-packages/future/moves/http/__init__.py\n",
            "    - lib/python3.10/site-packages/future/moves/http/client.py\n",
            "    - lib/python3.10/site-packages/future/moves/http/cookiejar.py\n",
            "    - lib/python3.10/site-packages/future/moves/http/cookies.py\n",
            "    - lib/python3.10/site-packages/future/moves/http/server.py\n",
            "    - lib/python3.10/site-packages/future/moves/itertools.py\n",
            "    - lib/python3.10/site-packages/future/moves/multiprocessing.py\n",
            "    - lib/python3.10/site-packages/future/moves/pickle.py\n",
            "    - lib/python3.10/site-packages/future/moves/queue.py\n",
            "    - lib/python3.10/site-packages/future/moves/reprlib.py\n",
            "    - lib/python3.10/site-packages/future/moves/socketserver.py\n",
            "    - lib/python3.10/site-packages/future/moves/subprocess.py\n",
            "    - lib/python3.10/site-packages/future/moves/sys.py\n",
            "    - lib/python3.10/site-packages/future/moves/test/__init__.py\n",
            "    - lib/python3.10/site-packages/future/moves/test/support.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/__init__.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/colorchooser.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/commondialog.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/constants.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/dialog.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/dnd.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/filedialog.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/font.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/messagebox.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/scrolledtext.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/simpledialog.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/tix.py\n",
            "    - lib/python3.10/site-packages/future/moves/tkinter/ttk.py\n",
            "    - lib/python3.10/site-packages/future/moves/urllib/__init__.py\n",
            "    - lib/python3.10/site-packages/future/moves/urllib/error.py\n",
            "    - lib/python3.10/site-packages/future/moves/urllib/parse.py\n",
            "    - lib/python3.10/site-packages/future/moves/urllib/request.py\n",
            "    - lib/python3.10/site-packages/future/moves/urllib/response.py\n",
            "    - lib/python3.10/site-packages/future/moves/urllib/robotparser.py\n",
            "    - lib/python3.10/site-packages/future/moves/winreg.py\n",
            "    - lib/python3.10/site-packages/future/moves/xmlrpc/__init__.py\n",
            "    - lib/python3.10/site-packages/future/moves/xmlrpc/client.py\n",
            "    - lib/python3.10/site-packages/future/moves/xmlrpc/server.py\n",
            "    - lib/python3.10/site-packages/future/standard_library/__init__.py\n",
            "    - lib/python3.10/site-packages/future/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/future/tests/base.py\n",
            "    - lib/python3.10/site-packages/future/types/__init__.py\n",
            "    - lib/python3.10/site-packages/future/types/newbytes.py\n",
            "    - lib/python3.10/site-packages/future/types/newdict.py\n",
            "    - lib/python3.10/site-packages/future/types/newint.py\n",
            "    - lib/python3.10/site-packages/future/types/newlist.py\n",
            "    - lib/python3.10/site-packages/future/types/newmemoryview.py\n",
            "    - lib/python3.10/site-packages/future/types/newobject.py\n",
            "    - lib/python3.10/site-packages/future/types/newopen.py\n",
            "    - lib/python3.10/site-packages/future/types/newrange.py\n",
            "    - lib/python3.10/site-packages/future/types/newstr.py\n",
            "    - lib/python3.10/site-packages/future/utils/__init__.py\n",
            "    - lib/python3.10/site-packages/future/utils/surrogateescape.py\n",
            "    - lib/python3.10/site-packages/libfuturize/__init__.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixer_util.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/__init__.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_UserDict.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_absolute_import.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_add__future__imports_except_unicode_literals.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_basestring.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_bytes.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_cmp.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_division.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_division_safe.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_execfile.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_future_builtins.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_future_standard_library.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_future_standard_library_urllib.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_input.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_metaclass.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_next_call.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_object.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_oldstr_wrap.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_order___future__imports.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_print.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_print_with_import.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_raise.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_remove_old__future__imports.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_unicode_keep_u.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_unicode_literals_import.py\n",
            "    - lib/python3.10/site-packages/libfuturize/fixes/fix_xrange_with_import.py\n",
            "    - lib/python3.10/site-packages/libfuturize/main.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/__init__.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/__init__.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/feature_base.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_add_all__future__imports.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_add_all_future_builtins.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_add_future_standard_library_import.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_annotations.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_division.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_features.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_fullargspec.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_future_builtins.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_getcwd.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_imports.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_imports2.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_kwargs.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_memoryview.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_metaclass.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_newstyle.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_next.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_printfunction.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_raise.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_raise_.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_throw.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/fixes/fix_unpacking.py\n",
            "    - lib/python3.10/site-packages/libpasteurize/main.py\n",
            "    - lib/python3.10/site-packages/past/__init__.py\n",
            "    - lib/python3.10/site-packages/past/builtins/__init__.py\n",
            "    - lib/python3.10/site-packages/past/builtins/misc.py\n",
            "    - lib/python3.10/site-packages/past/builtins/noniterators.py\n",
            "    - lib/python3.10/site-packages/past/translation/__init__.py\n",
            "    - lib/python3.10/site-packages/past/types/__init__.py\n",
            "    - lib/python3.10/site-packages/past/types/basestring.py\n",
            "    - lib/python3.10/site-packages/past/types/olddict.py\n",
            "    - lib/python3.10/site-packages/past/types/oldstr.py\n",
            "    - lib/python3.10/site-packages/past/utils/__init__.py\n",
            "    - bin/futurize\n",
            "    - bin/pasteurize\n",
            "Linking pygments-2.19.2-pyhd8ed1ab_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [pygments-2.19.2-pyhd8ed1ab_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/pygments-2.19.2.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/pygments-2.19.2.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/pygments-2.19.2.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/pygments-2.19.2.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/pygments-2.19.2.dist-info/entry_points.txt\n",
            "    - lib/python3.10/site-packages/pygments-2.19.2.dist-info/licenses/AUTHORS\n",
            "    - lib/python3.10/site-packages/pygments-2.19.2.dist-info/licenses/LICENSE\n",
            "    - lib/python3.10/site-packages/pygments/__init__.py\n",
            "    - lib/python3.10/site-packages/pygments/__main__.py\n",
            "    - lib/python3.10/site-packages/pygments/cmdline.py\n",
            "    - lib/python3.10/site-packages/pygments/console.py\n",
            "    - lib/python3.10/site-packages/pygments/filter.py\n",
            "    - lib/python3.10/site-packages/pygments/filters/__init__.py\n",
            "    - lib/python3.10/site-packages/pygments/formatter.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/__init__.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/_mapping.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/bbcode.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/groff.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/html.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/img.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/irc.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/latex.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/other.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/pangomarkup.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/rtf.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/svg.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/terminal.py\n",
            "    - lib/python3.10/site-packages/pygments/formatters/terminal256.py\n",
            "    - lib/python3.10/site-packages/pygments/lexer.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/__init__.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_ada_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_asy_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_cl_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_cocoa_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_csound_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_css_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_googlesql_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_julia_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_lasso_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_lilypond_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_lua_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_luau_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_mapping.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_mql_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_mysql_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_openedge_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_php_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_postgres_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_qlik_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_scheme_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_scilab_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_sourcemod_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_sql_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_stan_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_stata_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_tsql_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_usd_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_vbscript_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/_vim_builtins.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/actionscript.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ada.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/agile.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/algebra.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ambient.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/amdgpu.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ampl.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/apdlexer.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/apl.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/archetype.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/arrow.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/arturo.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/asc.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/asm.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/asn1.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/automation.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/bare.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/basic.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/bdd.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/berry.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/bibtex.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/blueprint.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/boa.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/bqn.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/business.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/c_cpp.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/c_like.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/capnproto.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/carbon.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/cddl.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/chapel.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/clean.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/codeql.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/comal.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/compiled.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/configs.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/console.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/cplint.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/crystal.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/csound.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/css.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/d.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/dalvik.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/data.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/dax.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/devicetree.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/diff.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/dns.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/dotnet.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/dsls.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/dylan.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ecl.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/eiffel.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/elm.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/elpi.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/email.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/erlang.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/esoteric.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ezhil.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/factor.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/fantom.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/felix.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/fift.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/floscript.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/forth.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/fortran.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/foxpro.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/freefem.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/func.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/functional.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/futhark.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/gcodelexer.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/gdscript.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/gleam.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/go.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/grammar_notation.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/graph.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/graphics.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/graphql.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/graphviz.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/gsql.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/hare.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/haskell.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/haxe.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/hdl.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/hexdump.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/html.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/idl.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/igor.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/inferno.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/installers.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/int_fiction.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/iolang.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/j.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/javascript.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/jmespath.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/jslt.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/json5.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/jsonnet.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/jsx.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/julia.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/jvm.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/kuin.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/kusto.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ldap.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/lean.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/lilypond.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/lisp.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/macaulay2.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/make.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/maple.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/markup.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/math.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/matlab.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/maxima.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/meson.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/mime.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/minecraft.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/mips.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ml.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/modeling.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/modula2.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/mojo.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/monte.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/mosel.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ncl.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/nimrod.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/nit.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/nix.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/numbair.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/oberon.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/objective.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ooc.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/openscad.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/other.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/parasail.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/parsers.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/pascal.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/pawn.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/pddl.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/perl.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/phix.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/php.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/pointless.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/pony.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/praat.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/procfile.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/prolog.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/promql.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/prql.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ptx.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/python.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/q.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/qlik.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/qvt.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/r.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/rdf.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/rebol.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/rego.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/resource.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ride.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/rita.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/rnc.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/roboconf.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/robotframework.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ruby.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/rust.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/sas.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/savi.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/scdoc.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/scripting.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/sgf.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/shell.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/sieve.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/slash.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/smalltalk.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/smithy.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/smv.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/snobol.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/solidity.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/soong.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/sophia.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/special.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/spice.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/sql.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/srcinfo.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/stata.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/supercollider.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/tablegen.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/tact.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/tal.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/tcl.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/teal.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/templates.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/teraterm.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/testing.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/text.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/textedit.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/textfmts.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/theorem.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/thingsdb.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/tlb.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/tls.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/tnt.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/trafficscript.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/typoscript.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/typst.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/ul4.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/unicon.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/urbi.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/usd.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/varnish.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/verification.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/verifpal.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/vip.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/vyper.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/web.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/webassembly.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/webidl.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/webmisc.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/wgsl.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/whiley.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/wowtoc.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/wren.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/x10.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/xorg.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/yang.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/yara.py\n",
            "    - lib/python3.10/site-packages/pygments/lexers/zig.py\n",
            "    - lib/python3.10/site-packages/pygments/modeline.py\n",
            "    - lib/python3.10/site-packages/pygments/plugin.py\n",
            "    - lib/python3.10/site-packages/pygments/regexopt.py\n",
            "    - lib/python3.10/site-packages/pygments/scanner.py\n",
            "    - lib/python3.10/site-packages/pygments/sphinxext.py\n",
            "    - lib/python3.10/site-packages/pygments/style.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/__init__.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/_mapping.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/abap.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/algol.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/algol_nu.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/arduino.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/autumn.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/borland.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/bw.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/coffee.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/colorful.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/default.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/dracula.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/emacs.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/friendly.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/friendly_grayscale.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/fruity.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/gh_dark.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/gruvbox.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/igor.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/inkpot.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/lightbulb.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/lilypond.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/lovelace.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/manni.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/material.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/monokai.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/murphy.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/native.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/nord.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/onedark.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/paraiso_dark.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/paraiso_light.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/pastie.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/perldoc.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/rainbow_dash.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/rrt.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/sas.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/solarized.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/staroffice.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/stata_dark.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/stata_light.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/tango.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/trac.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/vim.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/vs.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/xcode.py\n",
            "    - lib/python3.10/site-packages/pygments/styles/zenburn.py\n",
            "    - lib/python3.10/site-packages/pygments/token.py\n",
            "    - lib/python3.10/site-packages/pygments/unistring.py\n",
            "    - lib/python3.10/site-packages/pygments/util.py\n",
            "    - bin/pygmentize\n",
            "Linking annotated-types-0.7.0-pyhd8ed1ab_1\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [annotated-types-0.7.0-pyhd8ed1ab_1] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/annotated_types-0.7.0.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/annotated_types-0.7.0.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/annotated_types-0.7.0.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/annotated_types-0.7.0.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/annotated_types-0.7.0.dist-info/licenses/LICENSE\n",
            "    - lib/python3.10/site-packages/annotated_types/__init__.py\n",
            "    - lib/python3.10/site-packages/annotated_types/py.typed\n",
            "    - lib/python3.10/site-packages/annotated_types/test_cases.py\n",
            "Linking mdurl-0.1.2-pyhd8ed1ab_1\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [mdurl-0.1.2-pyhd8ed1ab_1] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/mdurl-0.1.2.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/mdurl-0.1.2.dist-info/LICENSE\n",
            "    - lib/python3.10/site-packages/mdurl-0.1.2.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/mdurl-0.1.2.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/mdurl-0.1.2.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/mdurl/__init__.py\n",
            "    - lib/python3.10/site-packages/mdurl/_decode.py\n",
            "    - lib/python3.10/site-packages/mdurl/_encode.py\n",
            "    - lib/python3.10/site-packages/mdurl/_format.py\n",
            "    - lib/python3.10/site-packages/mdurl/_parse.py\n",
            "    - lib/python3.10/site-packages/mdurl/_url.py\n",
            "    - lib/python3.10/site-packages/mdurl/py.typed\n",
            "Linking zipp-3.23.0-pyhd8ed1ab_0\n",
            "Linking certifi-2025.10.5-pyhd8ed1ab_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [certifi-2025.10.5-pyhd8ed1ab_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/certifi-2025.10.5.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/certifi-2025.10.5.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/certifi-2025.10.5.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/certifi-2025.10.5.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/certifi-2025.10.5.dist-info/top_level.txt\n",
            "    - lib/python3.10/site-packages/certifi/__init__.py\n",
            "    - lib/python3.10/site-packages/certifi/__main__.py\n",
            "    - lib/python3.10/site-packages/certifi/cacert.pem\n",
            "    - lib/python3.10/site-packages/certifi/core.py\n",
            "    - lib/python3.10/site-packages/certifi/py.typed\n",
            "Linking idna-3.11-pyhd8ed1ab_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [idna-3.11-pyhd8ed1ab_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/idna-3.11.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/idna-3.11.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/idna-3.11.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/idna-3.11.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/idna-3.11.dist-info/licenses/LICENSE.md\n",
            "    - lib/python3.10/site-packages/idna/__init__.py\n",
            "    - lib/python3.10/site-packages/idna/codec.py\n",
            "    - lib/python3.10/site-packages/idna/compat.py\n",
            "    - lib/python3.10/site-packages/idna/core.py\n",
            "    - lib/python3.10/site-packages/idna/idnadata.py\n",
            "    - lib/python3.10/site-packages/idna/intranges.py\n",
            "    - lib/python3.10/site-packages/idna/package_data.py\n",
            "    - lib/python3.10/site-packages/idna/py.typed\n",
            "    - lib/python3.10/site-packages/idna/uts46data.py\n",
            "Linking h11-0.16.0-pyhd8ed1ab_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [h11-0.16.0-pyhd8ed1ab_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/h11-0.16.0.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/h11-0.16.0.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/h11-0.16.0.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/h11-0.16.0.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/h11-0.16.0.dist-info/licenses/LICENSE.txt\n",
            "    - lib/python3.10/site-packages/h11-0.16.0.dist-info/top_level.txt\n",
            "    - lib/python3.10/site-packages/h11/__init__.py\n",
            "    - lib/python3.10/site-packages/h11/_abnf.py\n",
            "    - lib/python3.10/site-packages/h11/_connection.py\n",
            "    - lib/python3.10/site-packages/h11/_events.py\n",
            "    - lib/python3.10/site-packages/h11/_headers.py\n",
            "    - lib/python3.10/site-packages/h11/_readers.py\n",
            "    - lib/python3.10/site-packages/h11/_receivebuffer.py\n",
            "    - lib/python3.10/site-packages/h11/_state.py\n",
            "    - lib/python3.10/site-packages/h11/_util.py\n",
            "    - lib/python3.10/site-packages/h11/_version.py\n",
            "    - lib/python3.10/site-packages/h11/_writers.py\n",
            "    - lib/python3.10/site-packages/h11/py.typed\n",
            "Linking hpack-4.1.0-pyhd8ed1ab_0\n",
            "Linking hyperframe-6.1.0-pyhd8ed1ab_0\n",
            "Linking sniffio-1.3.1-pyhd8ed1ab_1\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [sniffio-1.3.1-pyhd8ed1ab_1] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/sniffio-1.3.1.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/sniffio-1.3.1.dist-info/LICENSE\n",
            "    - lib/python3.10/site-packages/sniffio-1.3.1.dist-info/LICENSE.APACHE2\n",
            "    - lib/python3.10/site-packages/sniffio-1.3.1.dist-info/LICENSE.MIT\n",
            "    - lib/python3.10/site-packages/sniffio-1.3.1.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/sniffio-1.3.1.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/sniffio-1.3.1.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/sniffio-1.3.1.dist-info/top_level.txt\n",
            "    - lib/python3.10/site-packages/sniffio/__init__.py\n",
            "    - lib/python3.10/site-packages/sniffio/_impl.py\n",
            "    - lib/python3.10/site-packages/sniffio/_tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sniffio/_tests/test_sniffio.py\n",
            "    - lib/python3.10/site-packages/sniffio/_version.py\n",
            "    - lib/python3.10/site-packages/sniffio/py.typed\n",
            "Linking exceptiongroup-1.3.0-pyhd8ed1ab_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [exceptiongroup-1.3.0-pyhd8ed1ab_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/exceptiongroup-1.3.0.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/exceptiongroup-1.3.0.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/exceptiongroup-1.3.0.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/exceptiongroup-1.3.0.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/exceptiongroup-1.3.0.dist-info/licenses/LICENSE\n",
            "    - lib/python3.10/site-packages/exceptiongroup/__init__.py\n",
            "    - lib/python3.10/site-packages/exceptiongroup/_catch.py\n",
            "    - lib/python3.10/site-packages/exceptiongroup/_exceptions.py\n",
            "    - lib/python3.10/site-packages/exceptiongroup/_formatting.py\n",
            "    - lib/python3.10/site-packages/exceptiongroup/_suppress.py\n",
            "    - lib/python3.10/site-packages/exceptiongroup/_version.py\n",
            "    - lib/python3.10/site-packages/exceptiongroup/py.typed\n",
            "Linking mpmath-1.3.0-pyhd8ed1ab_1\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [mpmath-1.3.0-pyhd8ed1ab_1] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/mpmath-1.3.0.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/mpmath-1.3.0.dist-info/LICENSE\n",
            "    - lib/python3.10/site-packages/mpmath-1.3.0.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/mpmath-1.3.0.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/mpmath-1.3.0.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/mpmath-1.3.0.dist-info/top_level.txt\n",
            "    - lib/python3.10/site-packages/mpmath/__init__.py\n",
            "    - lib/python3.10/site-packages/mpmath/calculus/__init__.py\n",
            "    - lib/python3.10/site-packages/mpmath/calculus/approximation.py\n",
            "    - lib/python3.10/site-packages/mpmath/calculus/calculus.py\n",
            "    - lib/python3.10/site-packages/mpmath/calculus/differentiation.py\n",
            "    - lib/python3.10/site-packages/mpmath/calculus/extrapolation.py\n",
            "    - lib/python3.10/site-packages/mpmath/calculus/inverselaplace.py\n",
            "    - lib/python3.10/site-packages/mpmath/calculus/odes.py\n",
            "    - lib/python3.10/site-packages/mpmath/calculus/optimization.py\n",
            "    - lib/python3.10/site-packages/mpmath/calculus/polynomials.py\n",
            "    - lib/python3.10/site-packages/mpmath/calculus/quadrature.py\n",
            "    - lib/python3.10/site-packages/mpmath/ctx_base.py\n",
            "    - lib/python3.10/site-packages/mpmath/ctx_fp.py\n",
            "    - lib/python3.10/site-packages/mpmath/ctx_iv.py\n",
            "    - lib/python3.10/site-packages/mpmath/ctx_mp.py\n",
            "    - lib/python3.10/site-packages/mpmath/ctx_mp_python.py\n",
            "    - lib/python3.10/site-packages/mpmath/function_docs.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/__init__.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/bessel.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/elliptic.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/expintegrals.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/factorials.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/functions.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/hypergeometric.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/orthogonal.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/qfunctions.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/rszeta.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/signals.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/theta.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/zeta.py\n",
            "    - lib/python3.10/site-packages/mpmath/functions/zetazeros.py\n",
            "    - lib/python3.10/site-packages/mpmath/identification.py\n",
            "    - lib/python3.10/site-packages/mpmath/libmp/__init__.py\n",
            "    - lib/python3.10/site-packages/mpmath/libmp/backend.py\n",
            "    - lib/python3.10/site-packages/mpmath/libmp/gammazeta.py\n",
            "    - lib/python3.10/site-packages/mpmath/libmp/libelefun.py\n",
            "    - lib/python3.10/site-packages/mpmath/libmp/libhyper.py\n",
            "    - lib/python3.10/site-packages/mpmath/libmp/libintmath.py\n",
            "    - lib/python3.10/site-packages/mpmath/libmp/libmpc.py\n",
            "    - lib/python3.10/site-packages/mpmath/libmp/libmpf.py\n",
            "    - lib/python3.10/site-packages/mpmath/libmp/libmpi.py\n",
            "    - lib/python3.10/site-packages/mpmath/math2.py\n",
            "    - lib/python3.10/site-packages/mpmath/matrices/__init__.py\n",
            "    - lib/python3.10/site-packages/mpmath/matrices/calculus.py\n",
            "    - lib/python3.10/site-packages/mpmath/matrices/eigen.py\n",
            "    - lib/python3.10/site-packages/mpmath/matrices/eigen_symmetric.py\n",
            "    - lib/python3.10/site-packages/mpmath/matrices/linalg.py\n",
            "    - lib/python3.10/site-packages/mpmath/matrices/matrices.py\n",
            "    - lib/python3.10/site-packages/mpmath/rational.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/extratest_gamma.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/extratest_zeta.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/runtests.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_basic_ops.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_bitwise.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_calculus.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_compatibility.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_convert.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_diff.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_division.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_eigen.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_eigen_symmetric.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_elliptic.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_fp.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_functions.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_functions2.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_gammazeta.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_hp.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_identify.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_interval.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_levin.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_linalg.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_matrices.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_mpmath.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_ode.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_pickle.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_power.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_quad.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_rootfinding.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_special.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_str.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_summation.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_trig.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/test_visualization.py\n",
            "    - lib/python3.10/site-packages/mpmath/tests/torture.py\n",
            "    - lib/python3.10/site-packages/mpmath/usertools.py\n",
            "    - lib/python3.10/site-packages/mpmath/visualization.py\n",
            "Linking cpython-3.10.19-py310hd8ed1ab_2\n",
            "Linking pydantic-2.12.3-pyh3cfb1c2_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [pydantic-2.12.3-pyh3cfb1c2_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/pydantic-2.12.3.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/pydantic-2.12.3.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/pydantic-2.12.3.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/pydantic-2.12.3.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/pydantic-2.12.3.dist-info/licenses/LICENSE\n",
            "    - lib/python3.10/site-packages/pydantic/__init__.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/__init__.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_config.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_core_metadata.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_core_utils.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_dataclasses.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_decorators.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_decorators_v1.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_discriminated_union.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_docs_extraction.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_fields.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_forward_ref.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_generics.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_git.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_import_utils.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_internal_dataclass.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_known_annotated_metadata.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_mock_val_ser.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_model_construction.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_namespace_utils.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_repr.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_schema_gather.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_schema_generation_shared.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_serializers.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_signature.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_typing_extra.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_utils.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_validate_call.py\n",
            "    - lib/python3.10/site-packages/pydantic/_internal/_validators.py\n",
            "    - lib/python3.10/site-packages/pydantic/_migration.py\n",
            "    - lib/python3.10/site-packages/pydantic/alias_generators.py\n",
            "    - lib/python3.10/site-packages/pydantic/aliases.py\n",
            "    - lib/python3.10/site-packages/pydantic/annotated_handlers.py\n",
            "    - lib/python3.10/site-packages/pydantic/class_validators.py\n",
            "    - lib/python3.10/site-packages/pydantic/color.py\n",
            "    - lib/python3.10/site-packages/pydantic/config.py\n",
            "    - lib/python3.10/site-packages/pydantic/dataclasses.py\n",
            "    - lib/python3.10/site-packages/pydantic/datetime_parse.py\n",
            "    - lib/python3.10/site-packages/pydantic/decorator.py\n",
            "    - lib/python3.10/site-packages/pydantic/deprecated/__init__.py\n",
            "    - lib/python3.10/site-packages/pydantic/deprecated/class_validators.py\n",
            "    - lib/python3.10/site-packages/pydantic/deprecated/config.py\n",
            "    - lib/python3.10/site-packages/pydantic/deprecated/copy_internals.py\n",
            "    - lib/python3.10/site-packages/pydantic/deprecated/decorator.py\n",
            "    - lib/python3.10/site-packages/pydantic/deprecated/json.py\n",
            "    - lib/python3.10/site-packages/pydantic/deprecated/parse.py\n",
            "    - lib/python3.10/site-packages/pydantic/deprecated/tools.py\n",
            "    - lib/python3.10/site-packages/pydantic/env_settings.py\n",
            "    - lib/python3.10/site-packages/pydantic/error_wrappers.py\n",
            "    - lib/python3.10/site-packages/pydantic/errors.py\n",
            "    - lib/python3.10/site-packages/pydantic/experimental/__init__.py\n",
            "    - lib/python3.10/site-packages/pydantic/experimental/arguments_schema.py\n",
            "    - lib/python3.10/site-packages/pydantic/experimental/missing_sentinel.py\n",
            "    - lib/python3.10/site-packages/pydantic/experimental/pipeline.py\n",
            "    - lib/python3.10/site-packages/pydantic/fields.py\n",
            "    - lib/python3.10/site-packages/pydantic/functional_serializers.py\n",
            "    - lib/python3.10/site-packages/pydantic/functional_validators.py\n",
            "    - lib/python3.10/site-packages/pydantic/generics.py\n",
            "    - lib/python3.10/site-packages/pydantic/json.py\n",
            "    - lib/python3.10/site-packages/pydantic/json_schema.py\n",
            "    - lib/python3.10/site-packages/pydantic/main.py\n",
            "    - lib/python3.10/site-packages/pydantic/mypy.py\n",
            "    - lib/python3.10/site-packages/pydantic/networks.py\n",
            "    - lib/python3.10/site-packages/pydantic/parse.py\n",
            "    - lib/python3.10/site-packages/pydantic/plugin/__init__.py\n",
            "    - lib/python3.10/site-packages/pydantic/plugin/_loader.py\n",
            "    - lib/python3.10/site-packages/pydantic/plugin/_schema_validator.py\n",
            "    - lib/python3.10/site-packages/pydantic/py.typed\n",
            "    - lib/python3.10/site-packages/pydantic/root_model.py\n",
            "    - lib/python3.10/site-packages/pydantic/schema.py\n",
            "    - lib/python3.10/site-packages/pydantic/tools.py\n",
            "    - lib/python3.10/site-packages/pydantic/type_adapter.py\n",
            "    - lib/python3.10/site-packages/pydantic/types.py\n",
            "    - lib/python3.10/site-packages/pydantic/typing.py\n",
            "    - lib/python3.10/site-packages/pydantic/utils.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/__init__.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/_hypothesis_plugin.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/annotated_types.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/class_validators.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/color.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/config.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/dataclasses.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/datetime_parse.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/decorator.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/env_settings.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/error_wrappers.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/errors.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/fields.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/generics.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/json.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/main.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/mypy.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/networks.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/parse.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/py.typed\n",
            "    - lib/python3.10/site-packages/pydantic/v1/schema.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/tools.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/types.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/typing.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/utils.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/validators.py\n",
            "    - lib/python3.10/site-packages/pydantic/v1/version.py\n",
            "    - lib/python3.10/site-packages/pydantic/validate_call_decorator.py\n",
            "    - lib/python3.10/site-packages/pydantic/validators.py\n",
            "    - lib/python3.10/site-packages/pydantic/version.py\n",
            "    - lib/python3.10/site-packages/pydantic/warnings.py\n",
            "Linking markdown-it-py-4.0.0-pyhd8ed1ab_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [markdown-it-py-4.0.0-pyhd8ed1ab_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/markdown_it/__init__.py\n",
            "    - lib/python3.10/site-packages/markdown_it/_compat.py\n",
            "    - lib/python3.10/site-packages/markdown_it/_punycode.py\n",
            "    - lib/python3.10/site-packages/markdown_it/cli/__init__.py\n",
            "    - lib/python3.10/site-packages/markdown_it/cli/parse.py\n",
            "    - lib/python3.10/site-packages/markdown_it/common/__init__.py\n",
            "    - lib/python3.10/site-packages/markdown_it/common/entities.py\n",
            "    - lib/python3.10/site-packages/markdown_it/common/html_blocks.py\n",
            "    - lib/python3.10/site-packages/markdown_it/common/html_re.py\n",
            "    - lib/python3.10/site-packages/markdown_it/common/normalize_url.py\n",
            "    - lib/python3.10/site-packages/markdown_it/common/utils.py\n",
            "    - lib/python3.10/site-packages/markdown_it/helpers/__init__.py\n",
            "    - lib/python3.10/site-packages/markdown_it/helpers/parse_link_destination.py\n",
            "    - lib/python3.10/site-packages/markdown_it/helpers/parse_link_label.py\n",
            "    - lib/python3.10/site-packages/markdown_it/helpers/parse_link_title.py\n",
            "    - lib/python3.10/site-packages/markdown_it/main.py\n",
            "    - lib/python3.10/site-packages/markdown_it/parser_block.py\n",
            "    - lib/python3.10/site-packages/markdown_it/parser_core.py\n",
            "    - lib/python3.10/site-packages/markdown_it/parser_inline.py\n",
            "    - lib/python3.10/site-packages/markdown_it/port.yaml\n",
            "    - lib/python3.10/site-packages/markdown_it/presets/__init__.py\n",
            "    - lib/python3.10/site-packages/markdown_it/presets/commonmark.py\n",
            "    - lib/python3.10/site-packages/markdown_it/presets/default.py\n",
            "    - lib/python3.10/site-packages/markdown_it/presets/zero.py\n",
            "    - lib/python3.10/site-packages/markdown_it/py.typed\n",
            "    - lib/python3.10/site-packages/markdown_it/renderer.py\n",
            "    - lib/python3.10/site-packages/markdown_it/ruler.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/__init__.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/blockquote.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/code.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/fence.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/heading.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/hr.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/html_block.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/lheading.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/list.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/paragraph.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/reference.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/state_block.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_block/table.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_core/__init__.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_core/block.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_core/inline.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_core/linkify.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_core/normalize.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_core/replacements.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_core/smartquotes.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_core/state_core.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_core/text_join.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/__init__.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/autolink.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/backticks.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/balance_pairs.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/emphasis.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/entity.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/escape.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/fragments_join.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/html_inline.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/image.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/link.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/linkify.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/newline.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/state_inline.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/strikethrough.py\n",
            "    - lib/python3.10/site-packages/markdown_it/rules_inline/text.py\n",
            "    - lib/python3.10/site-packages/markdown_it/token.py\n",
            "    - lib/python3.10/site-packages/markdown_it/tree.py\n",
            "    - lib/python3.10/site-packages/markdown_it/utils.py\n",
            "    - lib/python3.10/site-packages/markdown_it_py-4.0.0.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/markdown_it_py-4.0.0.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/markdown_it_py-4.0.0.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/markdown_it_py-4.0.0.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/markdown_it_py-4.0.0.dist-info/entry_points.txt\n",
            "    - lib/python3.10/site-packages/markdown_it_py-4.0.0.dist-info/licenses/LICENSE\n",
            "    - lib/python3.10/site-packages/markdown_it_py-4.0.0.dist-info/licenses/LICENSE.markdown-it\n",
            "    - bin/markdown-it\n",
            "Linking importlib-metadata-8.7.0-pyhe01879c_1\n",
            "Linking importlib_resources-6.5.2-pyhd8ed1ab_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [importlib_resources-6.5.2-pyhd8ed1ab_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/importlib_resources-6.5.2.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/importlib_resources-6.5.2.dist-info/LICENSE\n",
            "    - lib/python3.10/site-packages/importlib_resources-6.5.2.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/importlib_resources-6.5.2.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/importlib_resources-6.5.2.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/importlib_resources-6.5.2.dist-info/top_level.txt\n",
            "    - lib/python3.10/site-packages/importlib_resources/__init__.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/_adapters.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/_common.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/_functional.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/_itertools.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/abc.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/compat/__init__.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/compat/py39.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/future/__init__.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/future/adapters.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/py.typed\n",
            "    - lib/python3.10/site-packages/importlib_resources/readers.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/simple.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/_path.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/compat/__init__.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/compat/py312.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/compat/py39.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/test_compatibilty_files.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/test_contents.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/test_custom.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/test_files.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/test_functional.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/test_open.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/test_path.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/test_read.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/test_reader.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/test_resource.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/test_util.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/util.py\n",
            "    - lib/python3.10/site-packages/importlib_resources/tests/zip.py\n",
            "Linking h2-4.3.0-pyhcf101f3_0\n",
            "Linking anyio-4.11.0-pyhcf101f3_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [anyio-4.11.0-pyhcf101f3_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/anyio/__init__.py\n",
            "    - lib/python3.10/site-packages/anyio/_backends/__init__.py\n",
            "    - lib/python3.10/site-packages/anyio/_backends/_asyncio.py\n",
            "    - lib/python3.10/site-packages/anyio/_backends/_trio.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/__init__.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_asyncio_selector_thread.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_contextmanagers.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_eventloop.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_exceptions.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_fileio.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_resources.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_signals.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_sockets.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_streams.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_subprocesses.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_synchronization.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_tasks.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_tempfile.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_testing.py\n",
            "    - lib/python3.10/site-packages/anyio/_core/_typedattr.py\n",
            "    - lib/python3.10/site-packages/anyio/abc/__init__.py\n",
            "    - lib/python3.10/site-packages/anyio/abc/_eventloop.py\n",
            "    - lib/python3.10/site-packages/anyio/abc/_resources.py\n",
            "    - lib/python3.10/site-packages/anyio/abc/_sockets.py\n",
            "    - lib/python3.10/site-packages/anyio/abc/_streams.py\n",
            "    - lib/python3.10/site-packages/anyio/abc/_subprocesses.py\n",
            "    - lib/python3.10/site-packages/anyio/abc/_tasks.py\n",
            "    - lib/python3.10/site-packages/anyio/abc/_testing.py\n",
            "    - lib/python3.10/site-packages/anyio/from_thread.py\n",
            "    - lib/python3.10/site-packages/anyio/lowlevel.py\n",
            "    - lib/python3.10/site-packages/anyio/py.typed\n",
            "    - lib/python3.10/site-packages/anyio/pytest_plugin.py\n",
            "    - lib/python3.10/site-packages/anyio/streams/__init__.py\n",
            "    - lib/python3.10/site-packages/anyio/streams/buffered.py\n",
            "    - lib/python3.10/site-packages/anyio/streams/file.py\n",
            "    - lib/python3.10/site-packages/anyio/streams/memory.py\n",
            "    - lib/python3.10/site-packages/anyio/streams/stapled.py\n",
            "    - lib/python3.10/site-packages/anyio/streams/text.py\n",
            "    - lib/python3.10/site-packages/anyio/streams/tls.py\n",
            "    - lib/python3.10/site-packages/anyio/to_interpreter.py\n",
            "    - lib/python3.10/site-packages/anyio/to_process.py\n",
            "    - lib/python3.10/site-packages/anyio/to_thread.py\n",
            "    - lib/python3.10/site-packages/anyio-4.11.0.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/anyio-4.11.0.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/anyio-4.11.0.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/anyio-4.11.0.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/anyio-4.11.0.dist-info/entry_points.txt\n",
            "    - lib/python3.10/site-packages/anyio-4.11.0.dist-info/licenses/LICENSE\n",
            "    - lib/python3.10/site-packages/anyio-4.11.0.dist-info/top_level.txt\n",
            "Linking sympy-1.14.0-pyh2585a3b_105\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [sympy-1.14.0-pyh2585a3b_105] The following files were already present in the environment:\n",
            "    - share/man/man1/isympy.1\n",
            "    - lib/python3.10/site-packages/isympy.py\n",
            "    - lib/python3.10/site-packages/sympy-1.14.0.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/sympy-1.14.0.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/sympy-1.14.0.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/sympy-1.14.0.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/sympy-1.14.0.dist-info/entry_points.txt\n",
            "    - lib/python3.10/site-packages/sympy-1.14.0.dist-info/licenses/AUTHORS\n",
            "    - lib/python3.10/site-packages/sympy-1.14.0.dist-info/licenses/LICENSE\n",
            "    - lib/python3.10/site-packages/sympy-1.14.0.dist-info/top_level.txt\n",
            "    - lib/python3.10/site-packages/sympy/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/abc.py\n",
            "    - lib/python3.10/site-packages/sympy/algebras/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/algebras/quaternion.py\n",
            "    - lib/python3.10/site-packages/sympy/algebras/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/algebras/tests/test_quaternion.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/ask.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/ask_generated.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/assume.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/cnf.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/facts.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/handlers/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/handlers/calculus.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/handlers/common.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/handlers/matrices.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/handlers/ntheory.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/handlers/order.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/handlers/sets.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/lra_satask.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/predicates/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/predicates/calculus.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/predicates/common.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/predicates/matrices.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/predicates/ntheory.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/predicates/order.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/predicates/sets.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/refine.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/relation/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/relation/binrel.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/relation/equality.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/satask.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/sathandlers.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/tests/test_assumptions_2.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/tests/test_context.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/tests/test_matrices.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/tests/test_query.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/tests/test_refine.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/tests/test_rel_queries.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/tests/test_satask.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/tests/test_sathandlers.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/tests/test_wrapper.py\n",
            "    - lib/python3.10/site-packages/sympy/assumptions/wrapper.py\n",
            "    - lib/python3.10/site-packages/sympy/benchmarks/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/benchmarks/bench_discrete_log.py\n",
            "    - lib/python3.10/site-packages/sympy/benchmarks/bench_meijerint.py\n",
            "    - lib/python3.10/site-packages/sympy/benchmarks/bench_symbench.py\n",
            "    - lib/python3.10/site-packages/sympy/calculus/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/calculus/accumulationbounds.py\n",
            "    - lib/python3.10/site-packages/sympy/calculus/euler.py\n",
            "    - lib/python3.10/site-packages/sympy/calculus/finite_diff.py\n",
            "    - lib/python3.10/site-packages/sympy/calculus/singularities.py\n",
            "    - lib/python3.10/site-packages/sympy/calculus/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/calculus/tests/test_accumulationbounds.py\n",
            "    - lib/python3.10/site-packages/sympy/calculus/tests/test_euler.py\n",
            "    - lib/python3.10/site-packages/sympy/calculus/tests/test_finite_diff.py\n",
            "    - lib/python3.10/site-packages/sympy/calculus/tests/test_singularities.py\n",
            "    - lib/python3.10/site-packages/sympy/calculus/tests/test_util.py\n",
            "    - lib/python3.10/site-packages/sympy/calculus/util.py\n",
            "    - lib/python3.10/site-packages/sympy/categories/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/categories/baseclasses.py\n",
            "    - lib/python3.10/site-packages/sympy/categories/diagram_drawing.py\n",
            "    - lib/python3.10/site-packages/sympy/categories/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/categories/tests/test_baseclasses.py\n",
            "    - lib/python3.10/site-packages/sympy/categories/tests/test_drawing.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/abstract_nodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/algorithms.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/approximations.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/ast.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/cfunctions.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/cnodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/cutils.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/cxxnodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/fnodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/futils.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/matrix_nodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/numpy_nodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/pynodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/pyutils.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/rewriting.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/scipy_nodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_abstract_nodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_algorithms.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_applications.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_approximations.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_ast.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_cfunctions.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_cnodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_cxxnodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_fnodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_matrix_nodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_numpy_nodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_pynodes.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_pyutils.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_rewriting.py\n",
            "    - lib/python3.10/site-packages/sympy/codegen/tests/test_scipy_nodes.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/coset_table.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/fp_groups.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/free_groups.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/galois.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/generators.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/graycode.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/group_constructs.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/group_numbers.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/homomorphisms.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/named_groups.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/partitions.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/pc_groups.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/perm_groups.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/permutations.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/polyhedron.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/prufer.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/rewritingsystem.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/rewritingsystem_fsm.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/schur_number.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/subsets.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tensor_can.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_coset_table.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_fp_groups.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_free_groups.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_galois.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_generators.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_graycode.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_group_constructs.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_group_numbers.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_homomorphisms.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_named_groups.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_partitions.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_pc_groups.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_perm_groups.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_permutations.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_polyhedron.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_prufer.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_rewriting.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_schur_number.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_subsets.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_tensor_can.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_testutil.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/tests/test_util.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/testutil.py\n",
            "    - lib/python3.10/site-packages/sympy/combinatorics/util.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/delta.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/expr_with_intlimits.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/expr_with_limits.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/gosper.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/guess.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/products.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/summations.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/tests/test_delta.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/tests/test_gosper.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/tests/test_guess.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/tests/test_products.py\n",
            "    - lib/python3.10/site-packages/sympy/concrete/tests/test_sums_products.py\n",
            "    - lib/python3.10/site-packages/sympy/conftest.py\n",
            "    - lib/python3.10/site-packages/sympy/core/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/core/_print_helpers.py\n",
            "    - lib/python3.10/site-packages/sympy/core/add.py\n",
            "    - lib/python3.10/site-packages/sympy/core/alphabets.py\n",
            "    - lib/python3.10/site-packages/sympy/core/assumptions.py\n",
            "    - lib/python3.10/site-packages/sympy/core/assumptions_generated.py\n",
            "    - lib/python3.10/site-packages/sympy/core/backend.py\n",
            "    - lib/python3.10/site-packages/sympy/core/basic.py\n",
            "    - lib/python3.10/site-packages/sympy/core/benchmarks/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/core/benchmarks/bench_arit.py\n",
            "    - lib/python3.10/site-packages/sympy/core/benchmarks/bench_assumptions.py\n",
            "    - lib/python3.10/site-packages/sympy/core/benchmarks/bench_basic.py\n",
            "    - lib/python3.10/site-packages/sympy/core/benchmarks/bench_expand.py\n",
            "    - lib/python3.10/site-packages/sympy/core/benchmarks/bench_numbers.py\n",
            "    - lib/python3.10/site-packages/sympy/core/benchmarks/bench_sympify.py\n",
            "    - lib/python3.10/site-packages/sympy/core/cache.py\n",
            "    - lib/python3.10/site-packages/sympy/core/compatibility.py\n",
            "    - lib/python3.10/site-packages/sympy/core/containers.py\n",
            "    - lib/python3.10/site-packages/sympy/core/core.py\n",
            "    - lib/python3.10/site-packages/sympy/core/coreerrors.py\n",
            "    - lib/python3.10/site-packages/sympy/core/decorators.py\n",
            "    - lib/python3.10/site-packages/sympy/core/evalf.py\n",
            "    - lib/python3.10/site-packages/sympy/core/expr.py\n",
            "    - lib/python3.10/site-packages/sympy/core/exprtools.py\n",
            "    - lib/python3.10/site-packages/sympy/core/facts.py\n",
            "    - lib/python3.10/site-packages/sympy/core/function.py\n",
            "    - lib/python3.10/site-packages/sympy/core/intfunc.py\n",
            "    - lib/python3.10/site-packages/sympy/core/kind.py\n",
            "    - lib/python3.10/site-packages/sympy/core/logic.py\n",
            "    - lib/python3.10/site-packages/sympy/core/mod.py\n",
            "    - lib/python3.10/site-packages/sympy/core/mul.py\n",
            "    - lib/python3.10/site-packages/sympy/core/multidimensional.py\n",
            "    - lib/python3.10/site-packages/sympy/core/numbers.py\n",
            "    - lib/python3.10/site-packages/sympy/core/operations.py\n",
            "    - lib/python3.10/site-packages/sympy/core/parameters.py\n",
            "    - lib/python3.10/site-packages/sympy/core/power.py\n",
            "    - lib/python3.10/site-packages/sympy/core/random.py\n",
            "    - lib/python3.10/site-packages/sympy/core/relational.py\n",
            "    - lib/python3.10/site-packages/sympy/core/rules.py\n",
            "    - lib/python3.10/site-packages/sympy/core/singleton.py\n",
            "    - lib/python3.10/site-packages/sympy/core/sorting.py\n",
            "    - lib/python3.10/site-packages/sympy/core/symbol.py\n",
            "    - lib/python3.10/site-packages/sympy/core/sympify.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_args.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_arit.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_assumptions.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_basic.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_cache.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_compatibility.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_complex.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_constructor_postprocessor.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_containers.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_count_ops.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_diff.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_equal.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_eval.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_evalf.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_expand.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_expr.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_exprtools.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_facts.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_function.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_kind.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_logic.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_match.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_multidimensional.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_noncommutative.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_numbers.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_operations.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_parameters.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_power.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_priority.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_random.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_relational.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_rules.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_singleton.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_sorting.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_subs.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_symbol.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_sympify.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_traversal.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_truediv.py\n",
            "    - lib/python3.10/site-packages/sympy/core/tests/test_var.py\n",
            "    - lib/python3.10/site-packages/sympy/core/trace.py\n",
            "    - lib/python3.10/site-packages/sympy/core/traversal.py\n",
            "    - lib/python3.10/site-packages/sympy/crypto/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/crypto/crypto.py\n",
            "    - lib/python3.10/site-packages/sympy/crypto/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/crypto/tests/test_crypto.py\n",
            "    - lib/python3.10/site-packages/sympy/diffgeom/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/diffgeom/diffgeom.py\n",
            "    - lib/python3.10/site-packages/sympy/diffgeom/rn.py\n",
            "    - lib/python3.10/site-packages/sympy/diffgeom/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/diffgeom/tests/test_class_structure.py\n",
            "    - lib/python3.10/site-packages/sympy/diffgeom/tests/test_diffgeom.py\n",
            "    - lib/python3.10/site-packages/sympy/diffgeom/tests/test_function_diffgeom_book.py\n",
            "    - lib/python3.10/site-packages/sympy/diffgeom/tests/test_hyperbolic_space.py\n",
            "    - lib/python3.10/site-packages/sympy/discrete/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/discrete/convolutions.py\n",
            "    - lib/python3.10/site-packages/sympy/discrete/recurrences.py\n",
            "    - lib/python3.10/site-packages/sympy/discrete/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/discrete/tests/test_convolutions.py\n",
            "    - lib/python3.10/site-packages/sympy/discrete/tests/test_recurrences.py\n",
            "    - lib/python3.10/site-packages/sympy/discrete/tests/test_transforms.py\n",
            "    - lib/python3.10/site-packages/sympy/discrete/transforms.py\n",
            "    - lib/python3.10/site-packages/sympy/external/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/external/gmpy.py\n",
            "    - lib/python3.10/site-packages/sympy/external/importtools.py\n",
            "    - lib/python3.10/site-packages/sympy/external/ntheory.py\n",
            "    - lib/python3.10/site-packages/sympy/external/pythonmpq.py\n",
            "    - lib/python3.10/site-packages/sympy/external/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/external/tests/test_autowrap.py\n",
            "    - lib/python3.10/site-packages/sympy/external/tests/test_codegen.py\n",
            "    - lib/python3.10/site-packages/sympy/external/tests/test_gmpy.py\n",
            "    - lib/python3.10/site-packages/sympy/external/tests/test_importtools.py\n",
            "    - lib/python3.10/site-packages/sympy/external/tests/test_ntheory.py\n",
            "    - lib/python3.10/site-packages/sympy/external/tests/test_numpy.py\n",
            "    - lib/python3.10/site-packages/sympy/external/tests/test_pythonmpq.py\n",
            "    - lib/python3.10/site-packages/sympy/external/tests/test_scipy.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/combinatorial/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/combinatorial/factorials.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/combinatorial/numbers.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/combinatorial/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/combinatorial/tests/test_comb_factorials.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/combinatorial/tests/test_comb_numbers.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/_trigonometric_special.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/benchmarks/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/benchmarks/bench_exp.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/complexes.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/exponential.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/hyperbolic.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/integers.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/miscellaneous.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/piecewise.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/tests/test_complexes.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/tests/test_exponential.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/tests/test_hyperbolic.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/tests/test_integers.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/tests/test_interface.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/tests/test_miscellaneous.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/tests/test_piecewise.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/tests/test_trigonometric.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/elementary/trigonometric.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/benchmarks/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/benchmarks/bench_special.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/bessel.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/beta_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/bsplines.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/delta_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/elliptic_integrals.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/error_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/gamma_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/hyper.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/mathieu_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/polynomials.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/singularity_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/spherical_harmonics.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tensor_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_bessel.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_beta_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_bsplines.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_delta_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_elliptic_integrals.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_error_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_gamma_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_hyper.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_mathieu.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_singularity_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_spec_polynomials.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_spherical_harmonics.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_tensor_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/tests/test_zeta_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/functions/special/zeta_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/galgebra.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/curve.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/ellipse.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/entity.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/exceptions.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/line.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/parabola.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/plane.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/point.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/polygon.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/tests/test_curve.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/tests/test_ellipse.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/tests/test_entity.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/tests/test_geometrysets.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/tests/test_line.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/tests/test_parabola.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/tests/test_plane.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/tests/test_point.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/tests/test_polygon.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/tests/test_util.py\n",
            "    - lib/python3.10/site-packages/sympy/geometry/util.py\n",
            "    - lib/python3.10/site-packages/sympy/holonomic/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/holonomic/holonomic.py\n",
            "    - lib/python3.10/site-packages/sympy/holonomic/holonomicerrors.py\n",
            "    - lib/python3.10/site-packages/sympy/holonomic/numerical.py\n",
            "    - lib/python3.10/site-packages/sympy/holonomic/recurrence.py\n",
            "    - lib/python3.10/site-packages/sympy/holonomic/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/holonomic/tests/test_holonomic.py\n",
            "    - lib/python3.10/site-packages/sympy/holonomic/tests/test_recurrence.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/benchmarks/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/benchmarks/bench_integrate.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/benchmarks/bench_trigintegrate.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/deltafunctions.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/heurisch.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/integrals.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/intpoly.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/laplace.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/manualintegrate.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/meijerint.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/meijerint_doc.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/prde.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/quadrature.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/rationaltools.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/rde.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/risch.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/singularityfunctions.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_deltafunctions.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_failing_integrals.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_heurisch.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_integrals.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_intpoly.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_laplace.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_lineintegrals.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_manual.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_meijerint.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_prde.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_quadrature.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_rationaltools.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_rde.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_risch.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_singularityfunctions.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_transforms.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/tests/test_trigonometry.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/transforms.py\n",
            "    - lib/python3.10/site-packages/sympy/integrals/trigonometry.py\n",
            "    - lib/python3.10/site-packages/sympy/interactive/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/interactive/printing.py\n",
            "    - lib/python3.10/site-packages/sympy/interactive/session.py\n",
            "    - lib/python3.10/site-packages/sympy/interactive/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/interactive/tests/test_interactive.py\n",
            "    - lib/python3.10/site-packages/sympy/interactive/tests/test_ipython.py\n",
            "    - lib/python3.10/site-packages/sympy/interactive/traversal.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/cartan_matrix.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/cartan_type.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/dynkin_diagram.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/root_system.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/test_cartan_matrix.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/test_cartan_type.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/test_dynkin_diagram.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/test_root_system.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/test_type_A.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/test_type_B.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/test_type_C.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/test_type_D.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/test_type_E.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/test_type_F.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/test_type_G.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/tests/test_weyl_group.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/type_a.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/type_b.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/type_c.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/type_d.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/type_e.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/type_f.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/type_g.py\n",
            "    - lib/python3.10/site-packages/sympy/liealgebras/weyl_group.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/algorithms/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/algorithms/dpll.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/algorithms/dpll2.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/algorithms/lra_theory.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/algorithms/minisat22_wrapper.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/algorithms/pycosat_wrapper.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/algorithms/z3_wrapper.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/boolalg.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/inference.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/tests/test_boolalg.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/tests/test_dimacs.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/tests/test_inference.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/tests/test_lra_theory.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/utilities/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/logic/utilities/dimacs.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/benchmarks/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/benchmarks/bench_matrix.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/common.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/decompositions.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/dense.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/determinant.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/eigen.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/exceptions.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/_shape.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/adjoint.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/applyfunc.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/blockmatrix.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/companion.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/determinant.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/diagonal.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/dotproduct.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/factorizations.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/fourier.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/funcmatrix.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/hadamard.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/inverse.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/kronecker.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/matadd.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/matexpr.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/matmul.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/matpow.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/permutation.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/sets.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/slice.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/special.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_adjoint.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_applyfunc.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_blockmatrix.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_companion.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_derivatives.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_determinant.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_diagonal.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_dotproduct.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_factorizations.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_fourier.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_funcmatrix.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_hadamard.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_indexing.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_inverse.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_kronecker.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_matadd.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_matexpr.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_matmul.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_matpow.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_permutation.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_sets.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_slice.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_special.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_trace.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/tests/test_transpose.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/trace.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/expressions/transpose.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/graph.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/immutable.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/inverse.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/kind.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/matrices.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/matrixbase.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/normalforms.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/reductions.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/repmatrix.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/solvers.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/sparse.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/sparsetools.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/subspaces.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_commonmatrix.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_decompositions.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_determinant.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_domains.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_eigen.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_graph.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_immutable.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_interactions.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_matrices.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_matrixbase.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_normalforms.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_reductions.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_repmatrix.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_solvers.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_sparse.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_sparsetools.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/tests/test_subspaces.py\n",
            "    - lib/python3.10/site-packages/sympy/matrices/utilities.py\n",
            "    - lib/python3.10/site-packages/sympy/multipledispatch/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/multipledispatch/conflict.py\n",
            "    - lib/python3.10/site-packages/sympy/multipledispatch/core.py\n",
            "    - lib/python3.10/site-packages/sympy/multipledispatch/dispatcher.py\n",
            "    - lib/python3.10/site-packages/sympy/multipledispatch/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/multipledispatch/tests/test_conflict.py\n",
            "    - lib/python3.10/site-packages/sympy/multipledispatch/tests/test_core.py\n",
            "    - lib/python3.10/site-packages/sympy/multipledispatch/tests/test_dispatcher.py\n",
            "    - lib/python3.10/site-packages/sympy/multipledispatch/utils.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/bbp_pi.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/continued_fraction.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/digits.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/ecm.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/egyptian_fraction.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/elliptic_curve.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/factor_.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/generate.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/modular.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/multinomial.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/partitions_.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/primetest.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/qs.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/residue_ntheory.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_bbp_pi.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_continued_fraction.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_digits.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_ecm.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_egyptian_fraction.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_elliptic_curve.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_factor_.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_generate.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_hypothesis.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_modular.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_multinomial.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_partitions.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_primetest.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_qs.py\n",
            "    - lib/python3.10/site-packages/sympy/ntheory/tests/test_residue.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/ast_parser.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/Autolev.g4\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/_antlr/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/_antlr/autolevlexer.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/_build_autolev_antlr.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/_parse_autolev_antlr.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/README.txt\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/pydy-example-repo/chaos_pendulum.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/pydy-example-repo/chaos_pendulum.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/pydy-example-repo/double_pendulum.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/pydy-example-repo/double_pendulum.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/pydy-example-repo/mass_spring_damper.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/pydy-example-repo/mass_spring_damper.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/pydy-example-repo/non_min_pendulum.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/pydy-example-repo/non_min_pendulum.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest1.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest1.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest10.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest10.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest11.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest11.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest12.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest12.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest2.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest2.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest3.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest3.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest4.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest4.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest5.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest5.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest6.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest6.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest7.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest7.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest8.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest8.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest9.al\n",
            "    - lib/python3.10/site-packages/sympy/parsing/autolev/test-examples/ruletest9.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/c/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/c/c_parser.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/fortran/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/fortran/fortran_parser.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/LICENSE.txt\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/LaTeX.g4\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/_antlr/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/_antlr/latexlexer.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/_antlr/latexparser.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/_build_latex_antlr.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/_parse_latex_antlr.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/errors.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/lark/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/lark/grammar/greek_symbols.lark\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/lark/grammar/latex.lark\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/lark/latex_parser.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/latex/lark/transformer.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/mathematica.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/maxima.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/sym_expr.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/sympy_parser.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_ast_parser.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_autolev.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_c_parser.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_custom_latex.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_fortran_parser.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_implicit_multiplication_application.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_latex.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_latex_deps.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_latex_lark.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_mathematica.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_maxima.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_sym_expr.py\n",
            "    - lib/python3.10/site-packages/sympy/parsing/tests/test_sympy_parser.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/biomechanics/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/biomechanics/_mixin.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/biomechanics/activation.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/biomechanics/curve.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/biomechanics/musculotendon.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/biomechanics/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/biomechanics/tests/test_activation.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/biomechanics/tests/test_curve.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/biomechanics/tests/test_mixin.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/biomechanics/tests/test_musculotendon.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/continuum_mechanics/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/continuum_mechanics/arch.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/continuum_mechanics/beam.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/continuum_mechanics/cable.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/continuum_mechanics/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/continuum_mechanics/tests/test_arch.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/continuum_mechanics/tests/test_beam.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/continuum_mechanics/tests/test_cable.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/continuum_mechanics/tests/test_truss.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/continuum_mechanics/truss.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/control/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/control/control_plots.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/control/lti.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/control/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/control/tests/test_control_plots.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/control/tests/test_lti.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/hep/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/hep/gamma_matrices.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/hep/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/hep/tests/test_gamma_matrices.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/hydrogen.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/matrices.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/actuator.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/body.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/body_base.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/functions.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/inertia.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/joint.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/jointsmethod.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/kane.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/lagrange.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/linearize.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/loads.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/method.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/models.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/particle.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/pathway.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/rigidbody.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/system.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_actuator.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_body.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_inertia.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_joint.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_jointsmethod.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_kane.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_kane2.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_kane3.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_kane4.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_kane5.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_lagrange.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_lagrange2.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_linearity_of_velocity_constraints.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_linearize.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_loads.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_method.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_models.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_particle.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_pathway.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_rigidbody.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_system.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_system_class.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/tests/test_wrapping_geometry.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/mechanics/wrapping_geometry.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/optics/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/optics/gaussopt.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/optics/medium.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/optics/polarization.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/optics/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/optics/tests/test_gaussopt.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/optics/tests/test_medium.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/optics/tests/test_polarization.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/optics/tests/test_utils.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/optics/tests/test_waves.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/optics/utils.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/optics/waves.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/paulialgebra.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/pring.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/qho_1d.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/anticommutator.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/boson.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/cartesian.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/cg.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/circuitplot.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/circuitutils.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/commutator.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/constants.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/dagger.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/density.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/fermion.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/gate.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/grover.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/hilbert.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/identitysearch.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/innerproduct.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/kind.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/matrixcache.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/matrixutils.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/operator.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/operatorordering.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/operatorset.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/pauli.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/piab.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/qapply.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/qasm.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/qexpr.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/qft.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/qubit.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/represent.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/sho1d.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/shor.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/spin.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/state.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tensorproduct.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_anticommutator.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_boson.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_cartesian.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_cg.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_circuitplot.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_circuitutils.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_commutator.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_constants.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_dagger.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_density.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_fermion.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_gate.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_grover.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_hilbert.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_identitysearch.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_innerproduct.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_kind.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_matrixutils.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_operator.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_operatorordering.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_operatorset.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_pauli.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_piab.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_printing.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_qapply.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_qasm.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_qexpr.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_qft.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_qubit.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_represent.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_sho1d.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_shor.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_spin.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_state.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_tensorproduct.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_trace.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/tests/test_transforms.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/trace.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/quantum/transforms.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/secondquant.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/sho.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/tests/test_clebsch_gordan.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/tests/test_hydrogen.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/tests/test_paulialgebra.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/tests/test_physics_matrices.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/tests/test_pring.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/tests/test_qho_1d.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/tests/test_secondquant.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/tests/test_sho.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/definitions/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/definitions/dimension_definitions.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/definitions/unit_definitions.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/dimensions.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/prefixes.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/quantities.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/systems/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/systems/cgs.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/systems/length_weight_time.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/systems/mks.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/systems/mksa.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/systems/natural.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/systems/si.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/tests/test_dimensions.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/tests/test_dimensionsystem.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/tests/test_prefixes.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/tests/test_quantities.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/tests/test_unit_system_cgs_gauss.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/tests/test_unitsystem.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/tests/test_util.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/unitsystem.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/units/util.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/dyadic.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/fieldfunctions.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/frame.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/functions.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/point.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/printing.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/tests/test_dyadic.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/tests/test_fieldfunctions.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/tests/test_frame.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/tests/test_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/tests/test_output.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/tests/test_point.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/tests/test_printing.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/tests/test_vector.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/vector/vector.py\n",
            "    - lib/python3.10/site-packages/sympy/physics/wigner.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/backends/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/backends/base_backend.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/backends/matplotlibbackend/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/backends/textbackend/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/backends/textbackend/text.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/experimental_lambdify.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/intervalmath/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/intervalmath/interval_arithmetic.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/intervalmath/interval_membership.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/intervalmath/lib_interval.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/intervalmath/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/intervalmath/tests/test_interval_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/intervalmath/tests/test_interval_membership.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/intervalmath/tests/test_intervalmath.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/plot.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/plot_implicit.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/plotgrid.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/color_scheme.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/managed_window.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot_axes.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot_camera.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot_controller.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot_curve.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot_interval.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot_mode.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot_mode_base.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot_modes.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot_object.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot_rotation.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot_surface.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/plot_window.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/tests/test_plotting.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/pygletplot/util.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/series.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/tests/test_experimental_lambdify.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/tests/test_plot.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/tests/test_plot_implicit.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/tests/test_region_and.png\n",
            "    - lib/python3.10/site-packages/sympy/plotting/tests/test_region_not.png\n",
            "    - lib/python3.10/site-packages/sympy/plotting/tests/test_region_or.png\n",
            "    - lib/python3.10/site-packages/sympy/plotting/tests/test_region_xor.png\n",
            "    - lib/python3.10/site-packages/sympy/plotting/tests/test_series.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/tests/test_textplot.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/tests/test_utils.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/textplot.py\n",
            "    - lib/python3.10/site-packages/sympy/plotting/utils.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/agca/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/agca/extensions.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/agca/homomorphisms.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/agca/ideals.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/agca/modules.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/agca/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/agca/tests/test_extensions.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/agca/tests/test_homomorphisms.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/agca/tests/test_ideals.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/agca/tests/test_modules.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/appellseqs.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/benchmarks/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/benchmarks/bench_galoispolys.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/benchmarks/bench_groebnertools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/benchmarks/bench_solvers.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/compatibility.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/constructor.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/densearith.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/densebasic.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/densetools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/dispersion.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/distributedmodules.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domainmatrix.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/algebraicfield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/characteristiczero.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/complexfield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/compositedomain.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/domain.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/domainelement.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/expressiondomain.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/expressionrawdomain.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/field.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/finitefield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/fractionfield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/gaussiandomains.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/gmpyfinitefield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/gmpyintegerring.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/gmpyrationalfield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/groundtypes.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/integerring.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/modularinteger.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/mpelements.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/old_fractionfield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/old_polynomialring.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/polynomialring.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/pythonfinitefield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/pythonintegerring.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/pythonrational.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/pythonrationalfield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/quotientring.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/rationalfield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/realfield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/ring.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/simpledomain.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/tests/test_domains.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/tests/test_polynomialring.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/domains/tests/test_quotientring.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/euclidtools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/factortools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/fglmtools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/fields.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/galoistools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/groebnertools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/heuristicgcd.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/_dfm.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/_typing.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/ddm.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/dense.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/dfm.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/domainmatrix.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/domainscalar.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/eigen.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/exceptions.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/linsolve.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/lll.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/normalforms.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/rref.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/sdm.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_ddm.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_dense.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_domainmatrix.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_domainscalar.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_eigen.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_fflu.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_inverse.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_linsolve.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_lll.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_normalforms.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_nullspace.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_rref.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_sdm.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/matrices/tests/test_xxm.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/modulargcd.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/monomials.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/multivariate_resultants.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/basis.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/exceptions.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/galois_resolvents.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/galoisgroups.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/minpoly.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/modules.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/primes.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/resolvent_lookup.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/subfield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/tests/test_basis.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/tests/test_galoisgroups.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/tests/test_minpoly.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/tests/test_modules.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/tests/test_numbers.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/tests/test_primes.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/tests/test_subfield.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/tests/test_utilities.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/numberfields/utilities.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/orderings.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/orthopolys.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/partfrac.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/polyclasses.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/polyconfig.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/polyerrors.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/polyfuncs.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/polymatrix.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/polyoptions.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/polyquinticconst.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/polyroots.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/polytools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/polyutils.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/puiseux.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/rationaltools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/ring_series.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/rings.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/rootisolation.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/rootoftools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/solvers.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/specialpolys.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/sqfreetools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/subresultants_qq_zz.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_appellseqs.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_constructor.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_densearith.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_densebasic.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_densetools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_dispersion.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_distributedmodules.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_euclidtools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_factortools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_fields.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_galoistools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_groebnertools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_heuristicgcd.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_hypothesis.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_injections.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_modulargcd.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_monomials.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_multivariate_resultants.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_orderings.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_orthopolys.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_partfrac.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_polyclasses.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_polyfuncs.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_polymatrix.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_polyoptions.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_polyroots.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_polytools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_polyutils.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_puiseux.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_pythonrational.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_rationaltools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_ring_series.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_rings.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_rootisolation.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_rootoftools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_solvers.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_specialpolys.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_sqfreetools.py\n",
            "    - lib/python3.10/site-packages/sympy/polys/tests/test_subresultants_qq_zz.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/aesaracode.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/c.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/codeprinter.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/conventions.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/cxx.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/defaults.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/dot.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/fortran.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/glsl.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/gtk.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/jscode.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/julia.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/lambdarepr.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/latex.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/llvmjitcode.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/maple.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/mathematica.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/mathml.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/numpy.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/octave.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/precedence.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/pretty/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/pretty/pretty.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/pretty/pretty_symbology.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/pretty/stringpict.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/pretty/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/pretty/tests/test_pretty.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/preview.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/printer.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/pycode.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/python.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/pytorch.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/rcode.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/repr.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/rust.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/smtlib.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/str.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tableform.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tensorflow.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_aesaracode.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_c.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_codeprinter.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_conventions.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_cupy.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_cxx.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_dot.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_fortran.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_glsl.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_gtk.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_jax.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_jscode.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_julia.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_lambdarepr.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_latex.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_llvmjit.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_maple.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_mathematica.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_mathml.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_numpy.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_octave.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_precedence.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_preview.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_pycode.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_python.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_rcode.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_repr.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_rust.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_smtlib.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_str.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_tableform.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_tensorflow.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_theanocode.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_torch.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tests/test_tree.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/theanocode.py\n",
            "    - lib/python3.10/site-packages/sympy/printing/tree.py\n",
            "    - lib/python3.10/site-packages/sympy/release.py\n",
            "    - lib/python3.10/site-packages/sympy/sandbox/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/sandbox/indexed_integrals.py\n",
            "    - lib/python3.10/site-packages/sympy/sandbox/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/sandbox/tests/test_indexed_integrals.py\n",
            "    - lib/python3.10/site-packages/sympy/series/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/series/acceleration.py\n",
            "    - lib/python3.10/site-packages/sympy/series/approximants.py\n",
            "    - lib/python3.10/site-packages/sympy/series/aseries.py\n",
            "    - lib/python3.10/site-packages/sympy/series/benchmarks/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/series/benchmarks/bench_limit.py\n",
            "    - lib/python3.10/site-packages/sympy/series/benchmarks/bench_order.py\n",
            "    - lib/python3.10/site-packages/sympy/series/formal.py\n",
            "    - lib/python3.10/site-packages/sympy/series/fourier.py\n",
            "    - lib/python3.10/site-packages/sympy/series/gruntz.py\n",
            "    - lib/python3.10/site-packages/sympy/series/kauers.py\n",
            "    - lib/python3.10/site-packages/sympy/series/limits.py\n",
            "    - lib/python3.10/site-packages/sympy/series/limitseq.py\n",
            "    - lib/python3.10/site-packages/sympy/series/order.py\n",
            "    - lib/python3.10/site-packages/sympy/series/residues.py\n",
            "    - lib/python3.10/site-packages/sympy/series/sequences.py\n",
            "    - lib/python3.10/site-packages/sympy/series/series.py\n",
            "    - lib/python3.10/site-packages/sympy/series/series_class.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_approximants.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_aseries.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_demidovich.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_formal.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_fourier.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_gruntz.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_kauers.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_limits.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_limitseq.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_lseries.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_nseries.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_order.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_residues.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_sequences.py\n",
            "    - lib/python3.10/site-packages/sympy/series/tests/test_series.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/conditionset.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/contains.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/fancysets.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/handlers/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/handlers/add.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/handlers/comparison.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/handlers/functions.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/handlers/intersection.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/handlers/issubset.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/handlers/mul.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/handlers/power.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/handlers/union.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/ordinals.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/powerset.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/setexpr.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/sets.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/tests/test_conditionset.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/tests/test_contains.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/tests/test_fancysets.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/tests/test_ordinals.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/tests/test_powerset.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/tests/test_setexpr.py\n",
            "    - lib/python3.10/site-packages/sympy/sets/tests/test_sets.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/_cse_diff.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/combsimp.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/cse_main.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/cse_opts.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/epathtools.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/fu.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/gammasimp.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/hyperexpand.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/hyperexpand_doc.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/powsimp.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/radsimp.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/ratsimp.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/simplify.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/sqrtdenest.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_combsimp.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_cse.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_cse_diff.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_epathtools.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_fu.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_function.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_gammasimp.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_hyperexpand.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_powsimp.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_radsimp.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_ratsimp.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_rewrite.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_simplify.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_sqrtdenest.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/tests/test_trigsimp.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/traversaltools.py\n",
            "    - lib/python3.10/site-packages/sympy/simplify/trigsimp.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/benchmarks/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/benchmarks/bench_solvers.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/bivariate.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/decompogen.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/deutils.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/diophantine/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/diophantine/diophantine.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/diophantine/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/diophantine/tests/test_diophantine.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/inequalities.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/hypergeometric.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/lie_group.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/nonhomogeneous.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/ode.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/riccati.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/single.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/subscheck.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/systems.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/tests/test_lie_group.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/tests/test_ode.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/tests/test_riccati.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/tests/test_single.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/tests/test_subscheck.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/ode/tests/test_systems.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/pde.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/polysys.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/recurr.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/simplex.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/solvers.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/solveset.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/tests/test_constantsimp.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/tests/test_decompogen.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/tests/test_inequalities.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/tests/test_numeric.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/tests/test_pde.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/tests/test_polysys.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/tests/test_recurr.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/tests/test_simplex.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/tests/test_solvers.py\n",
            "    - lib/python3.10/site-packages/sympy/solvers/tests/test_solveset.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/compound_rv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/crv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/crv_types.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/drv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/drv_types.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/error_prop.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/frv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/frv_types.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/joint_rv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/joint_rv_types.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/matrix_distributions.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/random_matrix.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/random_matrix_models.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/rv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/rv_interface.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/sampling/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/sampling/sample_numpy.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/sampling/sample_pymc.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/sampling/sample_scipy.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/sampling/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/sampling/tests/test_sample_continuous_rv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/sampling/tests/test_sample_discrete_rv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/sampling/tests/test_sample_finite_rv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/stochastic_process.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/stochastic_process_types.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/symbolic_multivariate_probability.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/symbolic_probability.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_compound_rv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_continuous_rv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_discrete_rv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_error_prop.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_finite_rv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_joint_rv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_matrix_distributions.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_mix.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_random_matrix.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_rv.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_stochastic_process.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_symbolic_multivariate.py\n",
            "    - lib/python3.10/site-packages/sympy/stats/tests/test_symbolic_probability.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/branch/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/branch/core.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/branch/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/branch/tests/test_core.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/branch/tests/test_tools.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/branch/tests/test_traverse.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/branch/tools.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/branch/traverse.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/core.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/rl.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/tests/test_core.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/tests/test_rl.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/tests/test_tools.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/tests/test_traverse.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/tests/test_tree.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/tools.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/traverse.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/tree.py\n",
            "    - lib/python3.10/site-packages/sympy/strategies/util.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/array_comprehension.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/array_derivatives.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/arrayop.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/dense_ndim_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/array_expressions.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/arrayexpr_derivatives.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/conv_array_to_indexed.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/conv_array_to_matrix.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/conv_indexed_to_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/conv_matrix_to_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/from_array_to_indexed.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/from_indexed_to_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/from_matrix_to_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/tests/test_arrayexpr_derivatives.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/tests/test_as_explicit.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/tests/test_convert_array_to_indexed.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/tests/test_convert_array_to_matrix.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/tests/test_convert_indexed_to_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/tests/test_convert_matrix_to_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/tests/test_deprecated_conv_modules.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/expressions/utils.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/mutable_ndim_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/ndim_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/sparse_ndim_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/tests/test_array_comprehension.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/tests/test_array_derivatives.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/tests/test_arrayop.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/tests/test_immutable_ndim_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/tests/test_mutable_ndim_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/tests/test_ndim_array.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/array/tests/test_ndim_array_conversions.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/functions.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/index_methods.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/indexed.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/tensor.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/tests/test_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/tests/test_index_methods.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/tests/test_indexed.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/tests/test_printing.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/tests/test_tensor.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/tests/test_tensor_element.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/tests/test_tensor_operators.py\n",
            "    - lib/python3.10/site-packages/sympy/tensor/toperators.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/matrices.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/pytest.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/quality_unicode.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/randtest.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/runtests.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/runtests_pytest.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/tests/diagnose_imports.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/tests/test_code_quality.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/tests/test_deprecated.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/tests/test_module_imports.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/tests/test_pytest.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/tests/test_runtests_pytest.py\n",
            "    - lib/python3.10/site-packages/sympy/testing/tmpfiles.py\n",
            "    - lib/python3.10/site-packages/sympy/this.py\n",
            "    - lib/python3.10/site-packages/sympy/unify/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/unify/core.py\n",
            "    - lib/python3.10/site-packages/sympy/unify/rewrite.py\n",
            "    - lib/python3.10/site-packages/sympy/unify/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/unify/tests/test_rewrite.py\n",
            "    - lib/python3.10/site-packages/sympy/unify/tests/test_sympy.py\n",
            "    - lib/python3.10/site-packages/sympy/unify/tests/test_unify.py\n",
            "    - lib/python3.10/site-packages/sympy/unify/usympy.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/_compilation/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/_compilation/availability.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/_compilation/compilation.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/_compilation/runners.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/_compilation/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/_compilation/tests/test_compilation.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/_compilation/util.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/autowrap.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/codegen.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/decorator.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/enumerative.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/exceptions.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/iterables.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/lambdify.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/magic.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/matchpy_connector.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/mathml/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/mathml/data/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/mathml/data/mmlctop.xsl\n",
            "    - lib/python3.10/site-packages/sympy/utilities/mathml/data/mmltex.xsl\n",
            "    - lib/python3.10/site-packages/sympy/utilities/mathml/data/simple_mmlctop.xsl\n",
            "    - lib/python3.10/site-packages/sympy/utilities/memoization.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/misc.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/pkgdata.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/pytest.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/randtest.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/runtests.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/source.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_autowrap.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_codegen.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_codegen_julia.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_codegen_octave.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_codegen_rust.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_decorator.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_deprecated.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_enumerative.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_exceptions.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_iterables.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_lambdify.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_matchpy_connector.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_mathml.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_misc.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_pickling.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_source.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_timeutils.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_wester.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tests/test_xxe.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/timeutils.py\n",
            "    - lib/python3.10/site-packages/sympy/utilities/tmpfiles.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/basisdependent.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/coordsysrect.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/deloperator.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/dyadic.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/functions.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/implicitregion.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/integrals.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/kind.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/operators.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/orienters.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/parametricregion.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/point.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/scalar.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/tests/test_coordsysrect.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/tests/test_dyadic.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/tests/test_field_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/tests/test_functions.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/tests/test_implicitregion.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/tests/test_integrals.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/tests/test_operators.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/tests/test_parametricregion.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/tests/test_printing.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/tests/test_vector.py\n",
            "    - lib/python3.10/site-packages/sympy/vector/vector.py\n",
            "    - bin/isympy\n",
            "Linking rich-14.2.0-pyhcf101f3_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [rich-14.2.0-pyhcf101f3_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/rich/__init__.py\n",
            "    - lib/python3.10/site-packages/rich/__main__.py\n",
            "    - lib/python3.10/site-packages/rich/_cell_widths.py\n",
            "    - lib/python3.10/site-packages/rich/_emoji_codes.py\n",
            "    - lib/python3.10/site-packages/rich/_emoji_replace.py\n",
            "    - lib/python3.10/site-packages/rich/_export_format.py\n",
            "    - lib/python3.10/site-packages/rich/_extension.py\n",
            "    - lib/python3.10/site-packages/rich/_fileno.py\n",
            "    - lib/python3.10/site-packages/rich/_inspect.py\n",
            "    - lib/python3.10/site-packages/rich/_log_render.py\n",
            "    - lib/python3.10/site-packages/rich/_loop.py\n",
            "    - lib/python3.10/site-packages/rich/_null_file.py\n",
            "    - lib/python3.10/site-packages/rich/_palettes.py\n",
            "    - lib/python3.10/site-packages/rich/_pick.py\n",
            "    - lib/python3.10/site-packages/rich/_ratio.py\n",
            "    - lib/python3.10/site-packages/rich/_spinners.py\n",
            "    - lib/python3.10/site-packages/rich/_stack.py\n",
            "    - lib/python3.10/site-packages/rich/_timer.py\n",
            "    - lib/python3.10/site-packages/rich/_win32_console.py\n",
            "    - lib/python3.10/site-packages/rich/_windows.py\n",
            "    - lib/python3.10/site-packages/rich/_windows_renderer.py\n",
            "    - lib/python3.10/site-packages/rich/_wrap.py\n",
            "    - lib/python3.10/site-packages/rich/abc.py\n",
            "    - lib/python3.10/site-packages/rich/align.py\n",
            "    - lib/python3.10/site-packages/rich/ansi.py\n",
            "    - lib/python3.10/site-packages/rich/bar.py\n",
            "    - lib/python3.10/site-packages/rich/box.py\n",
            "    - lib/python3.10/site-packages/rich/cells.py\n",
            "    - lib/python3.10/site-packages/rich/color.py\n",
            "    - lib/python3.10/site-packages/rich/color_triplet.py\n",
            "    - lib/python3.10/site-packages/rich/columns.py\n",
            "    - lib/python3.10/site-packages/rich/console.py\n",
            "    - lib/python3.10/site-packages/rich/constrain.py\n",
            "    - lib/python3.10/site-packages/rich/containers.py\n",
            "    - lib/python3.10/site-packages/rich/control.py\n",
            "    - lib/python3.10/site-packages/rich/default_styles.py\n",
            "    - lib/python3.10/site-packages/rich/diagnose.py\n",
            "    - lib/python3.10/site-packages/rich/emoji.py\n",
            "    - lib/python3.10/site-packages/rich/errors.py\n",
            "    - lib/python3.10/site-packages/rich/file_proxy.py\n",
            "    - lib/python3.10/site-packages/rich/filesize.py\n",
            "    - lib/python3.10/site-packages/rich/highlighter.py\n",
            "    - lib/python3.10/site-packages/rich/json.py\n",
            "    - lib/python3.10/site-packages/rich/jupyter.py\n",
            "    - lib/python3.10/site-packages/rich/layout.py\n",
            "    - lib/python3.10/site-packages/rich/live.py\n",
            "    - lib/python3.10/site-packages/rich/live_render.py\n",
            "    - lib/python3.10/site-packages/rich/logging.py\n",
            "    - lib/python3.10/site-packages/rich/markdown.py\n",
            "    - lib/python3.10/site-packages/rich/markup.py\n",
            "    - lib/python3.10/site-packages/rich/measure.py\n",
            "    - lib/python3.10/site-packages/rich/padding.py\n",
            "    - lib/python3.10/site-packages/rich/pager.py\n",
            "    - lib/python3.10/site-packages/rich/palette.py\n",
            "    - lib/python3.10/site-packages/rich/panel.py\n",
            "    - lib/python3.10/site-packages/rich/pretty.py\n",
            "    - lib/python3.10/site-packages/rich/progress.py\n",
            "    - lib/python3.10/site-packages/rich/progress_bar.py\n",
            "    - lib/python3.10/site-packages/rich/prompt.py\n",
            "    - lib/python3.10/site-packages/rich/protocol.py\n",
            "    - lib/python3.10/site-packages/rich/py.typed\n",
            "    - lib/python3.10/site-packages/rich/region.py\n",
            "    - lib/python3.10/site-packages/rich/repr.py\n",
            "    - lib/python3.10/site-packages/rich/rule.py\n",
            "    - lib/python3.10/site-packages/rich/scope.py\n",
            "    - lib/python3.10/site-packages/rich/screen.py\n",
            "    - lib/python3.10/site-packages/rich/segment.py\n",
            "    - lib/python3.10/site-packages/rich/spinner.py\n",
            "    - lib/python3.10/site-packages/rich/status.py\n",
            "    - lib/python3.10/site-packages/rich/style.py\n",
            "    - lib/python3.10/site-packages/rich/styled.py\n",
            "    - lib/python3.10/site-packages/rich/syntax.py\n",
            "    - lib/python3.10/site-packages/rich/table.py\n",
            "    - lib/python3.10/site-packages/rich/terminal_theme.py\n",
            "    - lib/python3.10/site-packages/rich/text.py\n",
            "    - lib/python3.10/site-packages/rich/theme.py\n",
            "    - lib/python3.10/site-packages/rich/themes.py\n",
            "    - lib/python3.10/site-packages/rich/traceback.py\n",
            "    - lib/python3.10/site-packages/rich/tree.py\n",
            "    - lib/python3.10/site-packages/rich-14.2.0.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/rich-14.2.0.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/rich-14.2.0.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/rich-14.2.0.dist-info/WHEEL\n",
            "Linking importlib_metadata-8.7.0-h40b2b14_1\n",
            "Linking httpcore-1.0.9-pyh29332c3_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [httpcore-1.0.9-pyh29332c3_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/httpcore/__init__.py\n",
            "    - lib/python3.10/site-packages/httpcore/_api.py\n",
            "    - lib/python3.10/site-packages/httpcore/_async/__init__.py\n",
            "    - lib/python3.10/site-packages/httpcore/_async/connection.py\n",
            "    - lib/python3.10/site-packages/httpcore/_async/connection_pool.py\n",
            "    - lib/python3.10/site-packages/httpcore/_async/http11.py\n",
            "    - lib/python3.10/site-packages/httpcore/_async/http2.py\n",
            "    - lib/python3.10/site-packages/httpcore/_async/http_proxy.py\n",
            "    - lib/python3.10/site-packages/httpcore/_async/interfaces.py\n",
            "    - lib/python3.10/site-packages/httpcore/_async/socks_proxy.py\n",
            "    - lib/python3.10/site-packages/httpcore/_backends/__init__.py\n",
            "    - lib/python3.10/site-packages/httpcore/_backends/anyio.py\n",
            "    - lib/python3.10/site-packages/httpcore/_backends/auto.py\n",
            "    - lib/python3.10/site-packages/httpcore/_backends/base.py\n",
            "    - lib/python3.10/site-packages/httpcore/_backends/mock.py\n",
            "    - lib/python3.10/site-packages/httpcore/_backends/sync.py\n",
            "    - lib/python3.10/site-packages/httpcore/_backends/trio.py\n",
            "    - lib/python3.10/site-packages/httpcore/_exceptions.py\n",
            "    - lib/python3.10/site-packages/httpcore/_models.py\n",
            "    - lib/python3.10/site-packages/httpcore/_ssl.py\n",
            "    - lib/python3.10/site-packages/httpcore/_sync/__init__.py\n",
            "    - lib/python3.10/site-packages/httpcore/_sync/connection.py\n",
            "    - lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\n",
            "    - lib/python3.10/site-packages/httpcore/_sync/http11.py\n",
            "    - lib/python3.10/site-packages/httpcore/_sync/http2.py\n",
            "    - lib/python3.10/site-packages/httpcore/_sync/http_proxy.py\n",
            "    - lib/python3.10/site-packages/httpcore/_sync/interfaces.py\n",
            "    - lib/python3.10/site-packages/httpcore/_sync/socks_proxy.py\n",
            "    - lib/python3.10/site-packages/httpcore/_synchronization.py\n",
            "    - lib/python3.10/site-packages/httpcore/_trace.py\n",
            "    - lib/python3.10/site-packages/httpcore/_utils.py\n",
            "    - lib/python3.10/site-packages/httpcore/py.typed\n",
            "    - lib/python3.10/site-packages/httpcore-1.0.9.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/httpcore-1.0.9.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/httpcore-1.0.9.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/httpcore-1.0.9.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/httpcore-1.0.9.dist-info/licenses/LICENSE.md\n",
            "Linking optlang-1.8.3-pyhd8ed1ab_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [optlang-1.8.3-pyhd8ed1ab_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/optlang-1.8.3.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/optlang-1.8.3.dist-info/LICENSE\n",
            "    - lib/python3.10/site-packages/optlang-1.8.3.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/optlang-1.8.3.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/optlang-1.8.3.dist-info/REQUESTED\n",
            "    - lib/python3.10/site-packages/optlang-1.8.3.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/optlang-1.8.3.dist-info/top_level.txt\n",
            "    - lib/python3.10/site-packages/optlang-1.8.3.dist-info/zip-safe\n",
            "    - lib/python3.10/site-packages/optlang/__init__.py\n",
            "    - lib/python3.10/site-packages/optlang/_version.py\n",
            "    - lib/python3.10/site-packages/optlang/coinor_cbc_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/container.py\n",
            "    - lib/python3.10/site-packages/optlang/cplex_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/duality.py\n",
            "    - lib/python3.10/site-packages/optlang/exceptions.py\n",
            "    - lib/python3.10/site-packages/optlang/expression_parsing.py\n",
            "    - lib/python3.10/site-packages/optlang/glpk_exact_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/glpk_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/gurobi_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/hybrid_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/inspyred_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/interface.py\n",
            "    - lib/python3.10/site-packages/optlang/matrix_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/scipy_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/symbolics.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/__init__.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/abstract_test_cases.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/data/__init__.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/data/parse_the_final_netlib_results.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_change_solver.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_coinor_cbc_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_container.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_cplex_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_duality.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_elements.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_expression_parsing.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_glpk_exact_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_glpk_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_gurobi_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_hybrid_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_inspyred_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_io.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_scipy_interface.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_symbolics.py\n",
            "    - lib/python3.10/site-packages/optlang/tests/test_util.py\n",
            "    - lib/python3.10/site-packages/optlang/util.py\n",
            "Linking depinfo-2.2.0-pyhd8ed1ab_1\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [depinfo-2.2.0-pyhd8ed1ab_1] The following files were already present in the environment:\n",
            "    - bin/depinfo\n",
            "    - lib/python3.10/site-packages/depinfo-2.2.0.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/depinfo-2.2.0.dist-info/LICENSE\n",
            "    - lib/python3.10/site-packages/depinfo-2.2.0.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/depinfo-2.2.0.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/depinfo-2.2.0.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/depinfo-2.2.0.dist-info/entry_points.txt\n",
            "    - lib/python3.10/site-packages/depinfo-2.2.0.dist-info/top_level.txt\n",
            "    - lib/python3.10/site-packages/depinfo-2.2.0.dist-info/zip-safe\n",
            "    - lib/python3.10/site-packages/depinfo/__init__.py\n",
            "    - lib/python3.10/site-packages/depinfo/_version.py\n",
            "    - lib/python3.10/site-packages/depinfo/application/__init__.py\n",
            "    - lib/python3.10/site-packages/depinfo/application/abstract_display_service.py\n",
            "    - lib/python3.10/site-packages/depinfo/application/compatibility.py\n",
            "    - lib/python3.10/site-packages/depinfo/application/display_application.py\n",
            "    - lib/python3.10/site-packages/depinfo/application/display_format.py\n",
            "    - lib/python3.10/site-packages/depinfo/application/display_service_registry.py\n",
            "    - lib/python3.10/site-packages/depinfo/domain/__init__.py\n",
            "    - lib/python3.10/site-packages/depinfo/domain/dependency_report.py\n",
            "    - lib/python3.10/site-packages/depinfo/domain/package.py\n",
            "    - lib/python3.10/site-packages/depinfo/domain/platform.py\n",
            "    - lib/python3.10/site-packages/depinfo/domain/python.py\n",
            "    - lib/python3.10/site-packages/depinfo/infrastructure/__init__.py\n",
            "    - lib/python3.10/site-packages/depinfo/infrastructure/application/__init__.py\n",
            "    - lib/python3.10/site-packages/depinfo/infrastructure/application/cli.py\n",
            "    - lib/python3.10/site-packages/depinfo/infrastructure/application/markdown_table_display_service.py\n",
            "    - lib/python3.10/site-packages/depinfo/infrastructure/application/simple_display_service.py\n",
            "    - lib/python3.10/site-packages/depinfo/py.typed\n",
            "Linking httpx-0.28.1-pyhd8ed1ab_0\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [httpx-0.28.1-pyhd8ed1ab_0] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/httpx-0.28.1.dist-info/INSTALLER\n",
            "    - lib/python3.10/site-packages/httpx-0.28.1.dist-info/METADATA\n",
            "    - lib/python3.10/site-packages/httpx-0.28.1.dist-info/RECORD\n",
            "    - lib/python3.10/site-packages/httpx-0.28.1.dist-info/WHEEL\n",
            "    - lib/python3.10/site-packages/httpx-0.28.1.dist-info/entry_points.txt\n",
            "    - lib/python3.10/site-packages/httpx-0.28.1.dist-info/licenses/LICENSE.md\n",
            "    - lib/python3.10/site-packages/httpx/__init__.py\n",
            "    - lib/python3.10/site-packages/httpx/__version__.py\n",
            "    - lib/python3.10/site-packages/httpx/_api.py\n",
            "    - lib/python3.10/site-packages/httpx/_auth.py\n",
            "    - lib/python3.10/site-packages/httpx/_client.py\n",
            "    - lib/python3.10/site-packages/httpx/_config.py\n",
            "    - lib/python3.10/site-packages/httpx/_content.py\n",
            "    - lib/python3.10/site-packages/httpx/_decoders.py\n",
            "    - lib/python3.10/site-packages/httpx/_exceptions.py\n",
            "    - lib/python3.10/site-packages/httpx/_main.py\n",
            "    - lib/python3.10/site-packages/httpx/_models.py\n",
            "    - lib/python3.10/site-packages/httpx/_multipart.py\n",
            "    - lib/python3.10/site-packages/httpx/_status_codes.py\n",
            "    - lib/python3.10/site-packages/httpx/_transports/__init__.py\n",
            "    - lib/python3.10/site-packages/httpx/_transports/asgi.py\n",
            "    - lib/python3.10/site-packages/httpx/_transports/base.py\n",
            "    - lib/python3.10/site-packages/httpx/_transports/default.py\n",
            "    - lib/python3.10/site-packages/httpx/_transports/mock.py\n",
            "    - lib/python3.10/site-packages/httpx/_transports/wsgi.py\n",
            "    - lib/python3.10/site-packages/httpx/_types.py\n",
            "    - lib/python3.10/site-packages/httpx/_urlparse.py\n",
            "    - lib/python3.10/site-packages/httpx/_urls.py\n",
            "    - lib/python3.10/site-packages/httpx/_utils.py\n",
            "    - lib/python3.10/site-packages/httpx/py.typed\n",
            "    - bin/httpx\n",
            "Linking cobra-0.29.1-pyhd8ed1ab_1\n",
            "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [cobra-0.29.1-pyhd8ed1ab_1] The following files were already present in the environment:\n",
            "    - lib/python3.10/site-packages/cobra/__init__.py\n",
            "    - lib/python3.10/site-packages/cobra/core/__init__.py\n",
            "    - lib/python3.10/site-packages/cobra/core/configuration.py\n",
            "    - lib/python3.10/site-packages/cobra/core/dictlist.py\n",
            "    - lib/python3.10/site-packages/cobra/core/formula.py\n",
            "    - lib/python3.10/site-packages/cobra/core/gene.py\n",
            "    - lib/python3.10/site-packages/cobra/core/group.py\n",
            "    - lib/python3.10/site-packages/cobra/core/metabolite.py\n",
            "    - lib/python3.10/site-packages/cobra/core/model.py\n",
            "    - lib/python3.10/site-packages/cobra/core/object.py\n",
            "    - lib/python3.10/site-packages/cobra/core/reaction.py\n",
            "    - lib/python3.10/site-packages/cobra/core/singleton.py\n",
            "    - lib/python3.10/site-packages/cobra/core/solution.py\n",
            "    - lib/python3.10/site-packages/cobra/core/species.py\n",
            "    - lib/python3.10/site-packages/cobra/data/__init__.py\n",
            "    - lib/python3.10/site-packages/cobra/data/iJO1366.xml.gz\n",
            "    - lib/python3.10/site-packages/cobra/data/mini.json\n",
            "    - lib/python3.10/site-packages/cobra/data/mini.mat\n",
            "    - lib/python3.10/site-packages/cobra/data/mini.yml\n",
            "    - lib/python3.10/site-packages/cobra/data/mini_cobra.xml\n",
            "    - lib/python3.10/site-packages/cobra/data/salmonella.xml.gz\n",
            "    - lib/python3.10/site-packages/cobra/data/textbook.xml.gz\n",
            "    - lib/python3.10/site-packages/cobra/exceptions.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/__init__.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/deletion.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/fastcc.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/gapfilling.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/geometric.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/helpers.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/loopless.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/moma.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/parsimonious.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/phenotype_phase_plane.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/reaction.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/room.py\n",
            "    - lib/python3.10/site-packages/cobra/flux_analysis/variability.py\n",
            "    - lib/python3.10/site-packages/cobra/io/__init__.py\n",
            "    - lib/python3.10/site-packages/cobra/io/dict.py\n",
            "    - lib/python3.10/site-packages/cobra/io/json.py\n",
            "    - lib/python3.10/site-packages/cobra/io/mat.py\n",
            "    - lib/python3.10/site-packages/cobra/io/sbml.py\n",
            "    - lib/python3.10/site-packages/cobra/io/schema_v1.json\n",
            "    - lib/python3.10/site-packages/cobra/io/web/__init__.py\n",
            "    - lib/python3.10/site-packages/cobra/io/web/abstract_model_repository.py\n",
            "    - lib/python3.10/site-packages/cobra/io/web/bigg_models_repository.py\n",
            "    - lib/python3.10/site-packages/cobra/io/web/biomodels_repository.py\n",
            "    - lib/python3.10/site-packages/cobra/io/web/cobrapy_repository.py\n",
            "    - lib/python3.10/site-packages/cobra/io/web/load.py\n",
            "    - lib/python3.10/site-packages/cobra/io/yaml.py\n",
            "    - lib/python3.10/site-packages/cobra/manipulation/__init__.py\n",
            "    - lib/python3.10/site-packages/cobra/manipulation/annotate.py\n",
            "    - lib/python3.10/site-packages/cobra/manipulation/delete.py\n",
            "    - lib/python3.10/site-packages/cobra/manipulation/modify.py\n",
            "    - lib/python3.10/site-packages/cobra/manipulation/validate.py\n",
            "    - lib/python3.10/site-packages/cobra/medium/__init__.py\n",
            "    - lib/python3.10/site-packages/cobra/medium/annotations.py\n",
            "    - lib/python3.10/site-packages/cobra/medium/boundary_types.py\n",
            "    - lib/python3.10/site-packages/cobra/medium/minimal_medium.py\n",
            "    - lib/python3.10/site-packages/cobra/sampling/__init__.py\n",
            "    - lib/python3.10/site-packages/cobra/sampling/achr.py\n",
            "    - lib/python3.10/site-packages/cobra/sampling/core.py\n",
            "    - lib/python3.10/site-packages/cobra/sampling/hr_sampler.py\n",
            "    - lib/python3.10/site-packages/cobra/sampling/optgp.py\n",
            "    - lib/python3.10/site-packages/cobra/sampling/sampling.py\n",
            "    - lib/python3.10/site-packages/cobra/summary/__init__.py\n",
            "    - lib/python3.10/site-packages/cobra/summary/metabolite_summary.py\n",
            "    - lib/python3.10/site-packages/cobra/summary/model_summary.py\n",
            "    - lib/python3.10/site-packages/cobra/summary/reaction_summary.py\n",
            "    - lib/python3.10/site-packages/cobra/summary/summary.py\n",
            "    - lib/python3.10/site-packages/cobra/util/__init__.py\n",
            "    - lib/python3.10/site-packages/cobra/util/array.py\n",
            "    - lib/python3.10/site-packages/cobra/util/context.py\n",
            "    - lib/python3.10/site-packages/cobra/util/process_pool.py\n",
            "    - lib/python3.10/site-packages/cobra/util/solver.py\n",
            "    - lib/python3.10/site-packages/cobra/util/util.py\n",
            "\n",
            "Transaction finished\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! /content/runs/run_001/bin/micromamba run -p /content/runs/run_001/micromamba/envs/retrobiocat \\\n",
        "python -c \"import sys; print('python:', sys.executable); import importlib.util as u; print('cobra found?', u.find_spec('cobra') is not None)\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUCpwjLibOb0",
        "outputId": "1abd25cf-6dcd-4b26-b8a8-7995b2cd7511"
      },
      "id": "hUCpwjLibOb0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python: /content/runs/run_001/micromamba/envs/retrobiocat/bin/python\n",
            "cobra found? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Execution cell ===\n",
        "import os, urllib.request, pathlib, pandas as pd\n",
        "\n",
        "# 1) Prepare model if needed\n",
        "model_path = pathlib.Path(\"/content/models/iML1515.xml\")\n",
        "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "if not model_path.exists():\n",
        "    urllib.request.urlretrieve(\n",
        "        \"https://github.com/opencobra/COBRA.tutorials/raw/main/src/data/iML1515.xml\",\n",
        "        str(model_path)\n",
        "    )\n",
        "print(\"✅ SBML model ready:\", model_path)\n",
        "\n",
        "# 2) Initialize state\n",
        "workdir = pathlib.Path(\"/content/runs/run_001\")\n",
        "(workdir / \"retro_finish_out\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "state = {\n",
        "    \"run_id\": \"run_001\",\n",
        "    \"workdir\": str(workdir),\n",
        "    \"target_smiles\": \"COC1=C(C=CC(=C1)C=O)O\",\n",
        "    \"host\": \"Escherichia coli\",\n",
        "    \"signals\": {\"human_approved\": True},\n",
        "    \"approved\": True,  # human gate default\n",
        "    \"constraints\": {\n",
        "        \"max_steps\": 5,\n",
        "        \"net_access\": True,\n",
        "        \"uniprot\": {\"timeout_s\": 10, \"max_hits_per_query\": 3},\n",
        "        \"expanders\": [\"RetroBioCat\", \"EnzymeMap\", \"BKMS\", \"RetroRules\"],\n",
        "        \"max_search_time_s\": 15,\n",
        "    },\n",
        "    \"thermo_params\": {\n",
        "        \"pH\": 7.5,\n",
        "        \"ionic_strength\": 0.25,\n",
        "        \"pMg\": 3.0,\n",
        "        \"temperature_K\": 298.15,\n",
        "        \"pass_margin_kJ\": 0.0,\n",
        "    },\n",
        "    \"sbml_model_path\": str(model_path),\n",
        "    \"metabolite_map\": {},\n",
        "    \"simulate\": {\"mu_min\": 0.15, \"v_prod_min\": 1e-4, \"product_id\": None},\n",
        "    \"logs\": [],\n",
        "}\n",
        "\n",
        "# 3) Run sequentially\n",
        "state[\"logs\"].clear()\n",
        "\n",
        "# Upstream design / analysis\n",
        "state = retrosynthesis_node(state)\n",
        "state = extract_node(state)\n",
        "state = add_selenzyme_links_node(state)\n",
        "state = selenzyme_rank_node(state) or state        # writes steps_enzyme_choice.csv + seed_uniprots\n",
        "state = compound_map_node(state)\n",
        "state = thermo_node(state)\n",
        "state = rank_node(state)\n",
        "state = simulate_gem_node(state)\n",
        "\n",
        "# Enzyme/sequence stack\n",
        "# (A second selenzyme_rank pass is OK but not required; keep one to be fast)\n",
        "# state = selenzyme_rank_node(state) or state\n",
        "state = sequence_fetch_node(state, per_step=10, reviewed_first=False, timeout=12.0) or state\n",
        "state = sequence_rank_node(state) or state  # writes steps_sequence_plan.csv\n",
        "\n",
        "# --- sequence coverage summary logger (robust) ---\n",
        "from pathlib import Path\n",
        "finish = Path(state.get(\"workdir\") or \".\") / \"retro_finish_out\"\n",
        "\n",
        "def _safe_read(path, cols=None):\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        if cols:\n",
        "            for c in cols:\n",
        "                if c not in df.columns:\n",
        "                    df[c] = []\n",
        "            df = df[cols]\n",
        "        return df\n",
        "    except Exception:\n",
        "        return pd.DataFrame(columns=cols or [])\n",
        "\n",
        "steps = _safe_read(finish / \"steps_enzyme_plan.csv\", cols=[\"pathway_tag\",\"step_idx\"])\n",
        "cands = _safe_read(finish / \"steps_sequence_candidates.csv\", cols=[\"pathway_tag\",\"step_idx\"])\n",
        "picks = _safe_read(finish / \"steps_sequence_plan.csv\", cols=[\"pathway_tag\",\"step_idx\"])\n",
        "\n",
        "for df in (steps, cands, picks):\n",
        "    if len(df):\n",
        "        df[\"pathway_tag\"] = df[\"pathway_tag\"].astype(str)\n",
        "        df[\"step_idx\"] = pd.to_numeric(df[\"step_idx\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "steps = steps.drop_duplicates().assign(source=\"steps\")\n",
        "cands = cands.drop_duplicates().assign(source=\"candidates\")\n",
        "picks = picks.drop_duplicates().assign(source=\"picks\")\n",
        "\n",
        "n_cands = (\n",
        "    cands.groupby([\"pathway_tag\",\"step_idx\"]).size().reset_index(name=\"n_candidates\")\n",
        ") if len(cands) else pd.DataFrame(columns=[\"pathway_tag\",\"step_idx\",\"n_candidates\"])\n",
        "\n",
        "rep = steps.merge(n_cands, on=[\"pathway_tag\",\"step_idx\"], how=\"left\").fillna({\"n_candidates\": 0})\n",
        "pick_set = set(zip(picks.pathway_tag, picks.step_idx)) if len(picks) else set()\n",
        "rep[\"picked\"] = [(pt, si) in pick_set for pt, si in zip(rep.pathway_tag, rep.step_idx)]\n",
        "\n",
        "def _reason(row):\n",
        "    if int(row[\"n_candidates\"]) == 0:\n",
        "        return \"no_candidates_found\"\n",
        "    if not bool(row[\"picked\"]):\n",
        "        return \"not_selected_in_rank\"\n",
        "    return \"ok\"\n",
        "\n",
        "rep[\"reason\"] = rep.apply(_reason, axis=1)\n",
        "rep = rep.sort_values([\"pathway_tag\", \"step_idx\"]).reset_index(drop=True)\n",
        "out_csv = finish / \"sequence_coverage_report.csv\"\n",
        "rep.to_csv(out_csv, index=False)\n",
        "print(f\"✅ wrote coverage summary → {out_csv}\")\n",
        "print(rep.groupby(\"reason\").size() if len(rep) else \"no rows\")\n",
        "print(rep.head(15))\n",
        "\n",
        "# (Optional) simple coverage gate for sequential run\n",
        "coverage_ok = (rep[\"n_candidates\"] > 0).mean() >= 0.80 if len(rep) else False\n",
        "if not coverage_ok:\n",
        "    print(\"⚠️ coverage < 80% → quick retry with relaxed fetch\")\n",
        "    state = sequence_fetch_node(state, per_step=15, reviewed_first=False, timeout=15.0) or state\n",
        "    state = sequence_rank_node(state) or state\n",
        "\n",
        "\n",
        "state[\"strain\"] = {\n",
        "    \"objective_id\": \"BIOMASS_Ec_iML1515_core_75p37M\",\n",
        "    \"product_rxn\":  state.get(\"simulate\",{}).get(\"product_id\") or None,  # or set explicit rxn id\n",
        "    \"min_growth\":   0.05,\n",
        "    \"max_kos\":      2,\n",
        "    \"solver\":       \"glpk\",\n",
        "    \"fva\":          True,\n",
        "    \"time_limit_s\": 300,\n",
        "    \"search\":       \"auto\",   # \"heuristic\" if you want to skip cameo\n",
        "    \"medium\":       {\"EX_glc__D_e\": -10.0},\n",
        "\n",
        "    # Candidate chooser heuristics\n",
        "    \"ko_filters\": {\n",
        "        \"skip_exchange\": True,\n",
        "        \"skip_transport\": True,\n",
        "        \"protect_essentials\": True,\n",
        "        \"prefer_subsystems\": [\"Glycolysis/Gluconeogenesis\",\"TCA cycle\",\"Pentose Phosphate Pathway\"],\n",
        "        \"max_candidates\": 100\n",
        "    },\n",
        "\n",
        "    # Optional triples sweep\n",
        "    \"triples\": {\"enable\": False, \"top_k\": 30, \"patience\": 50}\n",
        "}\n",
        "\n",
        "\n",
        "# Strain optimization → Build → Test → Learn → Human gate → Export\n",
        "state = strain_optimize_node(state) or state\n",
        "state = build_node(state) or state\n",
        "state = test_node(state) or state\n",
        "state = learn_node(state) or state\n",
        "state = human_gate_node(state)\n",
        "state = export_node(state)\n",
        "\n",
        "# 4) Stream logs\n",
        "for l in state.get(\"logs\", []):\n",
        "    print(l)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rAdnxOdbOW4",
        "outputId": "0344c1ba-c62f-407d-800c-e6e3b568409c"
      },
      "id": "0rAdnxOdbOW4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ SBML model ready: /content/models/iML1515.xml\n",
            "▶ start extract\n",
            "extracted pathways from pathways_solved_steps.csv (82 step rows, 23 pathways)\n",
            "✔ done extract\n",
            "▶ start add_selenzyme_links\n",
            "selenzyme_links: filled 82 URLs out of 82 rows → /content/runs/run_001/retro_finish_out/steps_enzyme_plan.csv\n",
            "✔ done add_selenzyme_links\n",
            "compound_map: wrote /content/runs/run_001/retro_finish_out/metabolite_map.csv (inchikey filled 0 / 25)\n",
            "▶ start thermo\n",
            "thermo: token IDs available for 0 / 23 tokens\n",
            "thermo: id routes: {'via_explicit_id': 0, 'via_inchikey_literal': 0, 'via_rdkit_inchikey': 0, 'via_rdkit_inchikey_only': 23, 'via_pubchem_kegg': 0, 'via_pubchem_smiles': 0, 'via_pubchem_cas': 0, 'via_match_smiles': 0, 'via_name': 0, 'unmapped': 23}\n",
            "thermo: NOTE – RDKit produced InChIKeys but none resolved to KEGG via PubChem.\n",
            "thermo: example tokens with IK but no KEGG (first 5): ['CNC(=O)C(=O)c1ccc(O)c(OC)c1', 'CNC(=O)C(O)c1ccc(O)c(OC)c1', 'COC1=C(C=CC(=C1)C=O)O', 'COc1cc(C(=O)C#N)ccc1O', 'COc1cc(C(=O)C(=O)C(=O)O)ccc1O']\n",
            "thermo: equilibrator ran in env\n",
            "thermo: steps evaluable 0 / 82\n",
            "✔ done thermo (75.5s)\n",
            "▶ start simulate_gem\n",
            "simulate_gem: results=/content/runs/run_001/retro_finish_out/sim_fba_summary.csv\n",
            "✔ done simulate_gem (18.0s)\n",
            "▶ start sequence_fetch (v4)\n",
            "sequence_fetch: wrote 744 candidates → /content/runs/run_001/retro_finish_out/steps_sequence_candidates.csv\n",
            "✔ done sequence_fetch (20.3s)\n",
            "▶ start sequence_rank\n",
            "sequence_rank: wrote 75 picks → /content/runs/run_001/retro_finish_out/steps_sequence_plan.csv\n",
            "✔ done sequence_rank (0.0s)\n",
            "✅ wrote coverage summary → /content/runs/run_001/retro_finish_out/sequence_coverage_report.csv\n",
            "reason\n",
            "no_candidates_found     7\n",
            "ok                     75\n",
            "dtype: int64\n",
            "   pathway_tag  step_idx source  n_candidates  picked               reason\n",
            "0         P001         1  steps           1.0    True                   ok\n",
            "1         P001         2  steps           1.0    True                   ok\n",
            "2         P001         3  steps           1.0    True                   ok\n",
            "3         P001         4  steps           1.0    True                   ok\n",
            "4         P002         1  steps           1.0    True                   ok\n",
            "5         P002         2  steps           1.0    True                   ok\n",
            "6         P002         3  steps           1.0    True                   ok\n",
            "7         P002         4  steps           0.0   False  no_candidates_found\n",
            "8         P003         1  steps           1.0    True                   ok\n",
            "9         P004         1  steps           1.0    True                   ok\n",
            "10        P004         2  steps           1.0    True                   ok\n",
            "11        P004         3  steps           1.0    True                   ok\n",
            "12        P004         4  steps           1.0    True                   ok\n",
            "13        P004         5  steps           1.0    True                   ok\n",
            "14        P005         1  steps           1.0    True                   ok\n",
            "▶ start strain_optimize\n",
            "strain_optimize: ERROR → File \"<string>\", line 298\n",
            "SyntaxError: no binding for nonlocal 'best' found\n",
            "▶ start build (codon-opt + Golden Gate plan)\n",
            "build: wrote 75 constructs -> sequences_codon_opt.fasta, cloning_plan.csv\n",
            "✔ done build (0.4s)\n",
            "✔ done test_node (75 constructs tested) → /content/runs/run_001/retro_finish_out/test_results.csv\n",
            "learn_node: mean activities by status = {'active': 73.41706040361987, 'inactive': 25.514888873440828}\n",
            "✔ done learn_node → learn_update.json\n",
            "{'node': 'retrosynthesis', 'ts': '2025-10-24T20:55:28Z', 'cmd': '/content/runs/run_001/bin/micromamba run -p /content/runs/run_001/micromamba/envs/retrobiocat python /content/runs/run_001/bin/rbc2_runner.py', 'rc': 0, 'out_log': '/content/runs/run_001/logs/_rbc2_runner.out.log', 'err_log': '/content/runs/run_001/logs/_rbc2_runner.err.log'}\n",
            "▶ start extract\n",
            "extracted pathways from pathways_solved_steps.csv (82 step rows, 23 pathways)\n",
            "✔ done extract\n",
            "▶ start add_selenzyme_links\n",
            "selenzyme_links: filled 82 URLs out of 82 rows → /content/runs/run_001/retro_finish_out/steps_enzyme_plan.csv\n",
            "✔ done add_selenzyme_links\n",
            "selenzyme_rank: seed_uniprots populated for 0 / 82 steps\n",
            "compound_map: wrote /content/runs/run_001/retro_finish_out/metabolite_map.csv (inchikey filled 0 / 25)\n",
            "▶ start thermo\n",
            "thermo: token IDs available for 0 / 23 tokens\n",
            "thermo: id routes: {'via_explicit_id': 0, 'via_inchikey_literal': 0, 'via_rdkit_inchikey': 0, 'via_rdkit_inchikey_only': 23, 'via_pubchem_kegg': 0, 'via_pubchem_smiles': 0, 'via_pubchem_cas': 0, 'via_match_smiles': 0, 'via_name': 0, 'unmapped': 23}\n",
            "thermo: NOTE – RDKit produced InChIKeys but none resolved to KEGG via PubChem.\n",
            "thermo: example tokens with IK but no KEGG (first 5): ['CNC(=O)C(=O)c1ccc(O)c(OC)c1', 'CNC(=O)C(O)c1ccc(O)c(OC)c1', 'COC1=C(C=CC(=C1)C=O)O', 'COc1cc(C(=O)C#N)ccc1O', 'COc1cc(C(=O)C(=O)C(=O)O)ccc1O']\n",
            "thermo: equilibrator ran in env\n",
            "thermo: steps evaluable 0 / 82\n",
            "✔ done thermo (75.5s)\n",
            "▶ start rank\n",
            "ranked pathways (already computed with thermo)\n",
            "ranked_final=/content/runs/run_001/retro_finish_out/pathways_ranked_final.csv\n",
            "✔ done rank (0.0s)\n",
            "▶ start simulate_gem\n",
            "simulate_gem: results=/content/runs/run_001/retro_finish_out/sim_fba_summary.csv\n",
            "▶ start sequence_fetch (v4)\n",
            "sequence_fetch: wrote 744 candidates → /content/runs/run_001/retro_finish_out/steps_sequence_candidates.csv\n",
            "✔ done sequence_fetch (20.3s)\n",
            "▶ start sequence_rank\n",
            "sequence_rank: wrote 75 picks → /content/runs/run_001/retro_finish_out/steps_sequence_plan.csv\n",
            "✔ done sequence_rank (0.0s)\n",
            "▶ start strain_optimize\n",
            "strain_optimize: ERROR → File \"<string>\", line 298\n",
            "SyntaxError: no binding for nonlocal 'best' found\n",
            "▶ start build (codon-opt + Golden Gate plan)\n",
            "build: wrote 75 constructs -> sequences_codon_opt.fasta, cloning_plan.csv\n",
            "✔ done build (0.4s)\n",
            "human_gate: approval file ready at /content/runs/run_001/retro_finish_out/_HUMAN_GATE.md\n",
            "human_gate: approved=True\n",
            "export_node: exported 5 artifacts\n",
            "export_node: manifest=/content/runs/run_001/retro_export/manifest.json\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}